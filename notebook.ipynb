{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2seq-Chatbot-NLP-Term-Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XPwizXb0y9AQ",
        "ZUYtx6dU2TSx",
        "PSV0PYu32ujX",
        "RfHcSR353Vmx",
        "z2qqz12D4NWP",
        "77RNcbws4Ztu",
        "kINUv78044G-",
        "ZtTkn_Yu4_Ry"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45rC0sWh9k7h"
      },
      "source": [
        "# Jarvis: Seq2seq based Chatbot for Customer Support"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng1Esw24qXe0"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import torch\n",
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "from io import open\n",
        "import itertools\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fQqEPTjr1A0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMOAHqZvqXU7"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LMOlnOpC97j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac74310-5c02-4650-c1de-a35643c9c71b"
      },
      "source": [
        "USE_CUDA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU56Wycb06IJ"
      },
      "source": [
        "## Downloading dataset\n",
        "Requires API access from Kaggle. See [this](https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/) blog for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0KFUK1v1ACZ"
      },
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDT6woS11HYt"
      },
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L42J_5J-1LXb"
      },
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeChhYz71O-_",
        "outputId": "024aa161-a6eb-4e7d-8422-fbfc50a17064"
      },
      "source": [
        "!kaggle datasets download thoughtvector/customer-support-on-twitter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading customer-support-on-twitter.zip to /content\n",
            " 96% 161M/169M [00:04<00:00, 40.0MB/s]\n",
            "100% 169M/169M [00:04<00:00, 41.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c79tmgRF1wJg",
        "outputId": "ade6f5c8-ed13-4b99-de82-fba98c856c74"
      },
      "source": [
        "!unzip customer-support-on-twitter.zip -d dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  customer-support-on-twitter.zip\n",
            "  inflating: dataset/sample.csv      \n",
            "  inflating: dataset/twcs/twcs.csv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-xS4ux12OXb"
      },
      "source": [
        "## Preprocessing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1fWZRlP14qL"
      },
      "source": [
        "df = pd.read_csv('dataset/twcs/twcs.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "ZL9RBcT854-C",
        "outputId": "0f275cc3-6340-4d59-b348-6f9333177035"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
              "      <td>@sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
              "      <td>@sprintcare I have sent several private messag...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
              "      <td>@sprintcare I did.</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811769</th>\n",
              "      <td>2987947</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 22 08:43:51 +0000 2017</td>\n",
              "      <td>@823869 Hey, we'd be happy to look into this f...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2987948.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811770</th>\n",
              "      <td>2987948</td>\n",
              "      <td>823869</td>\n",
              "      <td>True</td>\n",
              "      <td>Wed Nov 22 08:35:16 +0000 2017</td>\n",
              "      <td>@115714 wtf!? I’ve been having really shitty s...</td>\n",
              "      <td>2987947</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811771</th>\n",
              "      <td>2812240</td>\n",
              "      <td>121673</td>\n",
              "      <td>True</td>\n",
              "      <td>Thu Nov 23 04:13:07 +0000 2017</td>\n",
              "      <td>@143549 @sprintcare You have to go to https://...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2812239.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811772</th>\n",
              "      <td>2987949</td>\n",
              "      <td>AldiUK</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 22 08:31:24 +0000 2017</td>\n",
              "      <td>@823870 Sounds delicious, Sarah! 😋 https://t.c...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2987950.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811773</th>\n",
              "      <td>2987950</td>\n",
              "      <td>823870</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Nov 21 22:01:04 +0000 2017</td>\n",
              "      <td>@AldiUK  warm sloe gin mince pies with ice cre...</td>\n",
              "      <td>2987951,2987949</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2811774 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         tweet_id   author_id  ...  response_tweet_id in_response_to_tweet_id\n",
              "0               1  sprintcare  ...                  2                     3.0\n",
              "1               2      115712  ...                NaN                     1.0\n",
              "2               3      115712  ...                  1                     4.0\n",
              "3               4  sprintcare  ...                  3                     5.0\n",
              "4               5      115712  ...                  4                     6.0\n",
              "...           ...         ...  ...                ...                     ...\n",
              "2811769   2987947  sprintcare  ...                NaN               2987948.0\n",
              "2811770   2987948      823869  ...            2987947                     NaN\n",
              "2811771   2812240      121673  ...                NaN               2812239.0\n",
              "2811772   2987949      AldiUK  ...                NaN               2987950.0\n",
              "2811773   2987950      823870  ...    2987951,2987949                     NaN\n",
              "\n",
              "[2811774 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny2l_Osi59WQ"
      },
      "source": [
        "df = df.fillna(np.nan).replace([np.nan], [None])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "JE3-jhj06SuG",
        "outputId": "76ae489e-aee8-4e7a-ec70-93ea0d3751f0"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
              "      <td>@sprintcare and how do you propose we do that</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
              "      <td>@sprintcare I have sent several private messag...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
              "      <td>@sprintcare I did.</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811769</th>\n",
              "      <td>2987947</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 22 08:43:51 +0000 2017</td>\n",
              "      <td>@823869 Hey, we'd be happy to look into this f...</td>\n",
              "      <td>None</td>\n",
              "      <td>2.98795e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811770</th>\n",
              "      <td>2987948</td>\n",
              "      <td>823869</td>\n",
              "      <td>True</td>\n",
              "      <td>Wed Nov 22 08:35:16 +0000 2017</td>\n",
              "      <td>@115714 wtf!? I’ve been having really shitty s...</td>\n",
              "      <td>2987947</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811771</th>\n",
              "      <td>2812240</td>\n",
              "      <td>121673</td>\n",
              "      <td>True</td>\n",
              "      <td>Thu Nov 23 04:13:07 +0000 2017</td>\n",
              "      <td>@143549 @sprintcare You have to go to https://...</td>\n",
              "      <td>None</td>\n",
              "      <td>2.81224e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811772</th>\n",
              "      <td>2987949</td>\n",
              "      <td>AldiUK</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 22 08:31:24 +0000 2017</td>\n",
              "      <td>@823870 Sounds delicious, Sarah! 😋 https://t.c...</td>\n",
              "      <td>None</td>\n",
              "      <td>2.98795e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811773</th>\n",
              "      <td>2987950</td>\n",
              "      <td>823870</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Nov 21 22:01:04 +0000 2017</td>\n",
              "      <td>@AldiUK  warm sloe gin mince pies with ice cre...</td>\n",
              "      <td>2987951,2987949</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2811774 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         tweet_id   author_id  ...  response_tweet_id in_response_to_tweet_id\n",
              "0               1  sprintcare  ...                  2                       3\n",
              "1               2      115712  ...               None                       1\n",
              "2               3      115712  ...                  1                       4\n",
              "3               4  sprintcare  ...                  3                       5\n",
              "4               5      115712  ...                  4                       6\n",
              "...           ...         ...  ...                ...                     ...\n",
              "2811769   2987947  sprintcare  ...               None             2.98795e+06\n",
              "2811770   2987948      823869  ...            2987947                    None\n",
              "2811771   2812240      121673  ...               None             2.81224e+06\n",
              "2811772   2987949      AldiUK  ...               None             2.98795e+06\n",
              "2811773   2987950      823870  ...    2987951,2987949                    None\n",
              "\n",
              "[2811774 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM52MgP3usXM"
      },
      "source": [
        "# Lowercasing the text\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq4CWFM1u4_i"
      },
      "source": [
        "# Removing html tags\n",
        "\n",
        "def cleanhtml(raw_html):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', raw_html)\n",
        "    return cleantext\n",
        "\n",
        "df['text'] = df['text'].apply(cleanhtml)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "713v9S5HvPSv"
      },
      "source": [
        "# Removing URLs\n",
        "\n",
        "def removeUrl(x):\n",
        "    x = re.sub(r'http\\S+', '', x)\n",
        "    return x\n",
        "\n",
        "df['text'] = df['text'].apply(removeUrl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnqeqk9cvhET"
      },
      "source": [
        "# Removing Username\n",
        "\n",
        "def removeUsername(x):\n",
        "    x = re.sub(r'@\\S+', '', x)\n",
        "    return x\n",
        "\n",
        "df['text'] = df['text'].apply(removeUsername)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhgNtfekvzI_"
      },
      "source": [
        "# Removing non-alphanumeric characters\n",
        "\n",
        "def removeNonAlpha(x):\n",
        "    x = re.sub(\"\\s+\", \" \", x)  # converting space-like character to single white space\n",
        "    x = ''.join([y for y in x if y.isalnum() or y ==' '])\n",
        "    return x\n",
        "\n",
        "df['text'] = df['text'].apply(removeNonAlpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwVr0TPT6Udg"
      },
      "source": [
        "tweet_id = df['tweet_id'].tolist()\n",
        "text = df['text'].tolist()\n",
        "response = df['response_tweet_id'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pMwbeIS6-il"
      },
      "source": [
        "tweets = dict()\n",
        "for i in range(len(tweet_id)):\n",
        "    tweets[tweet_id[i]] = text[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1uwbh5V6b59"
      },
      "source": [
        "MAX_PAIRS = 10000\n",
        "sent1 = []\n",
        "sent2 = []\n",
        "ctr = 0\n",
        "\n",
        "while len(sent1) < MAX_PAIRS:\n",
        "    r = response[ctr]\n",
        "    if r:\n",
        "        r = int(r.split(',')[0])\n",
        "        try:\n",
        "            sent1_ = tweets[tweet_id[ctr]]\n",
        "            sent2_ = tweets[r]\n",
        "        except:\n",
        "            ctr += 1\n",
        "            continue\n",
        "        sent1.append(sent1_)\n",
        "        sent2.append(sent2_)\n",
        "    ctr += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AabywLtNIs88"
      },
      "source": [
        "delimiter = '\\t'\n",
        "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
        "with open('pairs.txt', 'w', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f, delimiter=delimiter, lineterminator='\\n')\n",
        "    for i in range(len(sent1)):\n",
        "        pair = [sent1[i], sent2[i]]\n",
        "        writer.writerow(pair)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c123XGAtyGs",
        "outputId": "e3d1cde9-c92e-410e-d4fc-2e58886410c0"
      },
      "source": [
        "idx = np.random.randint(10000)\n",
        "print(sent1[idx])\n",
        "print(sent2[idx])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wells fargo did me so fucking dirty omg \n",
            " what happened please share more details about your recent service experience no account numbers hh \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPwizXb0y9AQ"
      },
      "source": [
        "## Loading and Trimming Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcVJeGTLyel4"
      },
      "source": [
        "# Default word tokens\n",
        "PAD_token = 0  # Used for padding short sentences\n",
        "SOS_token = 1  # Start-of-sentence token\n",
        "EOS_token = 2  # End-of-sentence token\n",
        "\n",
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.trimmed = False\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3  # Count SOS, EOS, PAD\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.num_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.num_words] = word\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    # Remove words below a certain count threshold\n",
        "    def trim(self, min_count):\n",
        "        if self.trimmed:\n",
        "            return\n",
        "        self.trimmed = True\n",
        "\n",
        "        keep_words = []\n",
        "\n",
        "        for k, v in self.word2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_words.append(k)\n",
        "\n",
        "        print('keep_words {} / {} = {:.4f}'.format(\n",
        "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
        "        ))\n",
        "\n",
        "        # Reinitialize dictionaries\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3 # Count default tokens\n",
        "\n",
        "        for word in keep_words:\n",
        "            self.addWord(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxFjj0IszRw2"
      },
      "source": [
        "MAX_LENGTH = 64  # Maximum sentence length to consider"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHxagTFrzYa2"
      },
      "source": [
        "# Turn a Unicode string to plain ASCII\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcozglQ2zgQz"
      },
      "source": [
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "    return s\n",
        "\n",
        "# Read query/response pairs and return a voc object\n",
        "def readVocs(datafile, corpus_name):\n",
        "    print(\"Reading lines...\")\n",
        "    # Read the file and split into lines\n",
        "    lines = open(datafile, encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    voc = Voc(corpus_name)\n",
        "    return voc, pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebhAMgj80OB0"
      },
      "source": [
        "# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
        "def filterPair(p):\n",
        "    # Input sequences need to preserve the last word for EOS token\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "# Filter pairs using filterPair condition\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqoXN9XI0bRM"
      },
      "source": [
        "# Using the functions defined above, return a populated voc object and pairs list\n",
        "\n",
        "def loadPrepareData(corpus, corpus_name, datafile, save_dir):\n",
        "    print(\"Start preparing training data ...\")\n",
        "    voc, pairs = readVocs(datafile, corpus_name)\n",
        "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        voc.addSentence(pair[0])\n",
        "        voc.addSentence(pair[1])\n",
        "    print(\"Counted words:\", voc.num_words)\n",
        "    return voc, pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaEBMfo70wZn",
        "outputId": "a9cc476e-a4d9-44bc-cd15-6c25dafaf756"
      },
      "source": [
        "corpus_name = 'customer-support-on-twitter'\n",
        "corpus = os.path.join(\"data\", corpus_name)\n",
        "datafile = 'pairs.txt'\n",
        "save_dir = os.path.join(\"data\", \"save\")\n",
        "\n",
        "voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)\n",
        "# Print some pairs to validate\n",
        "print(\"\\npairs:\")\n",
        "for pair in pairs[:10]:\n",
        "    print(pair)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start preparing training data ...\n",
            "Reading lines...\n",
            "Read 10000 sentence pairs\n",
            "Trimmed to 10000 sentence pairs\n",
            "Counting words...\n",
            "Counted words: 12899\n",
            "\n",
            "pairs:\n",
            "['i understand i would like to assist you we would need to get you into a private secured link to further assist', 'and how do you propose we do that']\n",
            "['i have sent several private messages and no one is responding as usual', 'i understand i would like to assist you we would need to get you into a private secured link to further assist']\n",
            "['please send us a private message so that we can further assist you just click message at the top of your profile', 'i have sent several private messages and no one is responding as usual']\n",
            "['i did', 'please send us a private message so that we can further assist you just click message at the top of your profile']\n",
            "['can you please send us a private message so that i can gain further details about your account', 'i did']\n",
            "['is the worst customer service', 'i would love the chance to review the account and provide assistance']\n",
            "['you gonna magically change your connectivity for me and my whole family', 'this is saddening to hear please shoot us a dm so that we can look into this for you kc']\n",
            "['we understand your concerns and wed like for you to please send us a direct message so that we can further assist you aa', 'you gonna magically change your connectivity for me and my whole family']\n",
            "['since i signed up with yousince day', 'we understand your concerns and wed like for you to please send us a direct message so that we can further assist you aa']\n",
            "['h there wed definitely like to work with you on this how long have you been experiencing this issue aa', 'since i signed up with yousince day']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUYtx6dU2TSx"
      },
      "source": [
        "## Removing rare words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4gyBDq610Iw"
      },
      "source": [
        "MIN_COUNT = 3    # Minimum word count threshold for trimming\n",
        "\n",
        "def trimRareWords(voc, pairs, MIN_COUNT):\n",
        "    # Trim words used under the MIN_COUNT from the voc\n",
        "    voc.trim(MIN_COUNT)\n",
        "    # Filter out pairs with trimmed words\n",
        "    keep_pairs = []\n",
        "    for pair in pairs:\n",
        "        input_sentence = pair[0]\n",
        "        output_sentence = pair[1]\n",
        "        keep_input = True\n",
        "        keep_output = True\n",
        "        # Check input sentence\n",
        "        for word in input_sentence.split(' '):\n",
        "            if word not in voc.word2index:\n",
        "                keep_input = False\n",
        "                break\n",
        "        # Check output sentence\n",
        "        for word in output_sentence.split(' '):\n",
        "            if word not in voc.word2index:\n",
        "                keep_output = False\n",
        "                break\n",
        "\n",
        "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
        "        if keep_input and keep_output:\n",
        "            keep_pairs.append(pair)\n",
        "\n",
        "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
        "    return keep_pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR_kdRRY2bL2",
        "outputId": "3726d9dd-d35b-4b3d-a510-2e81e7ab7b59"
      },
      "source": [
        "# Trim voc and pairs\n",
        "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keep_words 5543 / 12896 = 0.4298\n",
            "Trimmed from 10000 pairs to 4772, 0.4772 of total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSV0PYu32ujX"
      },
      "source": [
        "## Preparing data for the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_yTdfBm2ef4"
      },
      "source": [
        "def indexesFromSentence(voc, sentence):\n",
        "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
        "\n",
        "\n",
        "def zeroPadding(l, fillvalue=PAD_token):\n",
        "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2whBeGl21YE"
      },
      "source": [
        "def binaryMatrix(l, value=PAD_token):\n",
        "    m = []\n",
        "    for i, seq in enumerate(l):\n",
        "        m.append([])\n",
        "        for token in seq:\n",
        "            if token == PAD_token:\n",
        "                m[i].append(0)\n",
        "            else:\n",
        "                m[i].append(1)\n",
        "    return m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAba7hjW26oE"
      },
      "source": [
        "def inputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, lengths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4674Smdd29vv"
      },
      "source": [
        "# Returns padded target sequence tensor, padding mask, and max target length\n",
        "\n",
        "def outputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    mask = binaryMatrix(padList)\n",
        "    mask = torch.BoolTensor(mask)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, mask, max_target_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4m8DpwH3DDI"
      },
      "source": [
        "# Returns all items for a given batch of pairs\n",
        "def batch2TrainData(voc, pair_batch):\n",
        "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
        "    input_batch, output_batch = [], []\n",
        "    for pair in pair_batch:\n",
        "        input_batch.append(pair[0])\n",
        "        output_batch.append(pair[1])\n",
        "    inp, lengths = inputVar(input_batch, voc)\n",
        "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
        "    return inp, lengths, output, mask, max_target_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okH04JIg3H8Q",
        "outputId": "14643a3f-1b29-489d-8ec4-1e80cefe172e"
      },
      "source": [
        "small_batch_size = 32\n",
        "\n",
        "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
        "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
        "\n",
        "print(\"input_variable:\", input_variable)\n",
        "print(\"lengths:\", lengths)\n",
        "print(\"target_variable:\", target_variable)\n",
        "print(\"mask:\", mask)\n",
        "print(\"max_target_len:\", max_target_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variable: tensor([[ 232,  277,  195,  221,    9,  549,  103,  160,   65,   65,  205,   63,\n",
            "           10,   33,  117, 5511,  549,    9,  936,   65, 1609,   19,  873,  124,\n",
            "            9,   98,   42,  269,    3,  751,  750,  750],\n",
            "        [1716,    9,    7,  174,  735,   84,    3,    9,  169,  169, 1719, 1420,\n",
            "            5,  385, 1310,  142,   20,  771,  385,  191,   41,  371, 1286,   39,\n",
            "           11,   27, 3502,  224,  495,    2,    2,    2],\n",
            "        [ 127,  805,   69, 4078,  235,   20,  410, 1983,   63,  139, 1720, 3500,\n",
            "            6,   45,   21,    9,  179, 1352,   65,  231,   42,  269,  869,   35,\n",
            "            7,  586,  878,  133, 1823,    0,    0,    0],\n",
            "        [1225,   12,   22,   81,    7,  160,    7,   64,  170,  124,  335,  104,\n",
            "            7,   48,    9,   63,  305,   45,  104,   29, 2030,  418,  320,  874,\n",
            "          193,  327, 1031,  350,    9,    0,    0,    0],\n",
            "        [ 856,   65,    9,    3,  294,    9,  196,   14,  576, 3661,  150,   35,\n",
            "         2803,  111,  196,   42,   22, 4456,  231,   33, 1896,  324,  141, 1387,\n",
            "          124,   87,  395,  351,    2,    0,    0,    0],\n",
            "        [ 292, 1107,  160, 1206,  232, 1798,   42, 1242,  133,  811,  698,   41,\n",
            "            9,   42,   42, 1097,    3,  391,    7,  193,    6, 5498, 1884,  305,\n",
            "           64,    2,    2,    2,    0,    0,    0,    0],\n",
            "        [   7,  221,  197,  941, 4665,   42, 1669,  401,  756,  883,  111,   42,\n",
            "           22, 2463, 5407,  117,   38,   42,  941,   64, 1155,  576,    2,    2,\n",
            "            2,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 164,    7,  198, 1112,    7,  784,   22,    7,  197,  339, 4666,   52,\n",
            "           45,   17,  828,   91,   12,   17,  509,   87,    2,    2,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [1190,   64,   81, 1385,  100,    3,  113,   42,  174,   63,  697,   53,\n",
            "         2307, 5444,   87,  160,   42,   33,    7,   68,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [  63,   87,   45, 1499,  152,  376,   39, 4028,  150,  127,  132,  231,\n",
            "          136,   19,   19,    9,  565,  456,  104,  954,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 127,  305,  248,   63, 1508,   42, 1657, 1014,  175,  353,  864,   87,\n",
            "           89,  335,  309,  756, 1033,   35,   64,    2,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [1057,  117,   38,   14, 4663, 2311,   65, 1525,    7, 1205,  229,   42,\n",
            "         3314,  526, 2330,  197,  526, 1478,    2,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [  10, 1488,    9, 1499,   63,  781, 1286,   64,  193, 1915,  222,  418,\n",
            "          663,   68,  149,   81,   65, 1513,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [  23,    3,   33,  221, 1508,   38, 1210,  856, 1897,  150,   39,   44,\n",
            "         2461,   63,   22,   45,   71,    2,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [  14,  622, 3241,  852,  886,    9,   64,  156,   10,  418,  265,   45,\n",
            "          136,    9, 1310,  248,    2,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 934,  232,   45, 2383,   64,  385,   68,   14,   38,   87,   35,  395,\n",
            "           89, 5119,  238, 4159,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   7,   87,   50,    7,   42,   14,  113, 2360,   33,  283,   14,  142,\n",
            "         5459,    2,    2,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [2794,  305,  231,  774, 1485,  801,  642,    3,   71, 1055, 1008,    9,\n",
            "            2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 132,  269,   31,    7,    3,  784,  232,  448,   45,  312, 2427,    2,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 106,   14,  335, 2683, 1501,   81,  113,   65,   53,    2,    2,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 805, 2168,   31,  522, 1364,   35, 2068,  881,  499,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [  21,   45,   42, 1311,  166,    7,  232,  418,    2,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [  42, 1135, 1405,  232, 1436,  526,  193,    2,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [1057,  124,   53,  124, 1496,  796,    2,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 874,   80,  245,  151,    2,    2,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 106,    7, 4580,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 871,   42,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [2437, 2329,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 232,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [2795,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]])\n",
            "lengths: tensor([31, 29, 27, 26, 25, 25, 24, 23, 22, 20, 20, 19, 18, 17, 17, 17, 15, 14,\n",
            "        12, 11,  8,  8,  7,  7,  7,  6,  6,  6,  5,  2,  2,  2])\n",
            "target_variable: tensor([[ 360,  139,  363,  925,  325,    3,   10,  549,   33,    3, 1008,  142,\n",
            "          699,  462,   68, 1242,   10,  549,  431,   21,  156,  127,   39,  748,\n",
            "           68, 3275,   23,    3,  325,  751,  750, 2386],\n",
            "        [   7,  739,   39,   42,   84,  805,  267, 4183,   71,  321,  150,    9,\n",
            "          109, 1248,   29,   44,   23,   68,   33,    9,  310,  169,  633,   81,\n",
            "           29,   33,    9,  301,  193, 1604,    2, 4677],\n",
            "        [ 193,    7,  708,  659,   38,   24,   20, 1675,   45,  307,  111,    3,\n",
            "          365,    2,   87,  214,  951,   29,  166,  735,   88,   31,  374,  232,\n",
            "          740,  121,  114,  338,   35,    2,    0,  127],\n",
            "        [  34, 1208,    7,  221,    9,   42, 1837,   11,   53,  267, 4666,  187,\n",
            "          277,    0,   65,  292,    9,  632,   57,  307,  632,  232, 1896,  113,\n",
            "         5208,  127,  670,   53,    7,    0,    0,  509],\n",
            "        [  35,   45,  482,  174,  482, 1122,  232,    7,  191,   49,  697,    2,\n",
            "            3,    0, 1497,   44,  255,  210,   45, 1004,   47,  771, 4518,   39,\n",
            "           63,  911,   45,  339,  193,    0,    0,   29],\n",
            "        [  14,   50,    9,  655,   35,    2,   29, 1082,  231,   14,    2,    0,\n",
            "          187,    0, 3712,   27, 5465,  743,  104,    3,   68,  150,  109,  201,\n",
            "         2999,  105, 1758,  310,    9,    0,    0,   98],\n",
            "        [1366,  109,  267,  662,  267,    0,    7,   68,  172,  353,    0,    0,\n",
            "           12,    0,    2,  214,    2,  277,   48,  560, 2175, 1498,   68,  758,\n",
            "          132,  509, 3501,  340, 1678,    0,    0, 2345],\n",
            "        [ 360,   75,    2,   44,  463,    0,  150,   91,   50, 1205,    0,    0,\n",
            "         2461,    0,    0,  371,    0,  187,   31,  743,    2,   29, 1749,  472,\n",
            "          106,  324,    2,   44,  876,    0,    0,   45],\n",
            "        [  37,    6,    0,  243,  827,    0,  227,   80,  231,  312,    0,    0,\n",
            "           31,    0,    0,    3,    0,    9,  269,  472,    0,   42,  313,   14,\n",
            "           99,   48,    0,  341,  252,    0,    0,  955],\n",
            "        [  10,    7,    0, 1081, 1016,    0,    7,   81,   37,  109,    0,    0,\n",
            "          269,    0,    0,   23,    0, 4523, 1034, 1636,    0,  214,  599, 2237,\n",
            "          307,    7,    0,   87,  111,    0,    0,    9],\n",
            "        [  38,  193,    0, 1206,   75,    0, 1208,   45,   10,  371,    0,    0,\n",
            "         2044,    0,    0,  214,    0,   42,  454,  225,    0,  274,    7,  723,\n",
            "          193,  121,    0,   42,   14,    0,    0,  187],\n",
            "        [   8,  111,    0,  852,   54,    0,   45,  191,   38,    3,    0,    0,\n",
            "           78,    0,    0,  805,    0, 2460,  127,  294,    0,  756,  285,    2,\n",
            "           14,  663,    0,  342, 1054,    0,    0,  150],\n",
            "        [   2, 4115,    0,    7,    7,    0, 1669, 3122,   72,  448,    0,    0,\n",
            "           88,    0,    0,   12,    0,   80, 1089, 2324,    0,  275,   81,    0,\n",
            "         5480,   10,    0,  343,  132,    0,    0,  841],\n",
            "        [   0,  255,    0,  774, 1244,    0,  160, 4524,   13,  232,    0,    0,\n",
            "          305,    0,    0,   87,    0,    2, 1158, 3485,    0,   87,   38,    0,\n",
            "          252,  187,    0,  313,    9,    0,    0,    7],\n",
            "        [   0,  191,    0,   42,   14,    0,    9,    2,   68, 3210,    0,    0,\n",
            "            2,    0,    0,   42,    0,    0,   29,  495,    0,   42,    3,    0,\n",
            "            2,  294,    0,  344,   11,    0,    0,  931],\n",
            "        [   0,  172,    0, 3544, 1245,    0,  227,    0,   18,  232,    0,    0,\n",
            "            0,    0,    0, 2999,    0,    0, 4559, 1040,    0,  268,  764,    0,\n",
            "            0,  232,    0,  345,  101,    0,    0,  255],\n",
            "        [   0,  241,    0,    7,   73,    0,    7,    0,  885,   29,    0,    0,\n",
            "            0,    0,    0, 1415,    0,    0,    7,   22,    0, 4449,  331,    0,\n",
            "            0,  529,    0,  243, 1644,    0,    0,  121],\n",
            "        [   0,  360,    0,   42,    2,    0,  196,    0,    2,    2,    0,    0,\n",
            "            0,    0,    0,    7,    0,    0, 2223,    3,    0,    2,   65,    0,\n",
            "            0,    2,    0,  346,    2,    0,    0,  331],\n",
            "        [   0, 4635,    0, 2683,    0,    0, 3926,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,   12,    0,    0, 1250, 1716,    0,    0,  191,    0,\n",
            "            0,    0,    0,    2,    0,    0,    0,  151],\n",
            "        [   0,    2,    0,  659,    0,    0, 1669,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0, 1232,    0,    0,    2,   68,    0,    0,  979,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,  949],\n",
            "        [   0,    0,    0,  660,    0,    0,   87,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,   27,    0,    0,    0, 1941,    0,    0,  360,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    2],\n",
            "        [   0,    0,    0,  124,    0,    0,   45,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,   28,    0,    0,    0,    2,    0,    0,    2,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   0,    0,    0, 1501,    0,    0, 1286,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,  136,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   0,    0,    0,    2,    0,    0,    2,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,  203,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,   35,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]])\n",
            "mask: tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True],\n",
            "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True],\n",
            "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         False,  True],\n",
            "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
            "         False,  True],\n",
            "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
            "         False,  True],\n",
            "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True, False,  True, False,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
            "         False,  True],\n",
            "        [ True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
            "         False, False,  True, False,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
            "         False,  True],\n",
            "        [ True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
            "         False, False,  True, False, False,  True, False,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
            "         False,  True],\n",
            "        [ True,  True, False,  True,  True, False,  True,  True,  True,  True,\n",
            "         False, False,  True, False, False,  True, False,  True,  True,  True,\n",
            "         False,  True,  True,  True,  True,  True, False,  True,  True, False,\n",
            "         False,  True],\n",
            "        [ True,  True, False,  True,  True, False,  True,  True,  True,  True,\n",
            "         False, False,  True, False, False,  True, False,  True,  True,  True,\n",
            "         False,  True,  True,  True,  True,  True, False,  True,  True, False,\n",
            "         False,  True],\n",
            "        [ True,  True, False,  True,  True, False,  True,  True,  True,  True,\n",
            "         False, False,  True, False, False,  True, False,  True,  True,  True,\n",
            "         False,  True,  True,  True,  True,  True, False,  True,  True, False,\n",
            "         False,  True],\n",
            "        [ True,  True, False,  True,  True, False,  True,  True,  True,  True,\n",
            "         False, False,  True, False, False,  True, False,  True,  True,  True,\n",
            "         False,  True,  True,  True,  True,  True, False,  True,  True, False,\n",
            "         False,  True],\n",
            "        [ True,  True, False,  True,  True, False,  True,  True,  True,  True,\n",
            "         False, False,  True, False, False,  True, False,  True,  True,  True,\n",
            "         False,  True,  True, False,  True,  True, False,  True,  True, False,\n",
            "         False,  True],\n",
            "        [False,  True, False,  True,  True, False,  True,  True,  True,  True,\n",
            "         False, False,  True, False, False,  True, False,  True,  True,  True,\n",
            "         False,  True,  True, False,  True,  True, False,  True,  True, False,\n",
            "         False,  True],\n",
            "        [False,  True, False,  True,  True, False,  True,  True,  True,  True,\n",
            "         False, False,  True, False, False,  True, False, False,  True,  True,\n",
            "         False,  True,  True, False,  True,  True, False,  True,  True, False,\n",
            "         False,  True],\n",
            "        [False,  True, False,  True,  True, False,  True, False,  True,  True,\n",
            "         False, False, False, False, False,  True, False, False,  True,  True,\n",
            "         False,  True,  True, False, False,  True, False,  True,  True, False,\n",
            "         False,  True],\n",
            "        [False,  True, False,  True,  True, False,  True, False,  True,  True,\n",
            "         False, False, False, False, False,  True, False, False,  True,  True,\n",
            "         False,  True,  True, False, False,  True, False,  True,  True, False,\n",
            "         False,  True],\n",
            "        [False,  True, False,  True,  True, False,  True, False,  True,  True,\n",
            "         False, False, False, False, False,  True, False, False,  True,  True,\n",
            "         False,  True,  True, False, False,  True, False,  True,  True, False,\n",
            "         False,  True],\n",
            "        [False,  True, False,  True, False, False,  True, False, False, False,\n",
            "         False, False, False, False, False,  True, False, False,  True,  True,\n",
            "         False, False,  True, False, False, False, False,  True, False, False,\n",
            "         False,  True],\n",
            "        [False,  True, False,  True, False, False,  True, False, False, False,\n",
            "         False, False, False, False, False,  True, False, False,  True,  True,\n",
            "         False, False,  True, False, False, False, False, False, False, False,\n",
            "         False,  True],\n",
            "        [False, False, False,  True, False, False,  True, False, False, False,\n",
            "         False, False, False, False, False,  True, False, False, False,  True,\n",
            "         False, False,  True, False, False, False, False, False, False, False,\n",
            "         False,  True],\n",
            "        [False, False, False,  True, False, False,  True, False, False, False,\n",
            "         False, False, False, False, False,  True, False, False, False,  True,\n",
            "         False, False,  True, False, False, False, False, False, False, False,\n",
            "         False, False],\n",
            "        [False, False, False,  True, False, False,  True, False, False, False,\n",
            "         False, False, False, False, False,  True, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False],\n",
            "        [False, False, False,  True, False, False,  True, False, False, False,\n",
            "         False, False, False, False, False,  True, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False,  True, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False,  True, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False]])\n",
            "max_target_len: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfHcSR353Vmx"
      },
      "source": [
        "## Seq2seq models for chatbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uEugQMF3Noz"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    \"\"\"GRU Encoder\"\"\"\n",
        "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = embedding\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        embedded = self.embedding(input_seq)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
        "        return outputs, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b2uv8yd3sIt"
      },
      "source": [
        "class Attn(nn.Module):\n",
        "    \"\"\"Luong attention layer\"\"\"\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        self.method = method\n",
        "        if self.method not in ['dot', 'general', 'concat']:\n",
        "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
        "        self.hidden_size = hidden_size\n",
        "        if self.method == 'general':\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "        elif self.method == 'concat':\n",
        "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "    def dot_score(self, hidden, encoder_output):\n",
        "        return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "    def general_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(encoder_output)\n",
        "        return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "    def concat_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "        return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # Calculate the attention weights (energies) based on the given method\n",
        "        if self.method == 'general':\n",
        "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'concat':\n",
        "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'dot':\n",
        "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "        # Transpose max_length and batch_size dimensions\n",
        "        attn_energies = attn_energies.t()\n",
        "\n",
        "        # Return the softmax normalized probability scores (with added dimension)\n",
        "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxeYWOQ336s6"
      },
      "source": [
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "    \"\"\"Decoder based in Luong Attention\"\"\"\n",
        "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
        "        super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Keep for reference\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = embedding\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "        # Note: we run this one step (word) at a time\n",
        "        # Get embedding of current input word\n",
        "        embedded = self.embedding(input_step)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "        # Forward through unidirectional GRU\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "        # Calculate attention weights from the current GRU output\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "        # Predict next word using Luong eq. 6\n",
        "        output = self.out(concat_output)\n",
        "        output = F.softmax(output, dim=1)\n",
        "        # Return output and final hidden state\n",
        "        return output, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2qqz12D4NWP"
      },
      "source": [
        "## Masked Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0VcZGIL4HzW"
      },
      "source": [
        "def maskNLLLoss(inp, target, mask):\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
        "    loss = crossEntropy.masked_select(mask).mean()\n",
        "    loss = loss.to(device)\n",
        "    return loss, nTotal.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77RNcbws4Ztu"
      },
      "source": [
        "## Training procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGTzunYv4O2R"
      },
      "source": [
        "# Single iteration\n",
        "\n",
        "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
        "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
        "\n",
        "    # Zero gradients\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # Set device options\n",
        "    input_variable = input_variable.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "    mask = mask.to(device)\n",
        "    # Lengths for rnn packing should always be on the cpu\n",
        "    lengths = lengths.to(\"cpu\")\n",
        "\n",
        "    # Initialize variables\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "\n",
        "    # Forward pass through encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "\n",
        "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
        "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # Set initial decoder hidden state to the encoder's final hidden state\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "    # Determine if we are using teacher forcing this iteration\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    # Forward batch of sequences through decoder one time step at a time\n",
        "    if use_teacher_forcing:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # Teacher forcing: next input is current target\n",
        "            decoder_input = target_variable[t].view(1, -1)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    else:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # No teacher forcing: next input is decoder's own current output\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "    # Perform backpropatation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip gradients: gradients are modified in place\n",
        "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "    # Adjust model weights\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return sum(print_losses) / n_totals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T938NAIR4eqs"
      },
      "source": [
        "# Training iterations\n",
        "\n",
        "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
        "\n",
        "    # Load batches for each iteration\n",
        "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
        "                      for _ in range(n_iteration)]\n",
        "\n",
        "    # Initializations\n",
        "    print('Initializing ...')\n",
        "    start_iteration = 1\n",
        "    print_loss = 0\n",
        "    if loadFilename:\n",
        "        start_iteration = checkpoint['iteration'] + 1\n",
        "\n",
        "    # Training loop\n",
        "    print(\"Training...\")\n",
        "    for iteration in range(start_iteration, n_iteration + 1):\n",
        "        training_batch = training_batches[iteration - 1]\n",
        "        # Extract fields from batch\n",
        "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
        "\n",
        "        # Run a training iteration with batch\n",
        "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
        "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
        "        print_loss += loss\n",
        "\n",
        "        # Print progress\n",
        "        if iteration % print_every == 0:\n",
        "            print_loss_avg = print_loss / print_every\n",
        "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
        "            print_loss = 0\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (iteration % save_every == 0):\n",
        "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "            torch.save({\n",
        "                'iteration': iteration,\n",
        "                'en': encoder.state_dict(),\n",
        "                'de': decoder.state_dict(),\n",
        "                'en_opt': encoder_optimizer.state_dict(),\n",
        "                'de_opt': decoder_optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                'voc_dict': voc.__dict__,\n",
        "                'embedding': embedding.state_dict()\n",
        "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kINUv78044G-"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkYn7Z2D4tt_"
      },
      "source": [
        "class GreedySearchDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(GreedySearchDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, input_seq, input_length, max_length):\n",
        "        # Forward input through encoder model\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
        "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
        "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "        # Initialize decoder input with SOS_token\n",
        "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
        "        # Initialize tensors to append decoded words to\n",
        "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
        "        all_scores = torch.zeros([0], device=device)\n",
        "        # Iteratively decode one word token at a time\n",
        "        for _ in range(max_length):\n",
        "            # Forward pass through decoder\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # Obtain most likely word token and its softmax score\n",
        "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "            # Record token and score\n",
        "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
        "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
        "            # Prepare current token to be next decoder input (add a dimension)\n",
        "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "        # Return collections of word tokens and scores\n",
        "        return all_tokens, all_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtTkn_Yu4_Ry"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPumkYg346Im"
      },
      "source": [
        "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
        "    ### Format input sentence as a batch\n",
        "    # words -> indexes\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
        "    # Create lengths tensor\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    # Transpose dimensions of batch to match models' expectations\n",
        "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
        "    # Use appropriate device\n",
        "    input_batch = input_batch.to(device)\n",
        "    lengths = lengths.to(\"cpu\")\n",
        "    # Decode sentence with searcher\n",
        "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
        "    # indexes -> words\n",
        "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
        "    return decoded_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9okZ5KAC5ENq"
      },
      "source": [
        "def evaluateInput(encoder, decoder, searcher, voc):\n",
        "    input_sentence = ''\n",
        "    while(1):\n",
        "        try:\n",
        "            # Get input sentence\n",
        "            input_sentence = input('$ ')\n",
        "            # Check if it is quit case\n",
        "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
        "            # Normalize sentence\n",
        "            input_sentence = normalizeString(input_sentence)\n",
        "            # Evaluate sentence\n",
        "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
        "            # Format and print response sentence\n",
        "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "            print('Jarvis:', ' '.join(output_words))\n",
        "\n",
        "        except KeyError:\n",
        "            print(\"Jarvis: Sorry, I cannot understand your question. Try again.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3-PO1DL5rEz"
      },
      "source": [
        "## Running the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_7taX795noS"
      },
      "source": [
        "model_name = 'cb_model'\n",
        "attn_model = 'dot'\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tEHP6LJ53d-"
      },
      "source": [
        "loadFilename = None\n",
        "checkpoint_iter = 4000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkbGztJF569o"
      },
      "source": [
        "if loadFilename:\n",
        "    # If loading on same machine the model was trained on\n",
        "    # checkpoint = torch.load(loadFilename)\n",
        "    # If loading a model trained on GPU to CPU\n",
        "    checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
        "    encoder_sd = checkpoint['en']\n",
        "    decoder_sd = checkpoint['de']\n",
        "    encoder_optimizer_sd = checkpoint['en_opt']\n",
        "    decoder_optimizer_sd = checkpoint['de_opt']\n",
        "    embedding_sd = checkpoint['embedding']\n",
        "    voc.__dict__ = checkpoint['voc_dict']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TufKEDyf6X1e",
        "outputId": "865a09b3-3020-44e0-ff1d-84798a5063be"
      },
      "source": [
        "print('Building encoder and decoder ...')\n",
        "# Initialize word embeddings\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "if loadFilename:\n",
        "    embedding.load_state_dict(embedding_sd)\n",
        "# Initialize encoder & decoder models\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "if loadFilename:\n",
        "    encoder.load_state_dict(encoder_sd)\n",
        "    decoder.load_state_dict(decoder_sd)\n",
        "# Use appropriate device\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "print('Models built and ready to go!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US7P4H1T6Icr",
        "outputId": "4ed71bed-cab1-4799-efaf-6d78e5740e83"
      },
      "source": [
        "# Configure training/optimization\n",
        "clip = 50.0\n",
        "teacher_forcing_ratio = 1.0\n",
        "learning_rate = 0.0001\n",
        "decoder_learning_ratio = 5.0\n",
        "n_iteration = 4000\n",
        "print_every = 1\n",
        "save_every = 500\n",
        "\n",
        "# Ensure dropout layers are in train mode\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "# Initialize optimizers\n",
        "print('Building optimizers ...')\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "if loadFilename:\n",
        "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
        "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
        "\n",
        "# If you have cuda, configure cuda to call\n",
        "for state in encoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "\n",
        "for state in decoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "    \n",
        "# Run training iterations\n",
        "print(\"Starting Training!\")\n",
        "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
        "           print_every, save_every, clip, corpus_name, loadFilename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1; Percent complete: 0.0%; Average loss: 8.6167\n",
            "Iteration: 2; Percent complete: 0.1%; Average loss: 8.5979\n",
            "Iteration: 3; Percent complete: 0.1%; Average loss: 8.5695\n",
            "Iteration: 4; Percent complete: 0.1%; Average loss: 8.5201\n",
            "Iteration: 5; Percent complete: 0.1%; Average loss: 8.4444\n",
            "Iteration: 6; Percent complete: 0.1%; Average loss: 8.3209\n",
            "Iteration: 7; Percent complete: 0.2%; Average loss: 8.0719\n",
            "Iteration: 8; Percent complete: 0.2%; Average loss: 7.7820\n",
            "Iteration: 9; Percent complete: 0.2%; Average loss: 7.5963\n",
            "Iteration: 10; Percent complete: 0.2%; Average loss: 7.4436\n",
            "Iteration: 11; Percent complete: 0.3%; Average loss: 7.4978\n",
            "Iteration: 12; Percent complete: 0.3%; Average loss: 7.3218\n",
            "Iteration: 13; Percent complete: 0.3%; Average loss: 7.0750\n",
            "Iteration: 14; Percent complete: 0.4%; Average loss: 6.7507\n",
            "Iteration: 15; Percent complete: 0.4%; Average loss: 6.4841\n",
            "Iteration: 16; Percent complete: 0.4%; Average loss: 6.3369\n",
            "Iteration: 17; Percent complete: 0.4%; Average loss: 6.2990\n",
            "Iteration: 18; Percent complete: 0.4%; Average loss: 6.3362\n",
            "Iteration: 19; Percent complete: 0.5%; Average loss: 6.2170\n",
            "Iteration: 20; Percent complete: 0.5%; Average loss: 6.1181\n",
            "Iteration: 21; Percent complete: 0.5%; Average loss: 6.2514\n",
            "Iteration: 22; Percent complete: 0.5%; Average loss: 6.1297\n",
            "Iteration: 23; Percent complete: 0.6%; Average loss: 6.3105\n",
            "Iteration: 24; Percent complete: 0.6%; Average loss: 6.0467\n",
            "Iteration: 25; Percent complete: 0.6%; Average loss: 6.3631\n",
            "Iteration: 26; Percent complete: 0.7%; Average loss: 6.2350\n",
            "Iteration: 27; Percent complete: 0.7%; Average loss: 6.0176\n",
            "Iteration: 28; Percent complete: 0.7%; Average loss: 6.2800\n",
            "Iteration: 29; Percent complete: 0.7%; Average loss: 6.0201\n",
            "Iteration: 30; Percent complete: 0.8%; Average loss: 6.1409\n",
            "Iteration: 31; Percent complete: 0.8%; Average loss: 6.3419\n",
            "Iteration: 32; Percent complete: 0.8%; Average loss: 6.2324\n",
            "Iteration: 33; Percent complete: 0.8%; Average loss: 6.3058\n",
            "Iteration: 34; Percent complete: 0.9%; Average loss: 6.0719\n",
            "Iteration: 35; Percent complete: 0.9%; Average loss: 6.2069\n",
            "Iteration: 36; Percent complete: 0.9%; Average loss: 6.1996\n",
            "Iteration: 37; Percent complete: 0.9%; Average loss: 6.2332\n",
            "Iteration: 38; Percent complete: 0.9%; Average loss: 5.9926\n",
            "Iteration: 39; Percent complete: 1.0%; Average loss: 6.0985\n",
            "Iteration: 40; Percent complete: 1.0%; Average loss: 6.0885\n",
            "Iteration: 41; Percent complete: 1.0%; Average loss: 6.0963\n",
            "Iteration: 42; Percent complete: 1.1%; Average loss: 6.1738\n",
            "Iteration: 43; Percent complete: 1.1%; Average loss: 6.2283\n",
            "Iteration: 44; Percent complete: 1.1%; Average loss: 6.0842\n",
            "Iteration: 45; Percent complete: 1.1%; Average loss: 6.2253\n",
            "Iteration: 46; Percent complete: 1.1%; Average loss: 6.0885\n",
            "Iteration: 47; Percent complete: 1.2%; Average loss: 6.1324\n",
            "Iteration: 48; Percent complete: 1.2%; Average loss: 6.0230\n",
            "Iteration: 49; Percent complete: 1.2%; Average loss: 5.9914\n",
            "Iteration: 50; Percent complete: 1.2%; Average loss: 6.0255\n",
            "Iteration: 51; Percent complete: 1.3%; Average loss: 6.0527\n",
            "Iteration: 52; Percent complete: 1.3%; Average loss: 6.0551\n",
            "Iteration: 53; Percent complete: 1.3%; Average loss: 6.1622\n",
            "Iteration: 54; Percent complete: 1.4%; Average loss: 6.0994\n",
            "Iteration: 55; Percent complete: 1.4%; Average loss: 6.2033\n",
            "Iteration: 56; Percent complete: 1.4%; Average loss: 6.1756\n",
            "Iteration: 57; Percent complete: 1.4%; Average loss: 6.1127\n",
            "Iteration: 58; Percent complete: 1.5%; Average loss: 6.1213\n",
            "Iteration: 59; Percent complete: 1.5%; Average loss: 6.1610\n",
            "Iteration: 60; Percent complete: 1.5%; Average loss: 6.0755\n",
            "Iteration: 61; Percent complete: 1.5%; Average loss: 6.0241\n",
            "Iteration: 62; Percent complete: 1.6%; Average loss: 6.0890\n",
            "Iteration: 63; Percent complete: 1.6%; Average loss: 6.1423\n",
            "Iteration: 64; Percent complete: 1.6%; Average loss: 6.1327\n",
            "Iteration: 65; Percent complete: 1.6%; Average loss: 6.3321\n",
            "Iteration: 66; Percent complete: 1.7%; Average loss: 6.0848\n",
            "Iteration: 67; Percent complete: 1.7%; Average loss: 6.2062\n",
            "Iteration: 68; Percent complete: 1.7%; Average loss: 6.0752\n",
            "Iteration: 69; Percent complete: 1.7%; Average loss: 6.2319\n",
            "Iteration: 70; Percent complete: 1.8%; Average loss: 6.0257\n",
            "Iteration: 71; Percent complete: 1.8%; Average loss: 5.8933\n",
            "Iteration: 72; Percent complete: 1.8%; Average loss: 6.0396\n",
            "Iteration: 73; Percent complete: 1.8%; Average loss: 6.1067\n",
            "Iteration: 74; Percent complete: 1.8%; Average loss: 5.9446\n",
            "Iteration: 75; Percent complete: 1.9%; Average loss: 6.0259\n",
            "Iteration: 76; Percent complete: 1.9%; Average loss: 6.1092\n",
            "Iteration: 77; Percent complete: 1.9%; Average loss: 6.1521\n",
            "Iteration: 78; Percent complete: 1.9%; Average loss: 6.1036\n",
            "Iteration: 79; Percent complete: 2.0%; Average loss: 5.8973\n",
            "Iteration: 80; Percent complete: 2.0%; Average loss: 6.0513\n",
            "Iteration: 81; Percent complete: 2.0%; Average loss: 5.8957\n",
            "Iteration: 82; Percent complete: 2.1%; Average loss: 6.1502\n",
            "Iteration: 83; Percent complete: 2.1%; Average loss: 5.9810\n",
            "Iteration: 84; Percent complete: 2.1%; Average loss: 6.0458\n",
            "Iteration: 85; Percent complete: 2.1%; Average loss: 5.9270\n",
            "Iteration: 86; Percent complete: 2.1%; Average loss: 5.9288\n",
            "Iteration: 87; Percent complete: 2.2%; Average loss: 5.9073\n",
            "Iteration: 88; Percent complete: 2.2%; Average loss: 5.7980\n",
            "Iteration: 89; Percent complete: 2.2%; Average loss: 5.9300\n",
            "Iteration: 90; Percent complete: 2.2%; Average loss: 6.1193\n",
            "Iteration: 91; Percent complete: 2.3%; Average loss: 5.9128\n",
            "Iteration: 92; Percent complete: 2.3%; Average loss: 6.1141\n",
            "Iteration: 93; Percent complete: 2.3%; Average loss: 5.9907\n",
            "Iteration: 94; Percent complete: 2.4%; Average loss: 5.9252\n",
            "Iteration: 95; Percent complete: 2.4%; Average loss: 5.8848\n",
            "Iteration: 96; Percent complete: 2.4%; Average loss: 5.8095\n",
            "Iteration: 97; Percent complete: 2.4%; Average loss: 6.0231\n",
            "Iteration: 98; Percent complete: 2.5%; Average loss: 5.9914\n",
            "Iteration: 99; Percent complete: 2.5%; Average loss: 5.9310\n",
            "Iteration: 100; Percent complete: 2.5%; Average loss: 5.9625\n",
            "Iteration: 101; Percent complete: 2.5%; Average loss: 5.8250\n",
            "Iteration: 102; Percent complete: 2.5%; Average loss: 5.9173\n",
            "Iteration: 103; Percent complete: 2.6%; Average loss: 5.7606\n",
            "Iteration: 104; Percent complete: 2.6%; Average loss: 5.8328\n",
            "Iteration: 105; Percent complete: 2.6%; Average loss: 5.9143\n",
            "Iteration: 106; Percent complete: 2.6%; Average loss: 5.9152\n",
            "Iteration: 107; Percent complete: 2.7%; Average loss: 5.7871\n",
            "Iteration: 108; Percent complete: 2.7%; Average loss: 5.8269\n",
            "Iteration: 109; Percent complete: 2.7%; Average loss: 5.9235\n",
            "Iteration: 110; Percent complete: 2.8%; Average loss: 5.8320\n",
            "Iteration: 111; Percent complete: 2.8%; Average loss: 5.7901\n",
            "Iteration: 112; Percent complete: 2.8%; Average loss: 6.0031\n",
            "Iteration: 113; Percent complete: 2.8%; Average loss: 5.8517\n",
            "Iteration: 114; Percent complete: 2.9%; Average loss: 5.8599\n",
            "Iteration: 115; Percent complete: 2.9%; Average loss: 5.6200\n",
            "Iteration: 116; Percent complete: 2.9%; Average loss: 5.6572\n",
            "Iteration: 117; Percent complete: 2.9%; Average loss: 5.6951\n",
            "Iteration: 118; Percent complete: 2.9%; Average loss: 5.8394\n",
            "Iteration: 119; Percent complete: 3.0%; Average loss: 5.7348\n",
            "Iteration: 120; Percent complete: 3.0%; Average loss: 5.7237\n",
            "Iteration: 121; Percent complete: 3.0%; Average loss: 5.7121\n",
            "Iteration: 122; Percent complete: 3.0%; Average loss: 5.8225\n",
            "Iteration: 123; Percent complete: 3.1%; Average loss: 5.6795\n",
            "Iteration: 124; Percent complete: 3.1%; Average loss: 5.8407\n",
            "Iteration: 125; Percent complete: 3.1%; Average loss: 5.5995\n",
            "Iteration: 126; Percent complete: 3.1%; Average loss: 5.7468\n",
            "Iteration: 127; Percent complete: 3.2%; Average loss: 5.5852\n",
            "Iteration: 128; Percent complete: 3.2%; Average loss: 5.9877\n",
            "Iteration: 129; Percent complete: 3.2%; Average loss: 5.6663\n",
            "Iteration: 130; Percent complete: 3.2%; Average loss: 5.8151\n",
            "Iteration: 131; Percent complete: 3.3%; Average loss: 5.7455\n",
            "Iteration: 132; Percent complete: 3.3%; Average loss: 5.6278\n",
            "Iteration: 133; Percent complete: 3.3%; Average loss: 5.7871\n",
            "Iteration: 134; Percent complete: 3.4%; Average loss: 5.6707\n",
            "Iteration: 135; Percent complete: 3.4%; Average loss: 5.3956\n",
            "Iteration: 136; Percent complete: 3.4%; Average loss: 5.4151\n",
            "Iteration: 137; Percent complete: 3.4%; Average loss: 5.5257\n",
            "Iteration: 138; Percent complete: 3.5%; Average loss: 5.6471\n",
            "Iteration: 139; Percent complete: 3.5%; Average loss: 5.6021\n",
            "Iteration: 140; Percent complete: 3.5%; Average loss: 5.5920\n",
            "Iteration: 141; Percent complete: 3.5%; Average loss: 5.5854\n",
            "Iteration: 142; Percent complete: 3.5%; Average loss: 5.6739\n",
            "Iteration: 143; Percent complete: 3.6%; Average loss: 5.5079\n",
            "Iteration: 144; Percent complete: 3.6%; Average loss: 5.5608\n",
            "Iteration: 145; Percent complete: 3.6%; Average loss: 5.5216\n",
            "Iteration: 146; Percent complete: 3.6%; Average loss: 5.4428\n",
            "Iteration: 147; Percent complete: 3.7%; Average loss: 5.3641\n",
            "Iteration: 148; Percent complete: 3.7%; Average loss: 5.4284\n",
            "Iteration: 149; Percent complete: 3.7%; Average loss: 5.5823\n",
            "Iteration: 150; Percent complete: 3.8%; Average loss: 5.4157\n",
            "Iteration: 151; Percent complete: 3.8%; Average loss: 5.3936\n",
            "Iteration: 152; Percent complete: 3.8%; Average loss: 5.6540\n",
            "Iteration: 153; Percent complete: 3.8%; Average loss: 5.4992\n",
            "Iteration: 154; Percent complete: 3.9%; Average loss: 5.4338\n",
            "Iteration: 155; Percent complete: 3.9%; Average loss: 5.8266\n",
            "Iteration: 156; Percent complete: 3.9%; Average loss: 5.4754\n",
            "Iteration: 157; Percent complete: 3.9%; Average loss: 5.4897\n",
            "Iteration: 158; Percent complete: 4.0%; Average loss: 5.4063\n",
            "Iteration: 159; Percent complete: 4.0%; Average loss: 5.4289\n",
            "Iteration: 160; Percent complete: 4.0%; Average loss: 5.5146\n",
            "Iteration: 161; Percent complete: 4.0%; Average loss: 5.3257\n",
            "Iteration: 162; Percent complete: 4.0%; Average loss: 5.4446\n",
            "Iteration: 163; Percent complete: 4.1%; Average loss: 5.4721\n",
            "Iteration: 164; Percent complete: 4.1%; Average loss: 5.4616\n",
            "Iteration: 165; Percent complete: 4.1%; Average loss: 5.2763\n",
            "Iteration: 166; Percent complete: 4.2%; Average loss: 5.3943\n",
            "Iteration: 167; Percent complete: 4.2%; Average loss: 5.3105\n",
            "Iteration: 168; Percent complete: 4.2%; Average loss: 5.3502\n",
            "Iteration: 169; Percent complete: 4.2%; Average loss: 5.4946\n",
            "Iteration: 170; Percent complete: 4.2%; Average loss: 5.2438\n",
            "Iteration: 171; Percent complete: 4.3%; Average loss: 5.3062\n",
            "Iteration: 172; Percent complete: 4.3%; Average loss: 5.2801\n",
            "Iteration: 173; Percent complete: 4.3%; Average loss: 5.0530\n",
            "Iteration: 174; Percent complete: 4.3%; Average loss: 5.5320\n",
            "Iteration: 175; Percent complete: 4.4%; Average loss: 5.4904\n",
            "Iteration: 176; Percent complete: 4.4%; Average loss: 5.3107\n",
            "Iteration: 177; Percent complete: 4.4%; Average loss: 5.4320\n",
            "Iteration: 178; Percent complete: 4.5%; Average loss: 5.2894\n",
            "Iteration: 179; Percent complete: 4.5%; Average loss: 5.3710\n",
            "Iteration: 180; Percent complete: 4.5%; Average loss: 5.0080\n",
            "Iteration: 181; Percent complete: 4.5%; Average loss: 5.2222\n",
            "Iteration: 182; Percent complete: 4.5%; Average loss: 5.3033\n",
            "Iteration: 183; Percent complete: 4.6%; Average loss: 5.3893\n",
            "Iteration: 184; Percent complete: 4.6%; Average loss: 5.1821\n",
            "Iteration: 185; Percent complete: 4.6%; Average loss: 5.3221\n",
            "Iteration: 186; Percent complete: 4.7%; Average loss: 5.1369\n",
            "Iteration: 187; Percent complete: 4.7%; Average loss: 5.2263\n",
            "Iteration: 188; Percent complete: 4.7%; Average loss: 5.2228\n",
            "Iteration: 189; Percent complete: 4.7%; Average loss: 5.0513\n",
            "Iteration: 190; Percent complete: 4.8%; Average loss: 5.1854\n",
            "Iteration: 191; Percent complete: 4.8%; Average loss: 5.3085\n",
            "Iteration: 192; Percent complete: 4.8%; Average loss: 5.1063\n",
            "Iteration: 193; Percent complete: 4.8%; Average loss: 5.4301\n",
            "Iteration: 194; Percent complete: 4.9%; Average loss: 5.2666\n",
            "Iteration: 195; Percent complete: 4.9%; Average loss: 5.0759\n",
            "Iteration: 196; Percent complete: 4.9%; Average loss: 5.2721\n",
            "Iteration: 197; Percent complete: 4.9%; Average loss: 4.8881\n",
            "Iteration: 198; Percent complete: 5.0%; Average loss: 5.1243\n",
            "Iteration: 199; Percent complete: 5.0%; Average loss: 5.1648\n",
            "Iteration: 200; Percent complete: 5.0%; Average loss: 5.3171\n",
            "Iteration: 201; Percent complete: 5.0%; Average loss: 4.9951\n",
            "Iteration: 202; Percent complete: 5.1%; Average loss: 5.3847\n",
            "Iteration: 203; Percent complete: 5.1%; Average loss: 4.8862\n",
            "Iteration: 204; Percent complete: 5.1%; Average loss: 5.1484\n",
            "Iteration: 205; Percent complete: 5.1%; Average loss: 5.1363\n",
            "Iteration: 206; Percent complete: 5.1%; Average loss: 5.3681\n",
            "Iteration: 207; Percent complete: 5.2%; Average loss: 5.0221\n",
            "Iteration: 208; Percent complete: 5.2%; Average loss: 5.0735\n",
            "Iteration: 209; Percent complete: 5.2%; Average loss: 5.0596\n",
            "Iteration: 210; Percent complete: 5.2%; Average loss: 5.0560\n",
            "Iteration: 211; Percent complete: 5.3%; Average loss: 5.0839\n",
            "Iteration: 212; Percent complete: 5.3%; Average loss: 4.9934\n",
            "Iteration: 213; Percent complete: 5.3%; Average loss: 5.1380\n",
            "Iteration: 214; Percent complete: 5.3%; Average loss: 5.0855\n",
            "Iteration: 215; Percent complete: 5.4%; Average loss: 5.0974\n",
            "Iteration: 216; Percent complete: 5.4%; Average loss: 5.3193\n",
            "Iteration: 217; Percent complete: 5.4%; Average loss: 5.1983\n",
            "Iteration: 218; Percent complete: 5.5%; Average loss: 5.0301\n",
            "Iteration: 219; Percent complete: 5.5%; Average loss: 5.1345\n",
            "Iteration: 220; Percent complete: 5.5%; Average loss: 5.3092\n",
            "Iteration: 221; Percent complete: 5.5%; Average loss: 5.3248\n",
            "Iteration: 222; Percent complete: 5.5%; Average loss: 4.9377\n",
            "Iteration: 223; Percent complete: 5.6%; Average loss: 4.8580\n",
            "Iteration: 224; Percent complete: 5.6%; Average loss: 5.0038\n",
            "Iteration: 225; Percent complete: 5.6%; Average loss: 4.9891\n",
            "Iteration: 226; Percent complete: 5.7%; Average loss: 5.0934\n",
            "Iteration: 227; Percent complete: 5.7%; Average loss: 5.1711\n",
            "Iteration: 228; Percent complete: 5.7%; Average loss: 4.9122\n",
            "Iteration: 229; Percent complete: 5.7%; Average loss: 4.8179\n",
            "Iteration: 230; Percent complete: 5.8%; Average loss: 5.0462\n",
            "Iteration: 231; Percent complete: 5.8%; Average loss: 5.1024\n",
            "Iteration: 232; Percent complete: 5.8%; Average loss: 4.9783\n",
            "Iteration: 233; Percent complete: 5.8%; Average loss: 4.8628\n",
            "Iteration: 234; Percent complete: 5.9%; Average loss: 5.0385\n",
            "Iteration: 235; Percent complete: 5.9%; Average loss: 4.9411\n",
            "Iteration: 236; Percent complete: 5.9%; Average loss: 4.7900\n",
            "Iteration: 237; Percent complete: 5.9%; Average loss: 5.2023\n",
            "Iteration: 238; Percent complete: 5.9%; Average loss: 4.9647\n",
            "Iteration: 239; Percent complete: 6.0%; Average loss: 5.0083\n",
            "Iteration: 240; Percent complete: 6.0%; Average loss: 4.9136\n",
            "Iteration: 241; Percent complete: 6.0%; Average loss: 5.1444\n",
            "Iteration: 242; Percent complete: 6.0%; Average loss: 4.8508\n",
            "Iteration: 243; Percent complete: 6.1%; Average loss: 4.7577\n",
            "Iteration: 244; Percent complete: 6.1%; Average loss: 4.6648\n",
            "Iteration: 245; Percent complete: 6.1%; Average loss: 5.1635\n",
            "Iteration: 246; Percent complete: 6.2%; Average loss: 5.1344\n",
            "Iteration: 247; Percent complete: 6.2%; Average loss: 4.6839\n",
            "Iteration: 248; Percent complete: 6.2%; Average loss: 4.8182\n",
            "Iteration: 249; Percent complete: 6.2%; Average loss: 4.9818\n",
            "Iteration: 250; Percent complete: 6.2%; Average loss: 5.1541\n",
            "Iteration: 251; Percent complete: 6.3%; Average loss: 5.3275\n",
            "Iteration: 252; Percent complete: 6.3%; Average loss: 4.9176\n",
            "Iteration: 253; Percent complete: 6.3%; Average loss: 4.6289\n",
            "Iteration: 254; Percent complete: 6.3%; Average loss: 4.7317\n",
            "Iteration: 255; Percent complete: 6.4%; Average loss: 4.7031\n",
            "Iteration: 256; Percent complete: 6.4%; Average loss: 5.1108\n",
            "Iteration: 257; Percent complete: 6.4%; Average loss: 5.1054\n",
            "Iteration: 258; Percent complete: 6.5%; Average loss: 5.1102\n",
            "Iteration: 259; Percent complete: 6.5%; Average loss: 4.8572\n",
            "Iteration: 260; Percent complete: 6.5%; Average loss: 5.2177\n",
            "Iteration: 261; Percent complete: 6.5%; Average loss: 5.1260\n",
            "Iteration: 262; Percent complete: 6.6%; Average loss: 4.9103\n",
            "Iteration: 263; Percent complete: 6.6%; Average loss: 4.9349\n",
            "Iteration: 264; Percent complete: 6.6%; Average loss: 4.6943\n",
            "Iteration: 265; Percent complete: 6.6%; Average loss: 4.5169\n",
            "Iteration: 266; Percent complete: 6.7%; Average loss: 4.8343\n",
            "Iteration: 267; Percent complete: 6.7%; Average loss: 4.9719\n",
            "Iteration: 268; Percent complete: 6.7%; Average loss: 4.7902\n",
            "Iteration: 269; Percent complete: 6.7%; Average loss: 4.5905\n",
            "Iteration: 270; Percent complete: 6.8%; Average loss: 5.0282\n",
            "Iteration: 271; Percent complete: 6.8%; Average loss: 4.8870\n",
            "Iteration: 272; Percent complete: 6.8%; Average loss: 4.8675\n",
            "Iteration: 273; Percent complete: 6.8%; Average loss: 4.5840\n",
            "Iteration: 274; Percent complete: 6.9%; Average loss: 4.6862\n",
            "Iteration: 275; Percent complete: 6.9%; Average loss: 4.8054\n",
            "Iteration: 276; Percent complete: 6.9%; Average loss: 4.7506\n",
            "Iteration: 277; Percent complete: 6.9%; Average loss: 4.8238\n",
            "Iteration: 278; Percent complete: 7.0%; Average loss: 4.8432\n",
            "Iteration: 279; Percent complete: 7.0%; Average loss: 4.9084\n",
            "Iteration: 280; Percent complete: 7.0%; Average loss: 4.7209\n",
            "Iteration: 281; Percent complete: 7.0%; Average loss: 4.9718\n",
            "Iteration: 282; Percent complete: 7.0%; Average loss: 4.7753\n",
            "Iteration: 283; Percent complete: 7.1%; Average loss: 5.1367\n",
            "Iteration: 284; Percent complete: 7.1%; Average loss: 4.9378\n",
            "Iteration: 285; Percent complete: 7.1%; Average loss: 4.8572\n",
            "Iteration: 286; Percent complete: 7.1%; Average loss: 4.9631\n",
            "Iteration: 287; Percent complete: 7.2%; Average loss: 4.6509\n",
            "Iteration: 288; Percent complete: 7.2%; Average loss: 4.6476\n",
            "Iteration: 289; Percent complete: 7.2%; Average loss: 4.9241\n",
            "Iteration: 290; Percent complete: 7.2%; Average loss: 5.1013\n",
            "Iteration: 291; Percent complete: 7.3%; Average loss: 4.4334\n",
            "Iteration: 292; Percent complete: 7.3%; Average loss: 4.5381\n",
            "Iteration: 293; Percent complete: 7.3%; Average loss: 4.5440\n",
            "Iteration: 294; Percent complete: 7.3%; Average loss: 4.6932\n",
            "Iteration: 295; Percent complete: 7.4%; Average loss: 4.7696\n",
            "Iteration: 296; Percent complete: 7.4%; Average loss: 4.7586\n",
            "Iteration: 297; Percent complete: 7.4%; Average loss: 4.9918\n",
            "Iteration: 298; Percent complete: 7.4%; Average loss: 4.7532\n",
            "Iteration: 299; Percent complete: 7.5%; Average loss: 4.9065\n",
            "Iteration: 300; Percent complete: 7.5%; Average loss: 4.7071\n",
            "Iteration: 301; Percent complete: 7.5%; Average loss: 4.7995\n",
            "Iteration: 302; Percent complete: 7.5%; Average loss: 4.7954\n",
            "Iteration: 303; Percent complete: 7.6%; Average loss: 4.9301\n",
            "Iteration: 304; Percent complete: 7.6%; Average loss: 4.8214\n",
            "Iteration: 305; Percent complete: 7.6%; Average loss: 4.5742\n",
            "Iteration: 306; Percent complete: 7.6%; Average loss: 4.4862\n",
            "Iteration: 307; Percent complete: 7.7%; Average loss: 4.6346\n",
            "Iteration: 308; Percent complete: 7.7%; Average loss: 4.8908\n",
            "Iteration: 309; Percent complete: 7.7%; Average loss: 4.6697\n",
            "Iteration: 310; Percent complete: 7.8%; Average loss: 4.6511\n",
            "Iteration: 311; Percent complete: 7.8%; Average loss: 4.5721\n",
            "Iteration: 312; Percent complete: 7.8%; Average loss: 4.8702\n",
            "Iteration: 313; Percent complete: 7.8%; Average loss: 4.9135\n",
            "Iteration: 314; Percent complete: 7.8%; Average loss: 4.4745\n",
            "Iteration: 315; Percent complete: 7.9%; Average loss: 4.6727\n",
            "Iteration: 316; Percent complete: 7.9%; Average loss: 4.7900\n",
            "Iteration: 317; Percent complete: 7.9%; Average loss: 4.7646\n",
            "Iteration: 318; Percent complete: 8.0%; Average loss: 4.5257\n",
            "Iteration: 319; Percent complete: 8.0%; Average loss: 4.8624\n",
            "Iteration: 320; Percent complete: 8.0%; Average loss: 4.6745\n",
            "Iteration: 321; Percent complete: 8.0%; Average loss: 4.7119\n",
            "Iteration: 322; Percent complete: 8.1%; Average loss: 4.7193\n",
            "Iteration: 323; Percent complete: 8.1%; Average loss: 4.5625\n",
            "Iteration: 324; Percent complete: 8.1%; Average loss: 4.6891\n",
            "Iteration: 325; Percent complete: 8.1%; Average loss: 4.3732\n",
            "Iteration: 326; Percent complete: 8.2%; Average loss: 4.7537\n",
            "Iteration: 327; Percent complete: 8.2%; Average loss: 4.7121\n",
            "Iteration: 328; Percent complete: 8.2%; Average loss: 4.5117\n",
            "Iteration: 329; Percent complete: 8.2%; Average loss: 4.5736\n",
            "Iteration: 330; Percent complete: 8.2%; Average loss: 4.7829\n",
            "Iteration: 331; Percent complete: 8.3%; Average loss: 4.6002\n",
            "Iteration: 332; Percent complete: 8.3%; Average loss: 4.7292\n",
            "Iteration: 333; Percent complete: 8.3%; Average loss: 4.4482\n",
            "Iteration: 334; Percent complete: 8.3%; Average loss: 4.7175\n",
            "Iteration: 335; Percent complete: 8.4%; Average loss: 4.9119\n",
            "Iteration: 336; Percent complete: 8.4%; Average loss: 4.7054\n",
            "Iteration: 337; Percent complete: 8.4%; Average loss: 4.9724\n",
            "Iteration: 338; Percent complete: 8.5%; Average loss: 4.3955\n",
            "Iteration: 339; Percent complete: 8.5%; Average loss: 4.8812\n",
            "Iteration: 340; Percent complete: 8.5%; Average loss: 4.8925\n",
            "Iteration: 341; Percent complete: 8.5%; Average loss: 5.0650\n",
            "Iteration: 342; Percent complete: 8.6%; Average loss: 4.4603\n",
            "Iteration: 343; Percent complete: 8.6%; Average loss: 4.7119\n",
            "Iteration: 344; Percent complete: 8.6%; Average loss: 4.5401\n",
            "Iteration: 345; Percent complete: 8.6%; Average loss: 4.7652\n",
            "Iteration: 346; Percent complete: 8.6%; Average loss: 4.4724\n",
            "Iteration: 347; Percent complete: 8.7%; Average loss: 4.2665\n",
            "Iteration: 348; Percent complete: 8.7%; Average loss: 4.3076\n",
            "Iteration: 349; Percent complete: 8.7%; Average loss: 4.5522\n",
            "Iteration: 350; Percent complete: 8.8%; Average loss: 4.4019\n",
            "Iteration: 351; Percent complete: 8.8%; Average loss: 4.5522\n",
            "Iteration: 352; Percent complete: 8.8%; Average loss: 4.7738\n",
            "Iteration: 353; Percent complete: 8.8%; Average loss: 4.7823\n",
            "Iteration: 354; Percent complete: 8.8%; Average loss: 4.4932\n",
            "Iteration: 355; Percent complete: 8.9%; Average loss: 4.6318\n",
            "Iteration: 356; Percent complete: 8.9%; Average loss: 4.1821\n",
            "Iteration: 357; Percent complete: 8.9%; Average loss: 4.4341\n",
            "Iteration: 358; Percent complete: 8.9%; Average loss: 4.7094\n",
            "Iteration: 359; Percent complete: 9.0%; Average loss: 4.7134\n",
            "Iteration: 360; Percent complete: 9.0%; Average loss: 4.6826\n",
            "Iteration: 361; Percent complete: 9.0%; Average loss: 4.5978\n",
            "Iteration: 362; Percent complete: 9.0%; Average loss: 4.3883\n",
            "Iteration: 363; Percent complete: 9.1%; Average loss: 4.4431\n",
            "Iteration: 364; Percent complete: 9.1%; Average loss: 4.3068\n",
            "Iteration: 365; Percent complete: 9.1%; Average loss: 4.2448\n",
            "Iteration: 366; Percent complete: 9.2%; Average loss: 4.7058\n",
            "Iteration: 367; Percent complete: 9.2%; Average loss: 4.7817\n",
            "Iteration: 368; Percent complete: 9.2%; Average loss: 4.5418\n",
            "Iteration: 369; Percent complete: 9.2%; Average loss: 4.9534\n",
            "Iteration: 370; Percent complete: 9.2%; Average loss: 4.6052\n",
            "Iteration: 371; Percent complete: 9.3%; Average loss: 4.6705\n",
            "Iteration: 372; Percent complete: 9.3%; Average loss: 4.4638\n",
            "Iteration: 373; Percent complete: 9.3%; Average loss: 4.4568\n",
            "Iteration: 374; Percent complete: 9.3%; Average loss: 4.2252\n",
            "Iteration: 375; Percent complete: 9.4%; Average loss: 4.4609\n",
            "Iteration: 376; Percent complete: 9.4%; Average loss: 4.5234\n",
            "Iteration: 377; Percent complete: 9.4%; Average loss: 4.4973\n",
            "Iteration: 378; Percent complete: 9.4%; Average loss: 4.7459\n",
            "Iteration: 379; Percent complete: 9.5%; Average loss: 4.3672\n",
            "Iteration: 380; Percent complete: 9.5%; Average loss: 4.3363\n",
            "Iteration: 381; Percent complete: 9.5%; Average loss: 4.3949\n",
            "Iteration: 382; Percent complete: 9.6%; Average loss: 4.1931\n",
            "Iteration: 383; Percent complete: 9.6%; Average loss: 4.3537\n",
            "Iteration: 384; Percent complete: 9.6%; Average loss: 4.4361\n",
            "Iteration: 385; Percent complete: 9.6%; Average loss: 4.3511\n",
            "Iteration: 386; Percent complete: 9.7%; Average loss: 4.5046\n",
            "Iteration: 387; Percent complete: 9.7%; Average loss: 4.3784\n",
            "Iteration: 388; Percent complete: 9.7%; Average loss: 4.3233\n",
            "Iteration: 389; Percent complete: 9.7%; Average loss: 4.4530\n",
            "Iteration: 390; Percent complete: 9.8%; Average loss: 4.5686\n",
            "Iteration: 391; Percent complete: 9.8%; Average loss: 4.4316\n",
            "Iteration: 392; Percent complete: 9.8%; Average loss: 4.4381\n",
            "Iteration: 393; Percent complete: 9.8%; Average loss: 4.4372\n",
            "Iteration: 394; Percent complete: 9.8%; Average loss: 4.3404\n",
            "Iteration: 395; Percent complete: 9.9%; Average loss: 4.5339\n",
            "Iteration: 396; Percent complete: 9.9%; Average loss: 4.5104\n",
            "Iteration: 397; Percent complete: 9.9%; Average loss: 4.6439\n",
            "Iteration: 398; Percent complete: 10.0%; Average loss: 4.8046\n",
            "Iteration: 399; Percent complete: 10.0%; Average loss: 4.3392\n",
            "Iteration: 400; Percent complete: 10.0%; Average loss: 4.5665\n",
            "Iteration: 401; Percent complete: 10.0%; Average loss: 4.3514\n",
            "Iteration: 402; Percent complete: 10.1%; Average loss: 4.3465\n",
            "Iteration: 403; Percent complete: 10.1%; Average loss: 4.4211\n",
            "Iteration: 404; Percent complete: 10.1%; Average loss: 4.4374\n",
            "Iteration: 405; Percent complete: 10.1%; Average loss: 4.4145\n",
            "Iteration: 406; Percent complete: 10.2%; Average loss: 4.5922\n",
            "Iteration: 407; Percent complete: 10.2%; Average loss: 4.5549\n",
            "Iteration: 408; Percent complete: 10.2%; Average loss: 4.5791\n",
            "Iteration: 409; Percent complete: 10.2%; Average loss: 4.4718\n",
            "Iteration: 410; Percent complete: 10.2%; Average loss: 4.3283\n",
            "Iteration: 411; Percent complete: 10.3%; Average loss: 4.5161\n",
            "Iteration: 412; Percent complete: 10.3%; Average loss: 4.4757\n",
            "Iteration: 413; Percent complete: 10.3%; Average loss: 4.3305\n",
            "Iteration: 414; Percent complete: 10.3%; Average loss: 4.6376\n",
            "Iteration: 415; Percent complete: 10.4%; Average loss: 4.2874\n",
            "Iteration: 416; Percent complete: 10.4%; Average loss: 4.6898\n",
            "Iteration: 417; Percent complete: 10.4%; Average loss: 4.0775\n",
            "Iteration: 418; Percent complete: 10.4%; Average loss: 4.4372\n",
            "Iteration: 419; Percent complete: 10.5%; Average loss: 4.3992\n",
            "Iteration: 420; Percent complete: 10.5%; Average loss: 4.3565\n",
            "Iteration: 421; Percent complete: 10.5%; Average loss: 4.3686\n",
            "Iteration: 422; Percent complete: 10.5%; Average loss: 4.3761\n",
            "Iteration: 423; Percent complete: 10.6%; Average loss: 4.0801\n",
            "Iteration: 424; Percent complete: 10.6%; Average loss: 4.1455\n",
            "Iteration: 425; Percent complete: 10.6%; Average loss: 4.2927\n",
            "Iteration: 426; Percent complete: 10.7%; Average loss: 4.2484\n",
            "Iteration: 427; Percent complete: 10.7%; Average loss: 4.4163\n",
            "Iteration: 428; Percent complete: 10.7%; Average loss: 4.7201\n",
            "Iteration: 429; Percent complete: 10.7%; Average loss: 4.4035\n",
            "Iteration: 430; Percent complete: 10.8%; Average loss: 4.2469\n",
            "Iteration: 431; Percent complete: 10.8%; Average loss: 4.3746\n",
            "Iteration: 432; Percent complete: 10.8%; Average loss: 3.9718\n",
            "Iteration: 433; Percent complete: 10.8%; Average loss: 4.7293\n",
            "Iteration: 434; Percent complete: 10.8%; Average loss: 4.5568\n",
            "Iteration: 435; Percent complete: 10.9%; Average loss: 4.3819\n",
            "Iteration: 436; Percent complete: 10.9%; Average loss: 4.5618\n",
            "Iteration: 437; Percent complete: 10.9%; Average loss: 4.4700\n",
            "Iteration: 438; Percent complete: 10.9%; Average loss: 4.3147\n",
            "Iteration: 439; Percent complete: 11.0%; Average loss: 4.3276\n",
            "Iteration: 440; Percent complete: 11.0%; Average loss: 4.6301\n",
            "Iteration: 441; Percent complete: 11.0%; Average loss: 4.4296\n",
            "Iteration: 442; Percent complete: 11.1%; Average loss: 4.0365\n",
            "Iteration: 443; Percent complete: 11.1%; Average loss: 4.2232\n",
            "Iteration: 444; Percent complete: 11.1%; Average loss: 4.2307\n",
            "Iteration: 445; Percent complete: 11.1%; Average loss: 4.5116\n",
            "Iteration: 446; Percent complete: 11.2%; Average loss: 4.4155\n",
            "Iteration: 447; Percent complete: 11.2%; Average loss: 4.4136\n",
            "Iteration: 448; Percent complete: 11.2%; Average loss: 4.1636\n",
            "Iteration: 449; Percent complete: 11.2%; Average loss: 4.4271\n",
            "Iteration: 450; Percent complete: 11.2%; Average loss: 3.9738\n",
            "Iteration: 451; Percent complete: 11.3%; Average loss: 4.3045\n",
            "Iteration: 452; Percent complete: 11.3%; Average loss: 4.4456\n",
            "Iteration: 453; Percent complete: 11.3%; Average loss: 4.4590\n",
            "Iteration: 454; Percent complete: 11.3%; Average loss: 4.2963\n",
            "Iteration: 455; Percent complete: 11.4%; Average loss: 4.2051\n",
            "Iteration: 456; Percent complete: 11.4%; Average loss: 4.2280\n",
            "Iteration: 457; Percent complete: 11.4%; Average loss: 4.2196\n",
            "Iteration: 458; Percent complete: 11.5%; Average loss: 4.1414\n",
            "Iteration: 459; Percent complete: 11.5%; Average loss: 4.3565\n",
            "Iteration: 460; Percent complete: 11.5%; Average loss: 4.2518\n",
            "Iteration: 461; Percent complete: 11.5%; Average loss: 4.5362\n",
            "Iteration: 462; Percent complete: 11.6%; Average loss: 3.9858\n",
            "Iteration: 463; Percent complete: 11.6%; Average loss: 4.6082\n",
            "Iteration: 464; Percent complete: 11.6%; Average loss: 4.2549\n",
            "Iteration: 465; Percent complete: 11.6%; Average loss: 4.0649\n",
            "Iteration: 466; Percent complete: 11.7%; Average loss: 4.1796\n",
            "Iteration: 467; Percent complete: 11.7%; Average loss: 4.5394\n",
            "Iteration: 468; Percent complete: 11.7%; Average loss: 4.2309\n",
            "Iteration: 469; Percent complete: 11.7%; Average loss: 4.2572\n",
            "Iteration: 470; Percent complete: 11.8%; Average loss: 4.3536\n",
            "Iteration: 471; Percent complete: 11.8%; Average loss: 4.3597\n",
            "Iteration: 472; Percent complete: 11.8%; Average loss: 4.2122\n",
            "Iteration: 473; Percent complete: 11.8%; Average loss: 4.5778\n",
            "Iteration: 474; Percent complete: 11.8%; Average loss: 4.4470\n",
            "Iteration: 475; Percent complete: 11.9%; Average loss: 4.1402\n",
            "Iteration: 476; Percent complete: 11.9%; Average loss: 4.1355\n",
            "Iteration: 477; Percent complete: 11.9%; Average loss: 4.4707\n",
            "Iteration: 478; Percent complete: 11.9%; Average loss: 4.2244\n",
            "Iteration: 479; Percent complete: 12.0%; Average loss: 4.2594\n",
            "Iteration: 480; Percent complete: 12.0%; Average loss: 4.1504\n",
            "Iteration: 481; Percent complete: 12.0%; Average loss: 4.6056\n",
            "Iteration: 482; Percent complete: 12.0%; Average loss: 3.8348\n",
            "Iteration: 483; Percent complete: 12.1%; Average loss: 4.2211\n",
            "Iteration: 484; Percent complete: 12.1%; Average loss: 4.3157\n",
            "Iteration: 485; Percent complete: 12.1%; Average loss: 4.3240\n",
            "Iteration: 486; Percent complete: 12.2%; Average loss: 4.2275\n",
            "Iteration: 487; Percent complete: 12.2%; Average loss: 4.0933\n",
            "Iteration: 488; Percent complete: 12.2%; Average loss: 4.1857\n",
            "Iteration: 489; Percent complete: 12.2%; Average loss: 4.3315\n",
            "Iteration: 490; Percent complete: 12.2%; Average loss: 4.4719\n",
            "Iteration: 491; Percent complete: 12.3%; Average loss: 4.3686\n",
            "Iteration: 492; Percent complete: 12.3%; Average loss: 4.2752\n",
            "Iteration: 493; Percent complete: 12.3%; Average loss: 4.1259\n",
            "Iteration: 494; Percent complete: 12.3%; Average loss: 4.2223\n",
            "Iteration: 495; Percent complete: 12.4%; Average loss: 3.9653\n",
            "Iteration: 496; Percent complete: 12.4%; Average loss: 4.4641\n",
            "Iteration: 497; Percent complete: 12.4%; Average loss: 4.1722\n",
            "Iteration: 498; Percent complete: 12.4%; Average loss: 4.1848\n",
            "Iteration: 499; Percent complete: 12.5%; Average loss: 4.3116\n",
            "Iteration: 500; Percent complete: 12.5%; Average loss: 4.0743\n",
            "Iteration: 501; Percent complete: 12.5%; Average loss: 4.0156\n",
            "Iteration: 502; Percent complete: 12.6%; Average loss: 4.3097\n",
            "Iteration: 503; Percent complete: 12.6%; Average loss: 4.4639\n",
            "Iteration: 504; Percent complete: 12.6%; Average loss: 4.0505\n",
            "Iteration: 505; Percent complete: 12.6%; Average loss: 4.0563\n",
            "Iteration: 506; Percent complete: 12.7%; Average loss: 3.9527\n",
            "Iteration: 507; Percent complete: 12.7%; Average loss: 4.1699\n",
            "Iteration: 508; Percent complete: 12.7%; Average loss: 3.9463\n",
            "Iteration: 509; Percent complete: 12.7%; Average loss: 4.3511\n",
            "Iteration: 510; Percent complete: 12.8%; Average loss: 4.2049\n",
            "Iteration: 511; Percent complete: 12.8%; Average loss: 4.2655\n",
            "Iteration: 512; Percent complete: 12.8%; Average loss: 4.1731\n",
            "Iteration: 513; Percent complete: 12.8%; Average loss: 3.9181\n",
            "Iteration: 514; Percent complete: 12.8%; Average loss: 4.1567\n",
            "Iteration: 515; Percent complete: 12.9%; Average loss: 4.2359\n",
            "Iteration: 516; Percent complete: 12.9%; Average loss: 4.1598\n",
            "Iteration: 517; Percent complete: 12.9%; Average loss: 4.2858\n",
            "Iteration: 518; Percent complete: 13.0%; Average loss: 4.1971\n",
            "Iteration: 519; Percent complete: 13.0%; Average loss: 4.0708\n",
            "Iteration: 520; Percent complete: 13.0%; Average loss: 4.2100\n",
            "Iteration: 521; Percent complete: 13.0%; Average loss: 3.9837\n",
            "Iteration: 522; Percent complete: 13.1%; Average loss: 4.5627\n",
            "Iteration: 523; Percent complete: 13.1%; Average loss: 4.3565\n",
            "Iteration: 524; Percent complete: 13.1%; Average loss: 4.0954\n",
            "Iteration: 525; Percent complete: 13.1%; Average loss: 4.0168\n",
            "Iteration: 526; Percent complete: 13.2%; Average loss: 3.9704\n",
            "Iteration: 527; Percent complete: 13.2%; Average loss: 3.9097\n",
            "Iteration: 528; Percent complete: 13.2%; Average loss: 4.2880\n",
            "Iteration: 529; Percent complete: 13.2%; Average loss: 4.4301\n",
            "Iteration: 530; Percent complete: 13.2%; Average loss: 3.9319\n",
            "Iteration: 531; Percent complete: 13.3%; Average loss: 3.9485\n",
            "Iteration: 532; Percent complete: 13.3%; Average loss: 4.3716\n",
            "Iteration: 533; Percent complete: 13.3%; Average loss: 4.1838\n",
            "Iteration: 534; Percent complete: 13.4%; Average loss: 4.4034\n",
            "Iteration: 535; Percent complete: 13.4%; Average loss: 3.9763\n",
            "Iteration: 536; Percent complete: 13.4%; Average loss: 4.0490\n",
            "Iteration: 537; Percent complete: 13.4%; Average loss: 4.2245\n",
            "Iteration: 538; Percent complete: 13.5%; Average loss: 3.9796\n",
            "Iteration: 539; Percent complete: 13.5%; Average loss: 4.1131\n",
            "Iteration: 540; Percent complete: 13.5%; Average loss: 4.2038\n",
            "Iteration: 541; Percent complete: 13.5%; Average loss: 4.0489\n",
            "Iteration: 542; Percent complete: 13.6%; Average loss: 4.1638\n",
            "Iteration: 543; Percent complete: 13.6%; Average loss: 4.0025\n",
            "Iteration: 544; Percent complete: 13.6%; Average loss: 4.2044\n",
            "Iteration: 545; Percent complete: 13.6%; Average loss: 4.1795\n",
            "Iteration: 546; Percent complete: 13.7%; Average loss: 4.2777\n",
            "Iteration: 547; Percent complete: 13.7%; Average loss: 4.2020\n",
            "Iteration: 548; Percent complete: 13.7%; Average loss: 4.2243\n",
            "Iteration: 549; Percent complete: 13.7%; Average loss: 4.2493\n",
            "Iteration: 550; Percent complete: 13.8%; Average loss: 4.0410\n",
            "Iteration: 551; Percent complete: 13.8%; Average loss: 4.0442\n",
            "Iteration: 552; Percent complete: 13.8%; Average loss: 4.1722\n",
            "Iteration: 553; Percent complete: 13.8%; Average loss: 4.1216\n",
            "Iteration: 554; Percent complete: 13.9%; Average loss: 3.9014\n",
            "Iteration: 555; Percent complete: 13.9%; Average loss: 4.1879\n",
            "Iteration: 556; Percent complete: 13.9%; Average loss: 4.3791\n",
            "Iteration: 557; Percent complete: 13.9%; Average loss: 3.9806\n",
            "Iteration: 558; Percent complete: 14.0%; Average loss: 3.8565\n",
            "Iteration: 559; Percent complete: 14.0%; Average loss: 3.9323\n",
            "Iteration: 560; Percent complete: 14.0%; Average loss: 4.1425\n",
            "Iteration: 561; Percent complete: 14.0%; Average loss: 3.8961\n",
            "Iteration: 562; Percent complete: 14.1%; Average loss: 4.0923\n",
            "Iteration: 563; Percent complete: 14.1%; Average loss: 3.7615\n",
            "Iteration: 564; Percent complete: 14.1%; Average loss: 4.1894\n",
            "Iteration: 565; Percent complete: 14.1%; Average loss: 4.2403\n",
            "Iteration: 566; Percent complete: 14.1%; Average loss: 4.0966\n",
            "Iteration: 567; Percent complete: 14.2%; Average loss: 3.8847\n",
            "Iteration: 568; Percent complete: 14.2%; Average loss: 4.2224\n",
            "Iteration: 569; Percent complete: 14.2%; Average loss: 4.1982\n",
            "Iteration: 570; Percent complete: 14.2%; Average loss: 4.0085\n",
            "Iteration: 571; Percent complete: 14.3%; Average loss: 4.1325\n",
            "Iteration: 572; Percent complete: 14.3%; Average loss: 4.3174\n",
            "Iteration: 573; Percent complete: 14.3%; Average loss: 3.9701\n",
            "Iteration: 574; Percent complete: 14.3%; Average loss: 4.0217\n",
            "Iteration: 575; Percent complete: 14.4%; Average loss: 3.8879\n",
            "Iteration: 576; Percent complete: 14.4%; Average loss: 4.0186\n",
            "Iteration: 577; Percent complete: 14.4%; Average loss: 4.2317\n",
            "Iteration: 578; Percent complete: 14.4%; Average loss: 3.7571\n",
            "Iteration: 579; Percent complete: 14.5%; Average loss: 3.8920\n",
            "Iteration: 580; Percent complete: 14.5%; Average loss: 3.8467\n",
            "Iteration: 581; Percent complete: 14.5%; Average loss: 3.9429\n",
            "Iteration: 582; Percent complete: 14.5%; Average loss: 4.0895\n",
            "Iteration: 583; Percent complete: 14.6%; Average loss: 4.1578\n",
            "Iteration: 584; Percent complete: 14.6%; Average loss: 4.0052\n",
            "Iteration: 585; Percent complete: 14.6%; Average loss: 4.0059\n",
            "Iteration: 586; Percent complete: 14.6%; Average loss: 4.0412\n",
            "Iteration: 587; Percent complete: 14.7%; Average loss: 3.9788\n",
            "Iteration: 588; Percent complete: 14.7%; Average loss: 4.1763\n",
            "Iteration: 589; Percent complete: 14.7%; Average loss: 3.8923\n",
            "Iteration: 590; Percent complete: 14.8%; Average loss: 4.0138\n",
            "Iteration: 591; Percent complete: 14.8%; Average loss: 3.9753\n",
            "Iteration: 592; Percent complete: 14.8%; Average loss: 4.0733\n",
            "Iteration: 593; Percent complete: 14.8%; Average loss: 3.7529\n",
            "Iteration: 594; Percent complete: 14.8%; Average loss: 4.0621\n",
            "Iteration: 595; Percent complete: 14.9%; Average loss: 4.0641\n",
            "Iteration: 596; Percent complete: 14.9%; Average loss: 4.0452\n",
            "Iteration: 597; Percent complete: 14.9%; Average loss: 3.6911\n",
            "Iteration: 598; Percent complete: 14.9%; Average loss: 3.9444\n",
            "Iteration: 599; Percent complete: 15.0%; Average loss: 4.0636\n",
            "Iteration: 600; Percent complete: 15.0%; Average loss: 3.7969\n",
            "Iteration: 601; Percent complete: 15.0%; Average loss: 3.7853\n",
            "Iteration: 602; Percent complete: 15.0%; Average loss: 3.8378\n",
            "Iteration: 603; Percent complete: 15.1%; Average loss: 3.7734\n",
            "Iteration: 604; Percent complete: 15.1%; Average loss: 4.1438\n",
            "Iteration: 605; Percent complete: 15.1%; Average loss: 3.7175\n",
            "Iteration: 606; Percent complete: 15.2%; Average loss: 4.2206\n",
            "Iteration: 607; Percent complete: 15.2%; Average loss: 3.6542\n",
            "Iteration: 608; Percent complete: 15.2%; Average loss: 3.8417\n",
            "Iteration: 609; Percent complete: 15.2%; Average loss: 3.7579\n",
            "Iteration: 610; Percent complete: 15.2%; Average loss: 3.8822\n",
            "Iteration: 611; Percent complete: 15.3%; Average loss: 4.1277\n",
            "Iteration: 612; Percent complete: 15.3%; Average loss: 3.9145\n",
            "Iteration: 613; Percent complete: 15.3%; Average loss: 3.8418\n",
            "Iteration: 614; Percent complete: 15.3%; Average loss: 3.8165\n",
            "Iteration: 615; Percent complete: 15.4%; Average loss: 3.9697\n",
            "Iteration: 616; Percent complete: 15.4%; Average loss: 4.1338\n",
            "Iteration: 617; Percent complete: 15.4%; Average loss: 4.0390\n",
            "Iteration: 618; Percent complete: 15.4%; Average loss: 4.0817\n",
            "Iteration: 619; Percent complete: 15.5%; Average loss: 3.9586\n",
            "Iteration: 620; Percent complete: 15.5%; Average loss: 4.0654\n",
            "Iteration: 621; Percent complete: 15.5%; Average loss: 4.3180\n",
            "Iteration: 622; Percent complete: 15.6%; Average loss: 4.1726\n",
            "Iteration: 623; Percent complete: 15.6%; Average loss: 3.9394\n",
            "Iteration: 624; Percent complete: 15.6%; Average loss: 4.1279\n",
            "Iteration: 625; Percent complete: 15.6%; Average loss: 3.7101\n",
            "Iteration: 626; Percent complete: 15.7%; Average loss: 3.8986\n",
            "Iteration: 627; Percent complete: 15.7%; Average loss: 3.6331\n",
            "Iteration: 628; Percent complete: 15.7%; Average loss: 3.8146\n",
            "Iteration: 629; Percent complete: 15.7%; Average loss: 4.0695\n",
            "Iteration: 630; Percent complete: 15.8%; Average loss: 3.7612\n",
            "Iteration: 631; Percent complete: 15.8%; Average loss: 3.6906\n",
            "Iteration: 632; Percent complete: 15.8%; Average loss: 3.7732\n",
            "Iteration: 633; Percent complete: 15.8%; Average loss: 3.5390\n",
            "Iteration: 634; Percent complete: 15.8%; Average loss: 3.8608\n",
            "Iteration: 635; Percent complete: 15.9%; Average loss: 3.5459\n",
            "Iteration: 636; Percent complete: 15.9%; Average loss: 3.8731\n",
            "Iteration: 637; Percent complete: 15.9%; Average loss: 3.7241\n",
            "Iteration: 638; Percent complete: 16.0%; Average loss: 4.2023\n",
            "Iteration: 639; Percent complete: 16.0%; Average loss: 3.7756\n",
            "Iteration: 640; Percent complete: 16.0%; Average loss: 4.0570\n",
            "Iteration: 641; Percent complete: 16.0%; Average loss: 3.5818\n",
            "Iteration: 642; Percent complete: 16.1%; Average loss: 3.7011\n",
            "Iteration: 643; Percent complete: 16.1%; Average loss: 3.8219\n",
            "Iteration: 644; Percent complete: 16.1%; Average loss: 3.6617\n",
            "Iteration: 645; Percent complete: 16.1%; Average loss: 3.7147\n",
            "Iteration: 646; Percent complete: 16.2%; Average loss: 3.8454\n",
            "Iteration: 647; Percent complete: 16.2%; Average loss: 3.6183\n",
            "Iteration: 648; Percent complete: 16.2%; Average loss: 3.6431\n",
            "Iteration: 649; Percent complete: 16.2%; Average loss: 3.7520\n",
            "Iteration: 650; Percent complete: 16.2%; Average loss: 4.0156\n",
            "Iteration: 651; Percent complete: 16.3%; Average loss: 3.5540\n",
            "Iteration: 652; Percent complete: 16.3%; Average loss: 3.9970\n",
            "Iteration: 653; Percent complete: 16.3%; Average loss: 3.9017\n",
            "Iteration: 654; Percent complete: 16.4%; Average loss: 3.7473\n",
            "Iteration: 655; Percent complete: 16.4%; Average loss: 3.8120\n",
            "Iteration: 656; Percent complete: 16.4%; Average loss: 3.6765\n",
            "Iteration: 657; Percent complete: 16.4%; Average loss: 3.9287\n",
            "Iteration: 658; Percent complete: 16.4%; Average loss: 3.9182\n",
            "Iteration: 659; Percent complete: 16.5%; Average loss: 3.9800\n",
            "Iteration: 660; Percent complete: 16.5%; Average loss: 3.7194\n",
            "Iteration: 661; Percent complete: 16.5%; Average loss: 3.8574\n",
            "Iteration: 662; Percent complete: 16.6%; Average loss: 3.8612\n",
            "Iteration: 663; Percent complete: 16.6%; Average loss: 3.7434\n",
            "Iteration: 664; Percent complete: 16.6%; Average loss: 3.5300\n",
            "Iteration: 665; Percent complete: 16.6%; Average loss: 3.8320\n",
            "Iteration: 666; Percent complete: 16.7%; Average loss: 3.9410\n",
            "Iteration: 667; Percent complete: 16.7%; Average loss: 4.0292\n",
            "Iteration: 668; Percent complete: 16.7%; Average loss: 3.6863\n",
            "Iteration: 669; Percent complete: 16.7%; Average loss: 4.0512\n",
            "Iteration: 670; Percent complete: 16.8%; Average loss: 3.7166\n",
            "Iteration: 671; Percent complete: 16.8%; Average loss: 3.9106\n",
            "Iteration: 672; Percent complete: 16.8%; Average loss: 3.7186\n",
            "Iteration: 673; Percent complete: 16.8%; Average loss: 3.6364\n",
            "Iteration: 674; Percent complete: 16.9%; Average loss: 3.5697\n",
            "Iteration: 675; Percent complete: 16.9%; Average loss: 3.8635\n",
            "Iteration: 676; Percent complete: 16.9%; Average loss: 3.5266\n",
            "Iteration: 677; Percent complete: 16.9%; Average loss: 3.8364\n",
            "Iteration: 678; Percent complete: 17.0%; Average loss: 3.7971\n",
            "Iteration: 679; Percent complete: 17.0%; Average loss: 3.6439\n",
            "Iteration: 680; Percent complete: 17.0%; Average loss: 3.9221\n",
            "Iteration: 681; Percent complete: 17.0%; Average loss: 3.6377\n",
            "Iteration: 682; Percent complete: 17.1%; Average loss: 3.9240\n",
            "Iteration: 683; Percent complete: 17.1%; Average loss: 4.0953\n",
            "Iteration: 684; Percent complete: 17.1%; Average loss: 3.4558\n",
            "Iteration: 685; Percent complete: 17.1%; Average loss: 3.7908\n",
            "Iteration: 686; Percent complete: 17.2%; Average loss: 3.8405\n",
            "Iteration: 687; Percent complete: 17.2%; Average loss: 3.4965\n",
            "Iteration: 688; Percent complete: 17.2%; Average loss: 3.7577\n",
            "Iteration: 689; Percent complete: 17.2%; Average loss: 3.4880\n",
            "Iteration: 690; Percent complete: 17.2%; Average loss: 3.6597\n",
            "Iteration: 691; Percent complete: 17.3%; Average loss: 3.7263\n",
            "Iteration: 692; Percent complete: 17.3%; Average loss: 3.9675\n",
            "Iteration: 693; Percent complete: 17.3%; Average loss: 3.4785\n",
            "Iteration: 694; Percent complete: 17.3%; Average loss: 3.4876\n",
            "Iteration: 695; Percent complete: 17.4%; Average loss: 3.5871\n",
            "Iteration: 696; Percent complete: 17.4%; Average loss: 3.4621\n",
            "Iteration: 697; Percent complete: 17.4%; Average loss: 3.7431\n",
            "Iteration: 698; Percent complete: 17.4%; Average loss: 3.9305\n",
            "Iteration: 699; Percent complete: 17.5%; Average loss: 3.7125\n",
            "Iteration: 700; Percent complete: 17.5%; Average loss: 3.6961\n",
            "Iteration: 701; Percent complete: 17.5%; Average loss: 3.7180\n",
            "Iteration: 702; Percent complete: 17.5%; Average loss: 3.4494\n",
            "Iteration: 703; Percent complete: 17.6%; Average loss: 3.8745\n",
            "Iteration: 704; Percent complete: 17.6%; Average loss: 3.4634\n",
            "Iteration: 705; Percent complete: 17.6%; Average loss: 3.8436\n",
            "Iteration: 706; Percent complete: 17.6%; Average loss: 3.5270\n",
            "Iteration: 707; Percent complete: 17.7%; Average loss: 3.5606\n",
            "Iteration: 708; Percent complete: 17.7%; Average loss: 3.8332\n",
            "Iteration: 709; Percent complete: 17.7%; Average loss: 3.7616\n",
            "Iteration: 710; Percent complete: 17.8%; Average loss: 3.6552\n",
            "Iteration: 711; Percent complete: 17.8%; Average loss: 4.1279\n",
            "Iteration: 712; Percent complete: 17.8%; Average loss: 3.5106\n",
            "Iteration: 713; Percent complete: 17.8%; Average loss: 3.5823\n",
            "Iteration: 714; Percent complete: 17.8%; Average loss: 3.2723\n",
            "Iteration: 715; Percent complete: 17.9%; Average loss: 3.7256\n",
            "Iteration: 716; Percent complete: 17.9%; Average loss: 3.5489\n",
            "Iteration: 717; Percent complete: 17.9%; Average loss: 3.7176\n",
            "Iteration: 718; Percent complete: 17.9%; Average loss: 3.7012\n",
            "Iteration: 719; Percent complete: 18.0%; Average loss: 3.5835\n",
            "Iteration: 720; Percent complete: 18.0%; Average loss: 3.6091\n",
            "Iteration: 721; Percent complete: 18.0%; Average loss: 3.6871\n",
            "Iteration: 722; Percent complete: 18.1%; Average loss: 3.7522\n",
            "Iteration: 723; Percent complete: 18.1%; Average loss: 3.6601\n",
            "Iteration: 724; Percent complete: 18.1%; Average loss: 3.4064\n",
            "Iteration: 725; Percent complete: 18.1%; Average loss: 3.4859\n",
            "Iteration: 726; Percent complete: 18.1%; Average loss: 3.5339\n",
            "Iteration: 727; Percent complete: 18.2%; Average loss: 3.6223\n",
            "Iteration: 728; Percent complete: 18.2%; Average loss: 3.6786\n",
            "Iteration: 729; Percent complete: 18.2%; Average loss: 3.5578\n",
            "Iteration: 730; Percent complete: 18.2%; Average loss: 3.5195\n",
            "Iteration: 731; Percent complete: 18.3%; Average loss: 3.3766\n",
            "Iteration: 732; Percent complete: 18.3%; Average loss: 3.8226\n",
            "Iteration: 733; Percent complete: 18.3%; Average loss: 3.7566\n",
            "Iteration: 734; Percent complete: 18.4%; Average loss: 3.4883\n",
            "Iteration: 735; Percent complete: 18.4%; Average loss: 3.8148\n",
            "Iteration: 736; Percent complete: 18.4%; Average loss: 3.7269\n",
            "Iteration: 737; Percent complete: 18.4%; Average loss: 3.5821\n",
            "Iteration: 738; Percent complete: 18.4%; Average loss: 3.8822\n",
            "Iteration: 739; Percent complete: 18.5%; Average loss: 3.7655\n",
            "Iteration: 740; Percent complete: 18.5%; Average loss: 3.2958\n",
            "Iteration: 741; Percent complete: 18.5%; Average loss: 3.4734\n",
            "Iteration: 742; Percent complete: 18.6%; Average loss: 3.6951\n",
            "Iteration: 743; Percent complete: 18.6%; Average loss: 3.6364\n",
            "Iteration: 744; Percent complete: 18.6%; Average loss: 3.5784\n",
            "Iteration: 745; Percent complete: 18.6%; Average loss: 3.6144\n",
            "Iteration: 746; Percent complete: 18.6%; Average loss: 3.7648\n",
            "Iteration: 747; Percent complete: 18.7%; Average loss: 3.6910\n",
            "Iteration: 748; Percent complete: 18.7%; Average loss: 3.6587\n",
            "Iteration: 749; Percent complete: 18.7%; Average loss: 3.6865\n",
            "Iteration: 750; Percent complete: 18.8%; Average loss: 3.8701\n",
            "Iteration: 751; Percent complete: 18.8%; Average loss: 3.6077\n",
            "Iteration: 752; Percent complete: 18.8%; Average loss: 3.7675\n",
            "Iteration: 753; Percent complete: 18.8%; Average loss: 3.5589\n",
            "Iteration: 754; Percent complete: 18.9%; Average loss: 3.8719\n",
            "Iteration: 755; Percent complete: 18.9%; Average loss: 3.2906\n",
            "Iteration: 756; Percent complete: 18.9%; Average loss: 3.6064\n",
            "Iteration: 757; Percent complete: 18.9%; Average loss: 3.5190\n",
            "Iteration: 758; Percent complete: 18.9%; Average loss: 3.4765\n",
            "Iteration: 759; Percent complete: 19.0%; Average loss: 3.5181\n",
            "Iteration: 760; Percent complete: 19.0%; Average loss: 3.5518\n",
            "Iteration: 761; Percent complete: 19.0%; Average loss: 3.6610\n",
            "Iteration: 762; Percent complete: 19.1%; Average loss: 3.8594\n",
            "Iteration: 763; Percent complete: 19.1%; Average loss: 3.5583\n",
            "Iteration: 764; Percent complete: 19.1%; Average loss: 3.4168\n",
            "Iteration: 765; Percent complete: 19.1%; Average loss: 3.6443\n",
            "Iteration: 766; Percent complete: 19.1%; Average loss: 3.6807\n",
            "Iteration: 767; Percent complete: 19.2%; Average loss: 3.6210\n",
            "Iteration: 768; Percent complete: 19.2%; Average loss: 3.5023\n",
            "Iteration: 769; Percent complete: 19.2%; Average loss: 3.6114\n",
            "Iteration: 770; Percent complete: 19.2%; Average loss: 3.8408\n",
            "Iteration: 771; Percent complete: 19.3%; Average loss: 3.7506\n",
            "Iteration: 772; Percent complete: 19.3%; Average loss: 3.4778\n",
            "Iteration: 773; Percent complete: 19.3%; Average loss: 3.8020\n",
            "Iteration: 774; Percent complete: 19.4%; Average loss: 3.6602\n",
            "Iteration: 775; Percent complete: 19.4%; Average loss: 3.8367\n",
            "Iteration: 776; Percent complete: 19.4%; Average loss: 3.3880\n",
            "Iteration: 777; Percent complete: 19.4%; Average loss: 3.6150\n",
            "Iteration: 778; Percent complete: 19.4%; Average loss: 3.7421\n",
            "Iteration: 779; Percent complete: 19.5%; Average loss: 3.5385\n",
            "Iteration: 780; Percent complete: 19.5%; Average loss: 3.5311\n",
            "Iteration: 781; Percent complete: 19.5%; Average loss: 3.5977\n",
            "Iteration: 782; Percent complete: 19.6%; Average loss: 3.4290\n",
            "Iteration: 783; Percent complete: 19.6%; Average loss: 3.4578\n",
            "Iteration: 784; Percent complete: 19.6%; Average loss: 3.5085\n",
            "Iteration: 785; Percent complete: 19.6%; Average loss: 3.3927\n",
            "Iteration: 786; Percent complete: 19.7%; Average loss: 3.8527\n",
            "Iteration: 787; Percent complete: 19.7%; Average loss: 3.3857\n",
            "Iteration: 788; Percent complete: 19.7%; Average loss: 3.4579\n",
            "Iteration: 789; Percent complete: 19.7%; Average loss: 3.5424\n",
            "Iteration: 790; Percent complete: 19.8%; Average loss: 3.6949\n",
            "Iteration: 791; Percent complete: 19.8%; Average loss: 3.7111\n",
            "Iteration: 792; Percent complete: 19.8%; Average loss: 3.8905\n",
            "Iteration: 793; Percent complete: 19.8%; Average loss: 3.6120\n",
            "Iteration: 794; Percent complete: 19.9%; Average loss: 3.4757\n",
            "Iteration: 795; Percent complete: 19.9%; Average loss: 3.0424\n",
            "Iteration: 796; Percent complete: 19.9%; Average loss: 3.6532\n",
            "Iteration: 797; Percent complete: 19.9%; Average loss: 3.5626\n",
            "Iteration: 798; Percent complete: 20.0%; Average loss: 3.5763\n",
            "Iteration: 799; Percent complete: 20.0%; Average loss: 3.7090\n",
            "Iteration: 800; Percent complete: 20.0%; Average loss: 3.3325\n",
            "Iteration: 801; Percent complete: 20.0%; Average loss: 3.3731\n",
            "Iteration: 802; Percent complete: 20.1%; Average loss: 3.5024\n",
            "Iteration: 803; Percent complete: 20.1%; Average loss: 3.3637\n",
            "Iteration: 804; Percent complete: 20.1%; Average loss: 3.5833\n",
            "Iteration: 805; Percent complete: 20.1%; Average loss: 3.3337\n",
            "Iteration: 806; Percent complete: 20.2%; Average loss: 3.4095\n",
            "Iteration: 807; Percent complete: 20.2%; Average loss: 3.4754\n",
            "Iteration: 808; Percent complete: 20.2%; Average loss: 3.5934\n",
            "Iteration: 809; Percent complete: 20.2%; Average loss: 3.3835\n",
            "Iteration: 810; Percent complete: 20.2%; Average loss: 3.2887\n",
            "Iteration: 811; Percent complete: 20.3%; Average loss: 3.1510\n",
            "Iteration: 812; Percent complete: 20.3%; Average loss: 3.3901\n",
            "Iteration: 813; Percent complete: 20.3%; Average loss: 3.6648\n",
            "Iteration: 814; Percent complete: 20.3%; Average loss: 3.3964\n",
            "Iteration: 815; Percent complete: 20.4%; Average loss: 3.3921\n",
            "Iteration: 816; Percent complete: 20.4%; Average loss: 3.2905\n",
            "Iteration: 817; Percent complete: 20.4%; Average loss: 3.4231\n",
            "Iteration: 818; Percent complete: 20.4%; Average loss: 3.3709\n",
            "Iteration: 819; Percent complete: 20.5%; Average loss: 3.5212\n",
            "Iteration: 820; Percent complete: 20.5%; Average loss: 3.3648\n",
            "Iteration: 821; Percent complete: 20.5%; Average loss: 3.2849\n",
            "Iteration: 822; Percent complete: 20.5%; Average loss: 3.5214\n",
            "Iteration: 823; Percent complete: 20.6%; Average loss: 3.4620\n",
            "Iteration: 824; Percent complete: 20.6%; Average loss: 3.6439\n",
            "Iteration: 825; Percent complete: 20.6%; Average loss: 3.5721\n",
            "Iteration: 826; Percent complete: 20.6%; Average loss: 3.5274\n",
            "Iteration: 827; Percent complete: 20.7%; Average loss: 3.2111\n",
            "Iteration: 828; Percent complete: 20.7%; Average loss: 3.3587\n",
            "Iteration: 829; Percent complete: 20.7%; Average loss: 3.3763\n",
            "Iteration: 830; Percent complete: 20.8%; Average loss: 3.6811\n",
            "Iteration: 831; Percent complete: 20.8%; Average loss: 3.2060\n",
            "Iteration: 832; Percent complete: 20.8%; Average loss: 3.1188\n",
            "Iteration: 833; Percent complete: 20.8%; Average loss: 3.4756\n",
            "Iteration: 834; Percent complete: 20.8%; Average loss: 3.5686\n",
            "Iteration: 835; Percent complete: 20.9%; Average loss: 3.8519\n",
            "Iteration: 836; Percent complete: 20.9%; Average loss: 3.4224\n",
            "Iteration: 837; Percent complete: 20.9%; Average loss: 3.3982\n",
            "Iteration: 838; Percent complete: 20.9%; Average loss: 3.5128\n",
            "Iteration: 839; Percent complete: 21.0%; Average loss: 3.4364\n",
            "Iteration: 840; Percent complete: 21.0%; Average loss: 3.3757\n",
            "Iteration: 841; Percent complete: 21.0%; Average loss: 3.5274\n",
            "Iteration: 842; Percent complete: 21.1%; Average loss: 3.3150\n",
            "Iteration: 843; Percent complete: 21.1%; Average loss: 3.4691\n",
            "Iteration: 844; Percent complete: 21.1%; Average loss: 3.3117\n",
            "Iteration: 845; Percent complete: 21.1%; Average loss: 3.5576\n",
            "Iteration: 846; Percent complete: 21.1%; Average loss: 3.5163\n",
            "Iteration: 847; Percent complete: 21.2%; Average loss: 3.4015\n",
            "Iteration: 848; Percent complete: 21.2%; Average loss: 3.4648\n",
            "Iteration: 849; Percent complete: 21.2%; Average loss: 3.2595\n",
            "Iteration: 850; Percent complete: 21.2%; Average loss: 3.2577\n",
            "Iteration: 851; Percent complete: 21.3%; Average loss: 3.7446\n",
            "Iteration: 852; Percent complete: 21.3%; Average loss: 3.1656\n",
            "Iteration: 853; Percent complete: 21.3%; Average loss: 3.5657\n",
            "Iteration: 854; Percent complete: 21.3%; Average loss: 3.2796\n",
            "Iteration: 855; Percent complete: 21.4%; Average loss: 3.3859\n",
            "Iteration: 856; Percent complete: 21.4%; Average loss: 3.8111\n",
            "Iteration: 857; Percent complete: 21.4%; Average loss: 3.6764\n",
            "Iteration: 858; Percent complete: 21.4%; Average loss: 3.3000\n",
            "Iteration: 859; Percent complete: 21.5%; Average loss: 3.5304\n",
            "Iteration: 860; Percent complete: 21.5%; Average loss: 3.4067\n",
            "Iteration: 861; Percent complete: 21.5%; Average loss: 3.5669\n",
            "Iteration: 862; Percent complete: 21.6%; Average loss: 3.2420\n",
            "Iteration: 863; Percent complete: 21.6%; Average loss: 3.3595\n",
            "Iteration: 864; Percent complete: 21.6%; Average loss: 3.3074\n",
            "Iteration: 865; Percent complete: 21.6%; Average loss: 3.5531\n",
            "Iteration: 866; Percent complete: 21.6%; Average loss: 3.5042\n",
            "Iteration: 867; Percent complete: 21.7%; Average loss: 3.2487\n",
            "Iteration: 868; Percent complete: 21.7%; Average loss: 3.3239\n",
            "Iteration: 869; Percent complete: 21.7%; Average loss: 3.3184\n",
            "Iteration: 870; Percent complete: 21.8%; Average loss: 3.4088\n",
            "Iteration: 871; Percent complete: 21.8%; Average loss: 3.3687\n",
            "Iteration: 872; Percent complete: 21.8%; Average loss: 3.3336\n",
            "Iteration: 873; Percent complete: 21.8%; Average loss: 3.3578\n",
            "Iteration: 874; Percent complete: 21.9%; Average loss: 3.4867\n",
            "Iteration: 875; Percent complete: 21.9%; Average loss: 3.2891\n",
            "Iteration: 876; Percent complete: 21.9%; Average loss: 3.2915\n",
            "Iteration: 877; Percent complete: 21.9%; Average loss: 3.2118\n",
            "Iteration: 878; Percent complete: 21.9%; Average loss: 3.2200\n",
            "Iteration: 879; Percent complete: 22.0%; Average loss: 3.1628\n",
            "Iteration: 880; Percent complete: 22.0%; Average loss: 3.3427\n",
            "Iteration: 881; Percent complete: 22.0%; Average loss: 3.4254\n",
            "Iteration: 882; Percent complete: 22.1%; Average loss: 3.0841\n",
            "Iteration: 883; Percent complete: 22.1%; Average loss: 3.2012\n",
            "Iteration: 884; Percent complete: 22.1%; Average loss: 3.2753\n",
            "Iteration: 885; Percent complete: 22.1%; Average loss: 3.0853\n",
            "Iteration: 886; Percent complete: 22.1%; Average loss: 3.1090\n",
            "Iteration: 887; Percent complete: 22.2%; Average loss: 3.4328\n",
            "Iteration: 888; Percent complete: 22.2%; Average loss: 3.4745\n",
            "Iteration: 889; Percent complete: 22.2%; Average loss: 3.4526\n",
            "Iteration: 890; Percent complete: 22.2%; Average loss: 3.3836\n",
            "Iteration: 891; Percent complete: 22.3%; Average loss: 3.6422\n",
            "Iteration: 892; Percent complete: 22.3%; Average loss: 3.1511\n",
            "Iteration: 893; Percent complete: 22.3%; Average loss: 3.2778\n",
            "Iteration: 894; Percent complete: 22.4%; Average loss: 3.1693\n",
            "Iteration: 895; Percent complete: 22.4%; Average loss: 3.2676\n",
            "Iteration: 896; Percent complete: 22.4%; Average loss: 3.1903\n",
            "Iteration: 897; Percent complete: 22.4%; Average loss: 3.3136\n",
            "Iteration: 898; Percent complete: 22.4%; Average loss: 3.3411\n",
            "Iteration: 899; Percent complete: 22.5%; Average loss: 3.2963\n",
            "Iteration: 900; Percent complete: 22.5%; Average loss: 3.3148\n",
            "Iteration: 901; Percent complete: 22.5%; Average loss: 3.0311\n",
            "Iteration: 902; Percent complete: 22.6%; Average loss: 3.4193\n",
            "Iteration: 903; Percent complete: 22.6%; Average loss: 3.5115\n",
            "Iteration: 904; Percent complete: 22.6%; Average loss: 3.2858\n",
            "Iteration: 905; Percent complete: 22.6%; Average loss: 3.3293\n",
            "Iteration: 906; Percent complete: 22.7%; Average loss: 3.2311\n",
            "Iteration: 907; Percent complete: 22.7%; Average loss: 2.9759\n",
            "Iteration: 908; Percent complete: 22.7%; Average loss: 3.1996\n",
            "Iteration: 909; Percent complete: 22.7%; Average loss: 3.1312\n",
            "Iteration: 910; Percent complete: 22.8%; Average loss: 2.9202\n",
            "Iteration: 911; Percent complete: 22.8%; Average loss: 3.3070\n",
            "Iteration: 912; Percent complete: 22.8%; Average loss: 3.2261\n",
            "Iteration: 913; Percent complete: 22.8%; Average loss: 3.2443\n",
            "Iteration: 914; Percent complete: 22.9%; Average loss: 3.4830\n",
            "Iteration: 915; Percent complete: 22.9%; Average loss: 3.3313\n",
            "Iteration: 916; Percent complete: 22.9%; Average loss: 3.2014\n",
            "Iteration: 917; Percent complete: 22.9%; Average loss: 3.3049\n",
            "Iteration: 918; Percent complete: 22.9%; Average loss: 3.3074\n",
            "Iteration: 919; Percent complete: 23.0%; Average loss: 2.9113\n",
            "Iteration: 920; Percent complete: 23.0%; Average loss: 3.1718\n",
            "Iteration: 921; Percent complete: 23.0%; Average loss: 3.1477\n",
            "Iteration: 922; Percent complete: 23.1%; Average loss: 2.8924\n",
            "Iteration: 923; Percent complete: 23.1%; Average loss: 3.0531\n",
            "Iteration: 924; Percent complete: 23.1%; Average loss: 3.1633\n",
            "Iteration: 925; Percent complete: 23.1%; Average loss: 3.3760\n",
            "Iteration: 926; Percent complete: 23.2%; Average loss: 3.3483\n",
            "Iteration: 927; Percent complete: 23.2%; Average loss: 3.1952\n",
            "Iteration: 928; Percent complete: 23.2%; Average loss: 2.9659\n",
            "Iteration: 929; Percent complete: 23.2%; Average loss: 3.0683\n",
            "Iteration: 930; Percent complete: 23.2%; Average loss: 2.9283\n",
            "Iteration: 931; Percent complete: 23.3%; Average loss: 3.1992\n",
            "Iteration: 932; Percent complete: 23.3%; Average loss: 3.1421\n",
            "Iteration: 933; Percent complete: 23.3%; Average loss: 2.9608\n",
            "Iteration: 934; Percent complete: 23.4%; Average loss: 3.0335\n",
            "Iteration: 935; Percent complete: 23.4%; Average loss: 3.2430\n",
            "Iteration: 936; Percent complete: 23.4%; Average loss: 3.1711\n",
            "Iteration: 937; Percent complete: 23.4%; Average loss: 3.4531\n",
            "Iteration: 938; Percent complete: 23.4%; Average loss: 3.3958\n",
            "Iteration: 939; Percent complete: 23.5%; Average loss: 3.3139\n",
            "Iteration: 940; Percent complete: 23.5%; Average loss: 3.2415\n",
            "Iteration: 941; Percent complete: 23.5%; Average loss: 3.3503\n",
            "Iteration: 942; Percent complete: 23.5%; Average loss: 3.1348\n",
            "Iteration: 943; Percent complete: 23.6%; Average loss: 3.2165\n",
            "Iteration: 944; Percent complete: 23.6%; Average loss: 3.1135\n",
            "Iteration: 945; Percent complete: 23.6%; Average loss: 2.9452\n",
            "Iteration: 946; Percent complete: 23.6%; Average loss: 3.1489\n",
            "Iteration: 947; Percent complete: 23.7%; Average loss: 3.0942\n",
            "Iteration: 948; Percent complete: 23.7%; Average loss: 3.0289\n",
            "Iteration: 949; Percent complete: 23.7%; Average loss: 3.0764\n",
            "Iteration: 950; Percent complete: 23.8%; Average loss: 3.5779\n",
            "Iteration: 951; Percent complete: 23.8%; Average loss: 3.3101\n",
            "Iteration: 952; Percent complete: 23.8%; Average loss: 3.0230\n",
            "Iteration: 953; Percent complete: 23.8%; Average loss: 3.1113\n",
            "Iteration: 954; Percent complete: 23.8%; Average loss: 3.0695\n",
            "Iteration: 955; Percent complete: 23.9%; Average loss: 3.4797\n",
            "Iteration: 956; Percent complete: 23.9%; Average loss: 3.2663\n",
            "Iteration: 957; Percent complete: 23.9%; Average loss: 3.0967\n",
            "Iteration: 958; Percent complete: 23.9%; Average loss: 3.2652\n",
            "Iteration: 959; Percent complete: 24.0%; Average loss: 3.2519\n",
            "Iteration: 960; Percent complete: 24.0%; Average loss: 3.2010\n",
            "Iteration: 961; Percent complete: 24.0%; Average loss: 3.4019\n",
            "Iteration: 962; Percent complete: 24.1%; Average loss: 3.2555\n",
            "Iteration: 963; Percent complete: 24.1%; Average loss: 3.0771\n",
            "Iteration: 964; Percent complete: 24.1%; Average loss: 3.0222\n",
            "Iteration: 965; Percent complete: 24.1%; Average loss: 2.9865\n",
            "Iteration: 966; Percent complete: 24.1%; Average loss: 3.1108\n",
            "Iteration: 967; Percent complete: 24.2%; Average loss: 3.0104\n",
            "Iteration: 968; Percent complete: 24.2%; Average loss: 2.9947\n",
            "Iteration: 969; Percent complete: 24.2%; Average loss: 3.1580\n",
            "Iteration: 970; Percent complete: 24.2%; Average loss: 3.1703\n",
            "Iteration: 971; Percent complete: 24.3%; Average loss: 3.1140\n",
            "Iteration: 972; Percent complete: 24.3%; Average loss: 2.8873\n",
            "Iteration: 973; Percent complete: 24.3%; Average loss: 3.0530\n",
            "Iteration: 974; Percent complete: 24.3%; Average loss: 3.4090\n",
            "Iteration: 975; Percent complete: 24.4%; Average loss: 3.0383\n",
            "Iteration: 976; Percent complete: 24.4%; Average loss: 2.9776\n",
            "Iteration: 977; Percent complete: 24.4%; Average loss: 2.9197\n",
            "Iteration: 978; Percent complete: 24.4%; Average loss: 3.1896\n",
            "Iteration: 979; Percent complete: 24.5%; Average loss: 3.1046\n",
            "Iteration: 980; Percent complete: 24.5%; Average loss: 3.2483\n",
            "Iteration: 981; Percent complete: 24.5%; Average loss: 2.9498\n",
            "Iteration: 982; Percent complete: 24.6%; Average loss: 3.2928\n",
            "Iteration: 983; Percent complete: 24.6%; Average loss: 3.1544\n",
            "Iteration: 984; Percent complete: 24.6%; Average loss: 2.8112\n",
            "Iteration: 985; Percent complete: 24.6%; Average loss: 3.0280\n",
            "Iteration: 986; Percent complete: 24.6%; Average loss: 3.1758\n",
            "Iteration: 987; Percent complete: 24.7%; Average loss: 2.8439\n",
            "Iteration: 988; Percent complete: 24.7%; Average loss: 3.1260\n",
            "Iteration: 989; Percent complete: 24.7%; Average loss: 2.9554\n",
            "Iteration: 990; Percent complete: 24.8%; Average loss: 2.8694\n",
            "Iteration: 991; Percent complete: 24.8%; Average loss: 3.4492\n",
            "Iteration: 992; Percent complete: 24.8%; Average loss: 2.6122\n",
            "Iteration: 993; Percent complete: 24.8%; Average loss: 3.2332\n",
            "Iteration: 994; Percent complete: 24.9%; Average loss: 3.2267\n",
            "Iteration: 995; Percent complete: 24.9%; Average loss: 3.1112\n",
            "Iteration: 996; Percent complete: 24.9%; Average loss: 2.8631\n",
            "Iteration: 997; Percent complete: 24.9%; Average loss: 2.7464\n",
            "Iteration: 998; Percent complete: 24.9%; Average loss: 3.0735\n",
            "Iteration: 999; Percent complete: 25.0%; Average loss: 3.3339\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 3.2318\n",
            "Iteration: 1001; Percent complete: 25.0%; Average loss: 2.6767\n",
            "Iteration: 1002; Percent complete: 25.1%; Average loss: 2.9717\n",
            "Iteration: 1003; Percent complete: 25.1%; Average loss: 2.9792\n",
            "Iteration: 1004; Percent complete: 25.1%; Average loss: 3.1450\n",
            "Iteration: 1005; Percent complete: 25.1%; Average loss: 2.9821\n",
            "Iteration: 1006; Percent complete: 25.1%; Average loss: 2.8040\n",
            "Iteration: 1007; Percent complete: 25.2%; Average loss: 3.1187\n",
            "Iteration: 1008; Percent complete: 25.2%; Average loss: 3.2297\n",
            "Iteration: 1009; Percent complete: 25.2%; Average loss: 2.9855\n",
            "Iteration: 1010; Percent complete: 25.2%; Average loss: 2.9215\n",
            "Iteration: 1011; Percent complete: 25.3%; Average loss: 3.0328\n",
            "Iteration: 1012; Percent complete: 25.3%; Average loss: 2.7862\n",
            "Iteration: 1013; Percent complete: 25.3%; Average loss: 3.1939\n",
            "Iteration: 1014; Percent complete: 25.4%; Average loss: 3.0300\n",
            "Iteration: 1015; Percent complete: 25.4%; Average loss: 3.0522\n",
            "Iteration: 1016; Percent complete: 25.4%; Average loss: 2.9641\n",
            "Iteration: 1017; Percent complete: 25.4%; Average loss: 2.9691\n",
            "Iteration: 1018; Percent complete: 25.4%; Average loss: 2.9664\n",
            "Iteration: 1019; Percent complete: 25.5%; Average loss: 3.0464\n",
            "Iteration: 1020; Percent complete: 25.5%; Average loss: 2.8024\n",
            "Iteration: 1021; Percent complete: 25.5%; Average loss: 2.8820\n",
            "Iteration: 1022; Percent complete: 25.6%; Average loss: 2.7512\n",
            "Iteration: 1023; Percent complete: 25.6%; Average loss: 2.8873\n",
            "Iteration: 1024; Percent complete: 25.6%; Average loss: 2.9760\n",
            "Iteration: 1025; Percent complete: 25.6%; Average loss: 3.1758\n",
            "Iteration: 1026; Percent complete: 25.7%; Average loss: 2.8937\n",
            "Iteration: 1027; Percent complete: 25.7%; Average loss: 2.8507\n",
            "Iteration: 1028; Percent complete: 25.7%; Average loss: 2.7492\n",
            "Iteration: 1029; Percent complete: 25.7%; Average loss: 3.1680\n",
            "Iteration: 1030; Percent complete: 25.8%; Average loss: 3.0236\n",
            "Iteration: 1031; Percent complete: 25.8%; Average loss: 2.9719\n",
            "Iteration: 1032; Percent complete: 25.8%; Average loss: 2.9675\n",
            "Iteration: 1033; Percent complete: 25.8%; Average loss: 2.8217\n",
            "Iteration: 1034; Percent complete: 25.9%; Average loss: 3.4004\n",
            "Iteration: 1035; Percent complete: 25.9%; Average loss: 3.2061\n",
            "Iteration: 1036; Percent complete: 25.9%; Average loss: 2.8309\n",
            "Iteration: 1037; Percent complete: 25.9%; Average loss: 3.3296\n",
            "Iteration: 1038; Percent complete: 25.9%; Average loss: 3.1080\n",
            "Iteration: 1039; Percent complete: 26.0%; Average loss: 3.2434\n",
            "Iteration: 1040; Percent complete: 26.0%; Average loss: 3.0736\n",
            "Iteration: 1041; Percent complete: 26.0%; Average loss: 2.8997\n",
            "Iteration: 1042; Percent complete: 26.1%; Average loss: 3.1984\n",
            "Iteration: 1043; Percent complete: 26.1%; Average loss: 2.9003\n",
            "Iteration: 1044; Percent complete: 26.1%; Average loss: 2.9249\n",
            "Iteration: 1045; Percent complete: 26.1%; Average loss: 3.1728\n",
            "Iteration: 1046; Percent complete: 26.2%; Average loss: 3.0827\n",
            "Iteration: 1047; Percent complete: 26.2%; Average loss: 3.0770\n",
            "Iteration: 1048; Percent complete: 26.2%; Average loss: 2.8921\n",
            "Iteration: 1049; Percent complete: 26.2%; Average loss: 2.8830\n",
            "Iteration: 1050; Percent complete: 26.2%; Average loss: 2.6184\n",
            "Iteration: 1051; Percent complete: 26.3%; Average loss: 2.8175\n",
            "Iteration: 1052; Percent complete: 26.3%; Average loss: 2.8169\n",
            "Iteration: 1053; Percent complete: 26.3%; Average loss: 2.7592\n",
            "Iteration: 1054; Percent complete: 26.4%; Average loss: 2.7562\n",
            "Iteration: 1055; Percent complete: 26.4%; Average loss: 2.7899\n",
            "Iteration: 1056; Percent complete: 26.4%; Average loss: 2.8794\n",
            "Iteration: 1057; Percent complete: 26.4%; Average loss: 2.8495\n",
            "Iteration: 1058; Percent complete: 26.5%; Average loss: 2.7822\n",
            "Iteration: 1059; Percent complete: 26.5%; Average loss: 3.1625\n",
            "Iteration: 1060; Percent complete: 26.5%; Average loss: 2.7620\n",
            "Iteration: 1061; Percent complete: 26.5%; Average loss: 2.8940\n",
            "Iteration: 1062; Percent complete: 26.6%; Average loss: 3.0198\n",
            "Iteration: 1063; Percent complete: 26.6%; Average loss: 2.8705\n",
            "Iteration: 1064; Percent complete: 26.6%; Average loss: 2.7497\n",
            "Iteration: 1065; Percent complete: 26.6%; Average loss: 3.1210\n",
            "Iteration: 1066; Percent complete: 26.7%; Average loss: 3.0768\n",
            "Iteration: 1067; Percent complete: 26.7%; Average loss: 2.6920\n",
            "Iteration: 1068; Percent complete: 26.7%; Average loss: 2.8029\n",
            "Iteration: 1069; Percent complete: 26.7%; Average loss: 2.9348\n",
            "Iteration: 1070; Percent complete: 26.8%; Average loss: 2.8549\n",
            "Iteration: 1071; Percent complete: 26.8%; Average loss: 2.7105\n",
            "Iteration: 1072; Percent complete: 26.8%; Average loss: 2.7467\n",
            "Iteration: 1073; Percent complete: 26.8%; Average loss: 2.7290\n",
            "Iteration: 1074; Percent complete: 26.9%; Average loss: 2.7912\n",
            "Iteration: 1075; Percent complete: 26.9%; Average loss: 3.1494\n",
            "Iteration: 1076; Percent complete: 26.9%; Average loss: 3.1574\n",
            "Iteration: 1077; Percent complete: 26.9%; Average loss: 2.7545\n",
            "Iteration: 1078; Percent complete: 27.0%; Average loss: 2.6181\n",
            "Iteration: 1079; Percent complete: 27.0%; Average loss: 2.7838\n",
            "Iteration: 1080; Percent complete: 27.0%; Average loss: 3.0254\n",
            "Iteration: 1081; Percent complete: 27.0%; Average loss: 2.9719\n",
            "Iteration: 1082; Percent complete: 27.1%; Average loss: 2.7750\n",
            "Iteration: 1083; Percent complete: 27.1%; Average loss: 2.8768\n",
            "Iteration: 1084; Percent complete: 27.1%; Average loss: 2.6972\n",
            "Iteration: 1085; Percent complete: 27.1%; Average loss: 2.8172\n",
            "Iteration: 1086; Percent complete: 27.2%; Average loss: 2.8963\n",
            "Iteration: 1087; Percent complete: 27.2%; Average loss: 2.9850\n",
            "Iteration: 1088; Percent complete: 27.2%; Average loss: 2.9585\n",
            "Iteration: 1089; Percent complete: 27.2%; Average loss: 2.5513\n",
            "Iteration: 1090; Percent complete: 27.3%; Average loss: 3.0015\n",
            "Iteration: 1091; Percent complete: 27.3%; Average loss: 2.8455\n",
            "Iteration: 1092; Percent complete: 27.3%; Average loss: 2.6668\n",
            "Iteration: 1093; Percent complete: 27.3%; Average loss: 2.6879\n",
            "Iteration: 1094; Percent complete: 27.4%; Average loss: 2.9556\n",
            "Iteration: 1095; Percent complete: 27.4%; Average loss: 3.0377\n",
            "Iteration: 1096; Percent complete: 27.4%; Average loss: 3.0022\n",
            "Iteration: 1097; Percent complete: 27.4%; Average loss: 2.5377\n",
            "Iteration: 1098; Percent complete: 27.5%; Average loss: 3.1939\n",
            "Iteration: 1099; Percent complete: 27.5%; Average loss: 2.9250\n",
            "Iteration: 1100; Percent complete: 27.5%; Average loss: 2.8080\n",
            "Iteration: 1101; Percent complete: 27.5%; Average loss: 3.0212\n",
            "Iteration: 1102; Percent complete: 27.6%; Average loss: 2.9447\n",
            "Iteration: 1103; Percent complete: 27.6%; Average loss: 2.7978\n",
            "Iteration: 1104; Percent complete: 27.6%; Average loss: 2.7843\n",
            "Iteration: 1105; Percent complete: 27.6%; Average loss: 2.8992\n",
            "Iteration: 1106; Percent complete: 27.7%; Average loss: 2.7961\n",
            "Iteration: 1107; Percent complete: 27.7%; Average loss: 2.7791\n",
            "Iteration: 1108; Percent complete: 27.7%; Average loss: 2.8493\n",
            "Iteration: 1109; Percent complete: 27.7%; Average loss: 2.6532\n",
            "Iteration: 1110; Percent complete: 27.8%; Average loss: 2.7416\n",
            "Iteration: 1111; Percent complete: 27.8%; Average loss: 2.6200\n",
            "Iteration: 1112; Percent complete: 27.8%; Average loss: 2.9790\n",
            "Iteration: 1113; Percent complete: 27.8%; Average loss: 2.7170\n",
            "Iteration: 1114; Percent complete: 27.9%; Average loss: 3.0009\n",
            "Iteration: 1115; Percent complete: 27.9%; Average loss: 2.9415\n",
            "Iteration: 1116; Percent complete: 27.9%; Average loss: 2.9832\n",
            "Iteration: 1117; Percent complete: 27.9%; Average loss: 2.9866\n",
            "Iteration: 1118; Percent complete: 28.0%; Average loss: 2.7902\n",
            "Iteration: 1119; Percent complete: 28.0%; Average loss: 2.8343\n",
            "Iteration: 1120; Percent complete: 28.0%; Average loss: 2.7863\n",
            "Iteration: 1121; Percent complete: 28.0%; Average loss: 2.7833\n",
            "Iteration: 1122; Percent complete: 28.1%; Average loss: 2.5922\n",
            "Iteration: 1123; Percent complete: 28.1%; Average loss: 2.7872\n",
            "Iteration: 1124; Percent complete: 28.1%; Average loss: 2.8993\n",
            "Iteration: 1125; Percent complete: 28.1%; Average loss: 2.8272\n",
            "Iteration: 1126; Percent complete: 28.1%; Average loss: 2.9860\n",
            "Iteration: 1127; Percent complete: 28.2%; Average loss: 2.8165\n",
            "Iteration: 1128; Percent complete: 28.2%; Average loss: 2.6585\n",
            "Iteration: 1129; Percent complete: 28.2%; Average loss: 2.6742\n",
            "Iteration: 1130; Percent complete: 28.2%; Average loss: 2.5089\n",
            "Iteration: 1131; Percent complete: 28.3%; Average loss: 2.5427\n",
            "Iteration: 1132; Percent complete: 28.3%; Average loss: 2.9220\n",
            "Iteration: 1133; Percent complete: 28.3%; Average loss: 2.6743\n",
            "Iteration: 1134; Percent complete: 28.3%; Average loss: 2.9206\n",
            "Iteration: 1135; Percent complete: 28.4%; Average loss: 2.7667\n",
            "Iteration: 1136; Percent complete: 28.4%; Average loss: 2.7361\n",
            "Iteration: 1137; Percent complete: 28.4%; Average loss: 2.7288\n",
            "Iteration: 1138; Percent complete: 28.4%; Average loss: 2.9792\n",
            "Iteration: 1139; Percent complete: 28.5%; Average loss: 2.6064\n",
            "Iteration: 1140; Percent complete: 28.5%; Average loss: 2.7857\n",
            "Iteration: 1141; Percent complete: 28.5%; Average loss: 2.6243\n",
            "Iteration: 1142; Percent complete: 28.5%; Average loss: 2.7833\n",
            "Iteration: 1143; Percent complete: 28.6%; Average loss: 2.4478\n",
            "Iteration: 1144; Percent complete: 28.6%; Average loss: 2.8388\n",
            "Iteration: 1145; Percent complete: 28.6%; Average loss: 2.8002\n",
            "Iteration: 1146; Percent complete: 28.6%; Average loss: 2.6684\n",
            "Iteration: 1147; Percent complete: 28.7%; Average loss: 2.6379\n",
            "Iteration: 1148; Percent complete: 28.7%; Average loss: 2.4108\n",
            "Iteration: 1149; Percent complete: 28.7%; Average loss: 2.7689\n",
            "Iteration: 1150; Percent complete: 28.7%; Average loss: 2.7513\n",
            "Iteration: 1151; Percent complete: 28.8%; Average loss: 2.7418\n",
            "Iteration: 1152; Percent complete: 28.8%; Average loss: 2.9019\n",
            "Iteration: 1153; Percent complete: 28.8%; Average loss: 2.5549\n",
            "Iteration: 1154; Percent complete: 28.8%; Average loss: 2.6965\n",
            "Iteration: 1155; Percent complete: 28.9%; Average loss: 2.6322\n",
            "Iteration: 1156; Percent complete: 28.9%; Average loss: 2.9461\n",
            "Iteration: 1157; Percent complete: 28.9%; Average loss: 2.7552\n",
            "Iteration: 1158; Percent complete: 28.9%; Average loss: 2.6313\n",
            "Iteration: 1159; Percent complete: 29.0%; Average loss: 3.0133\n",
            "Iteration: 1160; Percent complete: 29.0%; Average loss: 2.6577\n",
            "Iteration: 1161; Percent complete: 29.0%; Average loss: 2.5693\n",
            "Iteration: 1162; Percent complete: 29.0%; Average loss: 2.4320\n",
            "Iteration: 1163; Percent complete: 29.1%; Average loss: 2.6958\n",
            "Iteration: 1164; Percent complete: 29.1%; Average loss: 2.5331\n",
            "Iteration: 1165; Percent complete: 29.1%; Average loss: 2.4999\n",
            "Iteration: 1166; Percent complete: 29.1%; Average loss: 2.5107\n",
            "Iteration: 1167; Percent complete: 29.2%; Average loss: 2.6333\n",
            "Iteration: 1168; Percent complete: 29.2%; Average loss: 3.0460\n",
            "Iteration: 1169; Percent complete: 29.2%; Average loss: 2.7645\n",
            "Iteration: 1170; Percent complete: 29.2%; Average loss: 2.8727\n",
            "Iteration: 1171; Percent complete: 29.3%; Average loss: 2.7407\n",
            "Iteration: 1172; Percent complete: 29.3%; Average loss: 2.4963\n",
            "Iteration: 1173; Percent complete: 29.3%; Average loss: 2.8258\n",
            "Iteration: 1174; Percent complete: 29.3%; Average loss: 2.6840\n",
            "Iteration: 1175; Percent complete: 29.4%; Average loss: 2.7154\n",
            "Iteration: 1176; Percent complete: 29.4%; Average loss: 2.8798\n",
            "Iteration: 1177; Percent complete: 29.4%; Average loss: 2.7433\n",
            "Iteration: 1178; Percent complete: 29.4%; Average loss: 2.8306\n",
            "Iteration: 1179; Percent complete: 29.5%; Average loss: 2.4941\n",
            "Iteration: 1180; Percent complete: 29.5%; Average loss: 2.8528\n",
            "Iteration: 1181; Percent complete: 29.5%; Average loss: 2.7777\n",
            "Iteration: 1182; Percent complete: 29.5%; Average loss: 2.6173\n",
            "Iteration: 1183; Percent complete: 29.6%; Average loss: 2.4674\n",
            "Iteration: 1184; Percent complete: 29.6%; Average loss: 2.8324\n",
            "Iteration: 1185; Percent complete: 29.6%; Average loss: 2.6098\n",
            "Iteration: 1186; Percent complete: 29.6%; Average loss: 2.7960\n",
            "Iteration: 1187; Percent complete: 29.7%; Average loss: 2.5290\n",
            "Iteration: 1188; Percent complete: 29.7%; Average loss: 2.5612\n",
            "Iteration: 1189; Percent complete: 29.7%; Average loss: 2.6677\n",
            "Iteration: 1190; Percent complete: 29.8%; Average loss: 2.7864\n",
            "Iteration: 1191; Percent complete: 29.8%; Average loss: 2.6184\n",
            "Iteration: 1192; Percent complete: 29.8%; Average loss: 2.6868\n",
            "Iteration: 1193; Percent complete: 29.8%; Average loss: 2.3453\n",
            "Iteration: 1194; Percent complete: 29.8%; Average loss: 2.5805\n",
            "Iteration: 1195; Percent complete: 29.9%; Average loss: 2.4856\n",
            "Iteration: 1196; Percent complete: 29.9%; Average loss: 2.3019\n",
            "Iteration: 1197; Percent complete: 29.9%; Average loss: 2.8944\n",
            "Iteration: 1198; Percent complete: 29.9%; Average loss: 2.5550\n",
            "Iteration: 1199; Percent complete: 30.0%; Average loss: 2.6082\n",
            "Iteration: 1200; Percent complete: 30.0%; Average loss: 2.4820\n",
            "Iteration: 1201; Percent complete: 30.0%; Average loss: 2.5646\n",
            "Iteration: 1202; Percent complete: 30.0%; Average loss: 2.6343\n",
            "Iteration: 1203; Percent complete: 30.1%; Average loss: 2.4292\n",
            "Iteration: 1204; Percent complete: 30.1%; Average loss: 2.7769\n",
            "Iteration: 1205; Percent complete: 30.1%; Average loss: 2.3308\n",
            "Iteration: 1206; Percent complete: 30.1%; Average loss: 2.5481\n",
            "Iteration: 1207; Percent complete: 30.2%; Average loss: 2.7224\n",
            "Iteration: 1208; Percent complete: 30.2%; Average loss: 2.7822\n",
            "Iteration: 1209; Percent complete: 30.2%; Average loss: 2.6395\n",
            "Iteration: 1210; Percent complete: 30.2%; Average loss: 2.5901\n",
            "Iteration: 1211; Percent complete: 30.3%; Average loss: 2.7101\n",
            "Iteration: 1212; Percent complete: 30.3%; Average loss: 2.5723\n",
            "Iteration: 1213; Percent complete: 30.3%; Average loss: 2.5245\n",
            "Iteration: 1214; Percent complete: 30.3%; Average loss: 2.5627\n",
            "Iteration: 1215; Percent complete: 30.4%; Average loss: 2.7478\n",
            "Iteration: 1216; Percent complete: 30.4%; Average loss: 2.3630\n",
            "Iteration: 1217; Percent complete: 30.4%; Average loss: 2.6813\n",
            "Iteration: 1218; Percent complete: 30.4%; Average loss: 2.6740\n",
            "Iteration: 1219; Percent complete: 30.5%; Average loss: 2.4420\n",
            "Iteration: 1220; Percent complete: 30.5%; Average loss: 2.5996\n",
            "Iteration: 1221; Percent complete: 30.5%; Average loss: 2.4785\n",
            "Iteration: 1222; Percent complete: 30.6%; Average loss: 2.8334\n",
            "Iteration: 1223; Percent complete: 30.6%; Average loss: 2.4986\n",
            "Iteration: 1224; Percent complete: 30.6%; Average loss: 2.3659\n",
            "Iteration: 1225; Percent complete: 30.6%; Average loss: 2.5960\n",
            "Iteration: 1226; Percent complete: 30.6%; Average loss: 2.6935\n",
            "Iteration: 1227; Percent complete: 30.7%; Average loss: 2.3689\n",
            "Iteration: 1228; Percent complete: 30.7%; Average loss: 2.5727\n",
            "Iteration: 1229; Percent complete: 30.7%; Average loss: 2.5414\n",
            "Iteration: 1230; Percent complete: 30.8%; Average loss: 2.4650\n",
            "Iteration: 1231; Percent complete: 30.8%; Average loss: 2.5876\n",
            "Iteration: 1232; Percent complete: 30.8%; Average loss: 2.6411\n",
            "Iteration: 1233; Percent complete: 30.8%; Average loss: 2.6001\n",
            "Iteration: 1234; Percent complete: 30.9%; Average loss: 2.7327\n",
            "Iteration: 1235; Percent complete: 30.9%; Average loss: 2.6115\n",
            "Iteration: 1236; Percent complete: 30.9%; Average loss: 2.3473\n",
            "Iteration: 1237; Percent complete: 30.9%; Average loss: 2.5556\n",
            "Iteration: 1238; Percent complete: 30.9%; Average loss: 2.4974\n",
            "Iteration: 1239; Percent complete: 31.0%; Average loss: 2.6860\n",
            "Iteration: 1240; Percent complete: 31.0%; Average loss: 2.6268\n",
            "Iteration: 1241; Percent complete: 31.0%; Average loss: 2.5213\n",
            "Iteration: 1242; Percent complete: 31.1%; Average loss: 2.5490\n",
            "Iteration: 1243; Percent complete: 31.1%; Average loss: 2.7208\n",
            "Iteration: 1244; Percent complete: 31.1%; Average loss: 2.4955\n",
            "Iteration: 1245; Percent complete: 31.1%; Average loss: 2.3813\n",
            "Iteration: 1246; Percent complete: 31.1%; Average loss: 2.5520\n",
            "Iteration: 1247; Percent complete: 31.2%; Average loss: 2.4936\n",
            "Iteration: 1248; Percent complete: 31.2%; Average loss: 2.5803\n",
            "Iteration: 1249; Percent complete: 31.2%; Average loss: 2.3870\n",
            "Iteration: 1250; Percent complete: 31.2%; Average loss: 2.7196\n",
            "Iteration: 1251; Percent complete: 31.3%; Average loss: 2.5071\n",
            "Iteration: 1252; Percent complete: 31.3%; Average loss: 2.6131\n",
            "Iteration: 1253; Percent complete: 31.3%; Average loss: 2.7616\n",
            "Iteration: 1254; Percent complete: 31.4%; Average loss: 2.3029\n",
            "Iteration: 1255; Percent complete: 31.4%; Average loss: 2.5990\n",
            "Iteration: 1256; Percent complete: 31.4%; Average loss: 2.1492\n",
            "Iteration: 1257; Percent complete: 31.4%; Average loss: 2.2388\n",
            "Iteration: 1258; Percent complete: 31.4%; Average loss: 2.5802\n",
            "Iteration: 1259; Percent complete: 31.5%; Average loss: 2.4649\n",
            "Iteration: 1260; Percent complete: 31.5%; Average loss: 2.5588\n",
            "Iteration: 1261; Percent complete: 31.5%; Average loss: 2.6323\n",
            "Iteration: 1262; Percent complete: 31.6%; Average loss: 2.5375\n",
            "Iteration: 1263; Percent complete: 31.6%; Average loss: 2.5215\n",
            "Iteration: 1264; Percent complete: 31.6%; Average loss: 2.3675\n",
            "Iteration: 1265; Percent complete: 31.6%; Average loss: 2.6157\n",
            "Iteration: 1266; Percent complete: 31.6%; Average loss: 2.5118\n",
            "Iteration: 1267; Percent complete: 31.7%; Average loss: 2.5712\n",
            "Iteration: 1268; Percent complete: 31.7%; Average loss: 2.5917\n",
            "Iteration: 1269; Percent complete: 31.7%; Average loss: 2.5201\n",
            "Iteration: 1270; Percent complete: 31.8%; Average loss: 2.6621\n",
            "Iteration: 1271; Percent complete: 31.8%; Average loss: 2.3966\n",
            "Iteration: 1272; Percent complete: 31.8%; Average loss: 2.5008\n",
            "Iteration: 1273; Percent complete: 31.8%; Average loss: 2.5725\n",
            "Iteration: 1274; Percent complete: 31.9%; Average loss: 2.3989\n",
            "Iteration: 1275; Percent complete: 31.9%; Average loss: 2.3795\n",
            "Iteration: 1276; Percent complete: 31.9%; Average loss: 2.5608\n",
            "Iteration: 1277; Percent complete: 31.9%; Average loss: 2.7001\n",
            "Iteration: 1278; Percent complete: 31.9%; Average loss: 2.6717\n",
            "Iteration: 1279; Percent complete: 32.0%; Average loss: 2.3764\n",
            "Iteration: 1280; Percent complete: 32.0%; Average loss: 2.3853\n",
            "Iteration: 1281; Percent complete: 32.0%; Average loss: 2.2480\n",
            "Iteration: 1282; Percent complete: 32.0%; Average loss: 2.7015\n",
            "Iteration: 1283; Percent complete: 32.1%; Average loss: 2.3789\n",
            "Iteration: 1284; Percent complete: 32.1%; Average loss: 2.7134\n",
            "Iteration: 1285; Percent complete: 32.1%; Average loss: 2.5282\n",
            "Iteration: 1286; Percent complete: 32.1%; Average loss: 2.3698\n",
            "Iteration: 1287; Percent complete: 32.2%; Average loss: 2.2779\n",
            "Iteration: 1288; Percent complete: 32.2%; Average loss: 2.6862\n",
            "Iteration: 1289; Percent complete: 32.2%; Average loss: 2.5218\n",
            "Iteration: 1290; Percent complete: 32.2%; Average loss: 2.6958\n",
            "Iteration: 1291; Percent complete: 32.3%; Average loss: 2.6835\n",
            "Iteration: 1292; Percent complete: 32.3%; Average loss: 2.6190\n",
            "Iteration: 1293; Percent complete: 32.3%; Average loss: 2.2426\n",
            "Iteration: 1294; Percent complete: 32.4%; Average loss: 2.5806\n",
            "Iteration: 1295; Percent complete: 32.4%; Average loss: 2.6846\n",
            "Iteration: 1296; Percent complete: 32.4%; Average loss: 2.4643\n",
            "Iteration: 1297; Percent complete: 32.4%; Average loss: 2.6205\n",
            "Iteration: 1298; Percent complete: 32.5%; Average loss: 2.3823\n",
            "Iteration: 1299; Percent complete: 32.5%; Average loss: 2.4448\n",
            "Iteration: 1300; Percent complete: 32.5%; Average loss: 2.3811\n",
            "Iteration: 1301; Percent complete: 32.5%; Average loss: 2.4003\n",
            "Iteration: 1302; Percent complete: 32.6%; Average loss: 2.5155\n",
            "Iteration: 1303; Percent complete: 32.6%; Average loss: 2.6899\n",
            "Iteration: 1304; Percent complete: 32.6%; Average loss: 2.4489\n",
            "Iteration: 1305; Percent complete: 32.6%; Average loss: 2.5132\n",
            "Iteration: 1306; Percent complete: 32.6%; Average loss: 2.4538\n",
            "Iteration: 1307; Percent complete: 32.7%; Average loss: 2.3364\n",
            "Iteration: 1308; Percent complete: 32.7%; Average loss: 2.2642\n",
            "Iteration: 1309; Percent complete: 32.7%; Average loss: 2.6663\n",
            "Iteration: 1310; Percent complete: 32.8%; Average loss: 2.5563\n",
            "Iteration: 1311; Percent complete: 32.8%; Average loss: 2.4389\n",
            "Iteration: 1312; Percent complete: 32.8%; Average loss: 2.3409\n",
            "Iteration: 1313; Percent complete: 32.8%; Average loss: 2.3996\n",
            "Iteration: 1314; Percent complete: 32.9%; Average loss: 2.4074\n",
            "Iteration: 1315; Percent complete: 32.9%; Average loss: 2.3046\n",
            "Iteration: 1316; Percent complete: 32.9%; Average loss: 2.3508\n",
            "Iteration: 1317; Percent complete: 32.9%; Average loss: 2.3364\n",
            "Iteration: 1318; Percent complete: 33.0%; Average loss: 2.4752\n",
            "Iteration: 1319; Percent complete: 33.0%; Average loss: 2.7123\n",
            "Iteration: 1320; Percent complete: 33.0%; Average loss: 2.2970\n",
            "Iteration: 1321; Percent complete: 33.0%; Average loss: 2.3896\n",
            "Iteration: 1322; Percent complete: 33.1%; Average loss: 2.4830\n",
            "Iteration: 1323; Percent complete: 33.1%; Average loss: 2.3951\n",
            "Iteration: 1324; Percent complete: 33.1%; Average loss: 2.3436\n",
            "Iteration: 1325; Percent complete: 33.1%; Average loss: 2.4464\n",
            "Iteration: 1326; Percent complete: 33.1%; Average loss: 2.2282\n",
            "Iteration: 1327; Percent complete: 33.2%; Average loss: 2.5144\n",
            "Iteration: 1328; Percent complete: 33.2%; Average loss: 2.4084\n",
            "Iteration: 1329; Percent complete: 33.2%; Average loss: 2.6194\n",
            "Iteration: 1330; Percent complete: 33.2%; Average loss: 2.4148\n",
            "Iteration: 1331; Percent complete: 33.3%; Average loss: 2.2679\n",
            "Iteration: 1332; Percent complete: 33.3%; Average loss: 2.7794\n",
            "Iteration: 1333; Percent complete: 33.3%; Average loss: 2.3966\n",
            "Iteration: 1334; Percent complete: 33.4%; Average loss: 2.3801\n",
            "Iteration: 1335; Percent complete: 33.4%; Average loss: 2.3576\n",
            "Iteration: 1336; Percent complete: 33.4%; Average loss: 2.2725\n",
            "Iteration: 1337; Percent complete: 33.4%; Average loss: 2.3871\n",
            "Iteration: 1338; Percent complete: 33.5%; Average loss: 2.3138\n",
            "Iteration: 1339; Percent complete: 33.5%; Average loss: 2.1311\n",
            "Iteration: 1340; Percent complete: 33.5%; Average loss: 2.2269\n",
            "Iteration: 1341; Percent complete: 33.5%; Average loss: 2.5152\n",
            "Iteration: 1342; Percent complete: 33.6%; Average loss: 2.1638\n",
            "Iteration: 1343; Percent complete: 33.6%; Average loss: 2.5576\n",
            "Iteration: 1344; Percent complete: 33.6%; Average loss: 2.2571\n",
            "Iteration: 1345; Percent complete: 33.6%; Average loss: 2.1979\n",
            "Iteration: 1346; Percent complete: 33.7%; Average loss: 2.4664\n",
            "Iteration: 1347; Percent complete: 33.7%; Average loss: 2.1979\n",
            "Iteration: 1348; Percent complete: 33.7%; Average loss: 2.2697\n",
            "Iteration: 1349; Percent complete: 33.7%; Average loss: 2.2936\n",
            "Iteration: 1350; Percent complete: 33.8%; Average loss: 2.0310\n",
            "Iteration: 1351; Percent complete: 33.8%; Average loss: 2.2643\n",
            "Iteration: 1352; Percent complete: 33.8%; Average loss: 2.3084\n",
            "Iteration: 1353; Percent complete: 33.8%; Average loss: 2.4634\n",
            "Iteration: 1354; Percent complete: 33.9%; Average loss: 2.2459\n",
            "Iteration: 1355; Percent complete: 33.9%; Average loss: 2.3578\n",
            "Iteration: 1356; Percent complete: 33.9%; Average loss: 2.3118\n",
            "Iteration: 1357; Percent complete: 33.9%; Average loss: 2.1378\n",
            "Iteration: 1358; Percent complete: 34.0%; Average loss: 2.3357\n",
            "Iteration: 1359; Percent complete: 34.0%; Average loss: 2.2165\n",
            "Iteration: 1360; Percent complete: 34.0%; Average loss: 2.1062\n",
            "Iteration: 1361; Percent complete: 34.0%; Average loss: 2.2452\n",
            "Iteration: 1362; Percent complete: 34.1%; Average loss: 2.3766\n",
            "Iteration: 1363; Percent complete: 34.1%; Average loss: 2.1214\n",
            "Iteration: 1364; Percent complete: 34.1%; Average loss: 2.4047\n",
            "Iteration: 1365; Percent complete: 34.1%; Average loss: 2.2077\n",
            "Iteration: 1366; Percent complete: 34.2%; Average loss: 2.1559\n",
            "Iteration: 1367; Percent complete: 34.2%; Average loss: 2.2052\n",
            "Iteration: 1368; Percent complete: 34.2%; Average loss: 2.3781\n",
            "Iteration: 1369; Percent complete: 34.2%; Average loss: 2.4561\n",
            "Iteration: 1370; Percent complete: 34.2%; Average loss: 2.4323\n",
            "Iteration: 1371; Percent complete: 34.3%; Average loss: 2.3222\n",
            "Iteration: 1372; Percent complete: 34.3%; Average loss: 2.5049\n",
            "Iteration: 1373; Percent complete: 34.3%; Average loss: 2.3125\n",
            "Iteration: 1374; Percent complete: 34.4%; Average loss: 2.1534\n",
            "Iteration: 1375; Percent complete: 34.4%; Average loss: 2.1551\n",
            "Iteration: 1376; Percent complete: 34.4%; Average loss: 2.3971\n",
            "Iteration: 1377; Percent complete: 34.4%; Average loss: 2.0736\n",
            "Iteration: 1378; Percent complete: 34.4%; Average loss: 2.2096\n",
            "Iteration: 1379; Percent complete: 34.5%; Average loss: 2.1337\n",
            "Iteration: 1380; Percent complete: 34.5%; Average loss: 2.3121\n",
            "Iteration: 1381; Percent complete: 34.5%; Average loss: 2.0451\n",
            "Iteration: 1382; Percent complete: 34.5%; Average loss: 2.1798\n",
            "Iteration: 1383; Percent complete: 34.6%; Average loss: 2.2998\n",
            "Iteration: 1384; Percent complete: 34.6%; Average loss: 2.3231\n",
            "Iteration: 1385; Percent complete: 34.6%; Average loss: 2.4702\n",
            "Iteration: 1386; Percent complete: 34.6%; Average loss: 2.2399\n",
            "Iteration: 1387; Percent complete: 34.7%; Average loss: 2.4932\n",
            "Iteration: 1388; Percent complete: 34.7%; Average loss: 2.3636\n",
            "Iteration: 1389; Percent complete: 34.7%; Average loss: 2.1392\n",
            "Iteration: 1390; Percent complete: 34.8%; Average loss: 2.3163\n",
            "Iteration: 1391; Percent complete: 34.8%; Average loss: 2.5500\n",
            "Iteration: 1392; Percent complete: 34.8%; Average loss: 2.2619\n",
            "Iteration: 1393; Percent complete: 34.8%; Average loss: 2.2701\n",
            "Iteration: 1394; Percent complete: 34.8%; Average loss: 2.4702\n",
            "Iteration: 1395; Percent complete: 34.9%; Average loss: 2.2526\n",
            "Iteration: 1396; Percent complete: 34.9%; Average loss: 2.2848\n",
            "Iteration: 1397; Percent complete: 34.9%; Average loss: 2.2689\n",
            "Iteration: 1398; Percent complete: 34.9%; Average loss: 2.1099\n",
            "Iteration: 1399; Percent complete: 35.0%; Average loss: 2.2316\n",
            "Iteration: 1400; Percent complete: 35.0%; Average loss: 2.0794\n",
            "Iteration: 1401; Percent complete: 35.0%; Average loss: 2.2464\n",
            "Iteration: 1402; Percent complete: 35.0%; Average loss: 2.3217\n",
            "Iteration: 1403; Percent complete: 35.1%; Average loss: 2.1553\n",
            "Iteration: 1404; Percent complete: 35.1%; Average loss: 2.0438\n",
            "Iteration: 1405; Percent complete: 35.1%; Average loss: 2.1946\n",
            "Iteration: 1406; Percent complete: 35.1%; Average loss: 1.9627\n",
            "Iteration: 1407; Percent complete: 35.2%; Average loss: 2.1211\n",
            "Iteration: 1408; Percent complete: 35.2%; Average loss: 2.3398\n",
            "Iteration: 1409; Percent complete: 35.2%; Average loss: 2.1257\n",
            "Iteration: 1410; Percent complete: 35.2%; Average loss: 2.2263\n",
            "Iteration: 1411; Percent complete: 35.3%; Average loss: 1.9930\n",
            "Iteration: 1412; Percent complete: 35.3%; Average loss: 2.1218\n",
            "Iteration: 1413; Percent complete: 35.3%; Average loss: 2.1920\n",
            "Iteration: 1414; Percent complete: 35.4%; Average loss: 2.0462\n",
            "Iteration: 1415; Percent complete: 35.4%; Average loss: 2.3573\n",
            "Iteration: 1416; Percent complete: 35.4%; Average loss: 2.4702\n",
            "Iteration: 1417; Percent complete: 35.4%; Average loss: 2.3173\n",
            "Iteration: 1418; Percent complete: 35.4%; Average loss: 2.2474\n",
            "Iteration: 1419; Percent complete: 35.5%; Average loss: 2.2785\n",
            "Iteration: 1420; Percent complete: 35.5%; Average loss: 2.3102\n",
            "Iteration: 1421; Percent complete: 35.5%; Average loss: 2.4691\n",
            "Iteration: 1422; Percent complete: 35.5%; Average loss: 2.1848\n",
            "Iteration: 1423; Percent complete: 35.6%; Average loss: 2.2356\n",
            "Iteration: 1424; Percent complete: 35.6%; Average loss: 2.3511\n",
            "Iteration: 1425; Percent complete: 35.6%; Average loss: 2.0527\n",
            "Iteration: 1426; Percent complete: 35.6%; Average loss: 2.1013\n",
            "Iteration: 1427; Percent complete: 35.7%; Average loss: 2.2328\n",
            "Iteration: 1428; Percent complete: 35.7%; Average loss: 2.1768\n",
            "Iteration: 1429; Percent complete: 35.7%; Average loss: 2.2918\n",
            "Iteration: 1430; Percent complete: 35.8%; Average loss: 2.0867\n",
            "Iteration: 1431; Percent complete: 35.8%; Average loss: 2.0441\n",
            "Iteration: 1432; Percent complete: 35.8%; Average loss: 2.1014\n",
            "Iteration: 1433; Percent complete: 35.8%; Average loss: 2.1342\n",
            "Iteration: 1434; Percent complete: 35.9%; Average loss: 2.2504\n",
            "Iteration: 1435; Percent complete: 35.9%; Average loss: 2.0741\n",
            "Iteration: 1436; Percent complete: 35.9%; Average loss: 2.1903\n",
            "Iteration: 1437; Percent complete: 35.9%; Average loss: 2.1017\n",
            "Iteration: 1438; Percent complete: 35.9%; Average loss: 2.0061\n",
            "Iteration: 1439; Percent complete: 36.0%; Average loss: 2.3335\n",
            "Iteration: 1440; Percent complete: 36.0%; Average loss: 2.0659\n",
            "Iteration: 1441; Percent complete: 36.0%; Average loss: 2.0185\n",
            "Iteration: 1442; Percent complete: 36.0%; Average loss: 2.2901\n",
            "Iteration: 1443; Percent complete: 36.1%; Average loss: 1.9584\n",
            "Iteration: 1444; Percent complete: 36.1%; Average loss: 2.0678\n",
            "Iteration: 1445; Percent complete: 36.1%; Average loss: 2.3867\n",
            "Iteration: 1446; Percent complete: 36.1%; Average loss: 1.8778\n",
            "Iteration: 1447; Percent complete: 36.2%; Average loss: 2.1882\n",
            "Iteration: 1448; Percent complete: 36.2%; Average loss: 2.1694\n",
            "Iteration: 1449; Percent complete: 36.2%; Average loss: 2.0673\n",
            "Iteration: 1450; Percent complete: 36.2%; Average loss: 1.9582\n",
            "Iteration: 1451; Percent complete: 36.3%; Average loss: 1.8737\n",
            "Iteration: 1452; Percent complete: 36.3%; Average loss: 2.2570\n",
            "Iteration: 1453; Percent complete: 36.3%; Average loss: 2.3062\n",
            "Iteration: 1454; Percent complete: 36.4%; Average loss: 2.0633\n",
            "Iteration: 1455; Percent complete: 36.4%; Average loss: 2.0709\n",
            "Iteration: 1456; Percent complete: 36.4%; Average loss: 1.8732\n",
            "Iteration: 1457; Percent complete: 36.4%; Average loss: 2.1811\n",
            "Iteration: 1458; Percent complete: 36.4%; Average loss: 2.0557\n",
            "Iteration: 1459; Percent complete: 36.5%; Average loss: 2.1494\n",
            "Iteration: 1460; Percent complete: 36.5%; Average loss: 2.0873\n",
            "Iteration: 1461; Percent complete: 36.5%; Average loss: 2.1736\n",
            "Iteration: 1462; Percent complete: 36.5%; Average loss: 1.9677\n",
            "Iteration: 1463; Percent complete: 36.6%; Average loss: 2.2287\n",
            "Iteration: 1464; Percent complete: 36.6%; Average loss: 2.0019\n",
            "Iteration: 1465; Percent complete: 36.6%; Average loss: 1.8813\n",
            "Iteration: 1466; Percent complete: 36.6%; Average loss: 2.1837\n",
            "Iteration: 1467; Percent complete: 36.7%; Average loss: 2.0353\n",
            "Iteration: 1468; Percent complete: 36.7%; Average loss: 2.0225\n",
            "Iteration: 1469; Percent complete: 36.7%; Average loss: 2.1379\n",
            "Iteration: 1470; Percent complete: 36.8%; Average loss: 2.1886\n",
            "Iteration: 1471; Percent complete: 36.8%; Average loss: 1.8515\n",
            "Iteration: 1472; Percent complete: 36.8%; Average loss: 2.3024\n",
            "Iteration: 1473; Percent complete: 36.8%; Average loss: 2.2519\n",
            "Iteration: 1474; Percent complete: 36.9%; Average loss: 1.9099\n",
            "Iteration: 1475; Percent complete: 36.9%; Average loss: 2.1485\n",
            "Iteration: 1476; Percent complete: 36.9%; Average loss: 2.3771\n",
            "Iteration: 1477; Percent complete: 36.9%; Average loss: 2.0221\n",
            "Iteration: 1478; Percent complete: 37.0%; Average loss: 2.0433\n",
            "Iteration: 1479; Percent complete: 37.0%; Average loss: 2.0038\n",
            "Iteration: 1480; Percent complete: 37.0%; Average loss: 2.0652\n",
            "Iteration: 1481; Percent complete: 37.0%; Average loss: 2.1600\n",
            "Iteration: 1482; Percent complete: 37.0%; Average loss: 2.1099\n",
            "Iteration: 1483; Percent complete: 37.1%; Average loss: 2.2554\n",
            "Iteration: 1484; Percent complete: 37.1%; Average loss: 1.9758\n",
            "Iteration: 1485; Percent complete: 37.1%; Average loss: 2.0972\n",
            "Iteration: 1486; Percent complete: 37.1%; Average loss: 1.9725\n",
            "Iteration: 1487; Percent complete: 37.2%; Average loss: 1.9148\n",
            "Iteration: 1488; Percent complete: 37.2%; Average loss: 2.1853\n",
            "Iteration: 1489; Percent complete: 37.2%; Average loss: 2.0530\n",
            "Iteration: 1490; Percent complete: 37.2%; Average loss: 2.2209\n",
            "Iteration: 1491; Percent complete: 37.3%; Average loss: 2.1220\n",
            "Iteration: 1492; Percent complete: 37.3%; Average loss: 1.9803\n",
            "Iteration: 1493; Percent complete: 37.3%; Average loss: 2.0037\n",
            "Iteration: 1494; Percent complete: 37.4%; Average loss: 2.1682\n",
            "Iteration: 1495; Percent complete: 37.4%; Average loss: 2.2058\n",
            "Iteration: 1496; Percent complete: 37.4%; Average loss: 2.0249\n",
            "Iteration: 1497; Percent complete: 37.4%; Average loss: 1.8596\n",
            "Iteration: 1498; Percent complete: 37.5%; Average loss: 2.0643\n",
            "Iteration: 1499; Percent complete: 37.5%; Average loss: 1.9948\n",
            "Iteration: 1500; Percent complete: 37.5%; Average loss: 2.0756\n",
            "Iteration: 1501; Percent complete: 37.5%; Average loss: 2.0656\n",
            "Iteration: 1502; Percent complete: 37.5%; Average loss: 1.9768\n",
            "Iteration: 1503; Percent complete: 37.6%; Average loss: 1.9642\n",
            "Iteration: 1504; Percent complete: 37.6%; Average loss: 2.1867\n",
            "Iteration: 1505; Percent complete: 37.6%; Average loss: 2.0914\n",
            "Iteration: 1506; Percent complete: 37.6%; Average loss: 2.1018\n",
            "Iteration: 1507; Percent complete: 37.7%; Average loss: 2.2234\n",
            "Iteration: 1508; Percent complete: 37.7%; Average loss: 1.9733\n",
            "Iteration: 1509; Percent complete: 37.7%; Average loss: 2.2488\n",
            "Iteration: 1510; Percent complete: 37.8%; Average loss: 1.8476\n",
            "Iteration: 1511; Percent complete: 37.8%; Average loss: 2.0869\n",
            "Iteration: 1512; Percent complete: 37.8%; Average loss: 2.2119\n",
            "Iteration: 1513; Percent complete: 37.8%; Average loss: 2.0739\n",
            "Iteration: 1514; Percent complete: 37.9%; Average loss: 1.8836\n",
            "Iteration: 1515; Percent complete: 37.9%; Average loss: 2.0912\n",
            "Iteration: 1516; Percent complete: 37.9%; Average loss: 2.1346\n",
            "Iteration: 1517; Percent complete: 37.9%; Average loss: 2.3058\n",
            "Iteration: 1518; Percent complete: 38.0%; Average loss: 2.1177\n",
            "Iteration: 1519; Percent complete: 38.0%; Average loss: 1.8793\n",
            "Iteration: 1520; Percent complete: 38.0%; Average loss: 1.7866\n",
            "Iteration: 1521; Percent complete: 38.0%; Average loss: 2.1744\n",
            "Iteration: 1522; Percent complete: 38.0%; Average loss: 1.8400\n",
            "Iteration: 1523; Percent complete: 38.1%; Average loss: 2.0557\n",
            "Iteration: 1524; Percent complete: 38.1%; Average loss: 1.9773\n",
            "Iteration: 1525; Percent complete: 38.1%; Average loss: 2.0219\n",
            "Iteration: 1526; Percent complete: 38.1%; Average loss: 1.7365\n",
            "Iteration: 1527; Percent complete: 38.2%; Average loss: 1.8515\n",
            "Iteration: 1528; Percent complete: 38.2%; Average loss: 1.8973\n",
            "Iteration: 1529; Percent complete: 38.2%; Average loss: 1.9433\n",
            "Iteration: 1530; Percent complete: 38.2%; Average loss: 1.9454\n",
            "Iteration: 1531; Percent complete: 38.3%; Average loss: 1.7995\n",
            "Iteration: 1532; Percent complete: 38.3%; Average loss: 2.1435\n",
            "Iteration: 1533; Percent complete: 38.3%; Average loss: 1.8798\n",
            "Iteration: 1534; Percent complete: 38.4%; Average loss: 1.7924\n",
            "Iteration: 1535; Percent complete: 38.4%; Average loss: 1.9551\n",
            "Iteration: 1536; Percent complete: 38.4%; Average loss: 1.9441\n",
            "Iteration: 1537; Percent complete: 38.4%; Average loss: 1.8815\n",
            "Iteration: 1538; Percent complete: 38.5%; Average loss: 1.9639\n",
            "Iteration: 1539; Percent complete: 38.5%; Average loss: 2.1011\n",
            "Iteration: 1540; Percent complete: 38.5%; Average loss: 2.0359\n",
            "Iteration: 1541; Percent complete: 38.5%; Average loss: 1.8825\n",
            "Iteration: 1542; Percent complete: 38.6%; Average loss: 2.0020\n",
            "Iteration: 1543; Percent complete: 38.6%; Average loss: 1.8936\n",
            "Iteration: 1544; Percent complete: 38.6%; Average loss: 1.7636\n",
            "Iteration: 1545; Percent complete: 38.6%; Average loss: 1.7712\n",
            "Iteration: 1546; Percent complete: 38.6%; Average loss: 1.8108\n",
            "Iteration: 1547; Percent complete: 38.7%; Average loss: 1.8954\n",
            "Iteration: 1548; Percent complete: 38.7%; Average loss: 1.8972\n",
            "Iteration: 1549; Percent complete: 38.7%; Average loss: 1.8530\n",
            "Iteration: 1550; Percent complete: 38.8%; Average loss: 1.7871\n",
            "Iteration: 1551; Percent complete: 38.8%; Average loss: 2.0324\n",
            "Iteration: 1552; Percent complete: 38.8%; Average loss: 2.0578\n",
            "Iteration: 1553; Percent complete: 38.8%; Average loss: 1.9946\n",
            "Iteration: 1554; Percent complete: 38.9%; Average loss: 1.8886\n",
            "Iteration: 1555; Percent complete: 38.9%; Average loss: 1.9014\n",
            "Iteration: 1556; Percent complete: 38.9%; Average loss: 1.9593\n",
            "Iteration: 1557; Percent complete: 38.9%; Average loss: 1.9740\n",
            "Iteration: 1558; Percent complete: 39.0%; Average loss: 1.9712\n",
            "Iteration: 1559; Percent complete: 39.0%; Average loss: 1.8760\n",
            "Iteration: 1560; Percent complete: 39.0%; Average loss: 1.9889\n",
            "Iteration: 1561; Percent complete: 39.0%; Average loss: 1.9752\n",
            "Iteration: 1562; Percent complete: 39.1%; Average loss: 2.0116\n",
            "Iteration: 1563; Percent complete: 39.1%; Average loss: 1.9767\n",
            "Iteration: 1564; Percent complete: 39.1%; Average loss: 1.8131\n",
            "Iteration: 1565; Percent complete: 39.1%; Average loss: 1.9201\n",
            "Iteration: 1566; Percent complete: 39.1%; Average loss: 1.7382\n",
            "Iteration: 1567; Percent complete: 39.2%; Average loss: 2.0867\n",
            "Iteration: 1568; Percent complete: 39.2%; Average loss: 1.9665\n",
            "Iteration: 1569; Percent complete: 39.2%; Average loss: 2.0088\n",
            "Iteration: 1570; Percent complete: 39.2%; Average loss: 1.8601\n",
            "Iteration: 1571; Percent complete: 39.3%; Average loss: 2.0220\n",
            "Iteration: 1572; Percent complete: 39.3%; Average loss: 1.9280\n",
            "Iteration: 1573; Percent complete: 39.3%; Average loss: 2.1678\n",
            "Iteration: 1574; Percent complete: 39.4%; Average loss: 1.8679\n",
            "Iteration: 1575; Percent complete: 39.4%; Average loss: 2.0641\n",
            "Iteration: 1576; Percent complete: 39.4%; Average loss: 1.9513\n",
            "Iteration: 1577; Percent complete: 39.4%; Average loss: 1.8337\n",
            "Iteration: 1578; Percent complete: 39.5%; Average loss: 1.9045\n",
            "Iteration: 1579; Percent complete: 39.5%; Average loss: 1.9673\n",
            "Iteration: 1580; Percent complete: 39.5%; Average loss: 2.2727\n",
            "Iteration: 1581; Percent complete: 39.5%; Average loss: 1.8747\n",
            "Iteration: 1582; Percent complete: 39.6%; Average loss: 2.0509\n",
            "Iteration: 1583; Percent complete: 39.6%; Average loss: 1.8392\n",
            "Iteration: 1584; Percent complete: 39.6%; Average loss: 1.9588\n",
            "Iteration: 1585; Percent complete: 39.6%; Average loss: 2.0216\n",
            "Iteration: 1586; Percent complete: 39.6%; Average loss: 2.0023\n",
            "Iteration: 1587; Percent complete: 39.7%; Average loss: 1.7174\n",
            "Iteration: 1588; Percent complete: 39.7%; Average loss: 1.8675\n",
            "Iteration: 1589; Percent complete: 39.7%; Average loss: 1.9696\n",
            "Iteration: 1590; Percent complete: 39.8%; Average loss: 1.8273\n",
            "Iteration: 1591; Percent complete: 39.8%; Average loss: 2.0034\n",
            "Iteration: 1592; Percent complete: 39.8%; Average loss: 1.9060\n",
            "Iteration: 1593; Percent complete: 39.8%; Average loss: 2.0323\n",
            "Iteration: 1594; Percent complete: 39.9%; Average loss: 1.9867\n",
            "Iteration: 1595; Percent complete: 39.9%; Average loss: 1.9284\n",
            "Iteration: 1596; Percent complete: 39.9%; Average loss: 1.8075\n",
            "Iteration: 1597; Percent complete: 39.9%; Average loss: 1.8427\n",
            "Iteration: 1598; Percent complete: 40.0%; Average loss: 2.1141\n",
            "Iteration: 1599; Percent complete: 40.0%; Average loss: 2.0204\n",
            "Iteration: 1600; Percent complete: 40.0%; Average loss: 1.9190\n",
            "Iteration: 1601; Percent complete: 40.0%; Average loss: 1.9837\n",
            "Iteration: 1602; Percent complete: 40.1%; Average loss: 1.9666\n",
            "Iteration: 1603; Percent complete: 40.1%; Average loss: 1.8526\n",
            "Iteration: 1604; Percent complete: 40.1%; Average loss: 1.6779\n",
            "Iteration: 1605; Percent complete: 40.1%; Average loss: 1.9735\n",
            "Iteration: 1606; Percent complete: 40.2%; Average loss: 2.0601\n",
            "Iteration: 1607; Percent complete: 40.2%; Average loss: 1.6830\n",
            "Iteration: 1608; Percent complete: 40.2%; Average loss: 1.8071\n",
            "Iteration: 1609; Percent complete: 40.2%; Average loss: 1.8201\n",
            "Iteration: 1610; Percent complete: 40.2%; Average loss: 1.9003\n",
            "Iteration: 1611; Percent complete: 40.3%; Average loss: 1.8260\n",
            "Iteration: 1612; Percent complete: 40.3%; Average loss: 1.7184\n",
            "Iteration: 1613; Percent complete: 40.3%; Average loss: 1.9229\n",
            "Iteration: 1614; Percent complete: 40.4%; Average loss: 1.9421\n",
            "Iteration: 1615; Percent complete: 40.4%; Average loss: 1.7706\n",
            "Iteration: 1616; Percent complete: 40.4%; Average loss: 1.6828\n",
            "Iteration: 1617; Percent complete: 40.4%; Average loss: 1.7296\n",
            "Iteration: 1618; Percent complete: 40.5%; Average loss: 1.8226\n",
            "Iteration: 1619; Percent complete: 40.5%; Average loss: 1.9436\n",
            "Iteration: 1620; Percent complete: 40.5%; Average loss: 1.7955\n",
            "Iteration: 1621; Percent complete: 40.5%; Average loss: 1.6467\n",
            "Iteration: 1622; Percent complete: 40.6%; Average loss: 1.7592\n",
            "Iteration: 1623; Percent complete: 40.6%; Average loss: 1.6508\n",
            "Iteration: 1624; Percent complete: 40.6%; Average loss: 2.0133\n",
            "Iteration: 1625; Percent complete: 40.6%; Average loss: 1.9463\n",
            "Iteration: 1626; Percent complete: 40.6%; Average loss: 1.8903\n",
            "Iteration: 1627; Percent complete: 40.7%; Average loss: 1.6500\n",
            "Iteration: 1628; Percent complete: 40.7%; Average loss: 1.8404\n",
            "Iteration: 1629; Percent complete: 40.7%; Average loss: 1.6885\n",
            "Iteration: 1630; Percent complete: 40.8%; Average loss: 1.8026\n",
            "Iteration: 1631; Percent complete: 40.8%; Average loss: 1.7095\n",
            "Iteration: 1632; Percent complete: 40.8%; Average loss: 1.7726\n",
            "Iteration: 1633; Percent complete: 40.8%; Average loss: 1.7161\n",
            "Iteration: 1634; Percent complete: 40.8%; Average loss: 1.8145\n",
            "Iteration: 1635; Percent complete: 40.9%; Average loss: 1.7349\n",
            "Iteration: 1636; Percent complete: 40.9%; Average loss: 1.8237\n",
            "Iteration: 1637; Percent complete: 40.9%; Average loss: 1.6771\n",
            "Iteration: 1638; Percent complete: 40.9%; Average loss: 1.6554\n",
            "Iteration: 1639; Percent complete: 41.0%; Average loss: 1.7653\n",
            "Iteration: 1640; Percent complete: 41.0%; Average loss: 1.9695\n",
            "Iteration: 1641; Percent complete: 41.0%; Average loss: 1.7773\n",
            "Iteration: 1642; Percent complete: 41.0%; Average loss: 1.6225\n",
            "Iteration: 1643; Percent complete: 41.1%; Average loss: 1.6671\n",
            "Iteration: 1644; Percent complete: 41.1%; Average loss: 1.6470\n",
            "Iteration: 1645; Percent complete: 41.1%; Average loss: 1.7044\n",
            "Iteration: 1646; Percent complete: 41.1%; Average loss: 1.7672\n",
            "Iteration: 1647; Percent complete: 41.2%; Average loss: 1.7822\n",
            "Iteration: 1648; Percent complete: 41.2%; Average loss: 1.8462\n",
            "Iteration: 1649; Percent complete: 41.2%; Average loss: 1.7679\n",
            "Iteration: 1650; Percent complete: 41.2%; Average loss: 1.6164\n",
            "Iteration: 1651; Percent complete: 41.3%; Average loss: 1.6166\n",
            "Iteration: 1652; Percent complete: 41.3%; Average loss: 1.6778\n",
            "Iteration: 1653; Percent complete: 41.3%; Average loss: 1.5159\n",
            "Iteration: 1654; Percent complete: 41.3%; Average loss: 1.7633\n",
            "Iteration: 1655; Percent complete: 41.4%; Average loss: 1.8278\n",
            "Iteration: 1656; Percent complete: 41.4%; Average loss: 1.6427\n",
            "Iteration: 1657; Percent complete: 41.4%; Average loss: 1.7566\n",
            "Iteration: 1658; Percent complete: 41.4%; Average loss: 1.8336\n",
            "Iteration: 1659; Percent complete: 41.5%; Average loss: 1.9246\n",
            "Iteration: 1660; Percent complete: 41.5%; Average loss: 1.9365\n",
            "Iteration: 1661; Percent complete: 41.5%; Average loss: 1.7057\n",
            "Iteration: 1662; Percent complete: 41.5%; Average loss: 1.6632\n",
            "Iteration: 1663; Percent complete: 41.6%; Average loss: 1.8721\n",
            "Iteration: 1664; Percent complete: 41.6%; Average loss: 1.6363\n",
            "Iteration: 1665; Percent complete: 41.6%; Average loss: 1.9194\n",
            "Iteration: 1666; Percent complete: 41.6%; Average loss: 1.9209\n",
            "Iteration: 1667; Percent complete: 41.7%; Average loss: 1.6289\n",
            "Iteration: 1668; Percent complete: 41.7%; Average loss: 1.6718\n",
            "Iteration: 1669; Percent complete: 41.7%; Average loss: 1.8455\n",
            "Iteration: 1670; Percent complete: 41.8%; Average loss: 1.6894\n",
            "Iteration: 1671; Percent complete: 41.8%; Average loss: 1.6281\n",
            "Iteration: 1672; Percent complete: 41.8%; Average loss: 1.7025\n",
            "Iteration: 1673; Percent complete: 41.8%; Average loss: 1.6636\n",
            "Iteration: 1674; Percent complete: 41.9%; Average loss: 1.7847\n",
            "Iteration: 1675; Percent complete: 41.9%; Average loss: 1.5423\n",
            "Iteration: 1676; Percent complete: 41.9%; Average loss: 1.7414\n",
            "Iteration: 1677; Percent complete: 41.9%; Average loss: 1.8584\n",
            "Iteration: 1678; Percent complete: 41.9%; Average loss: 1.7314\n",
            "Iteration: 1679; Percent complete: 42.0%; Average loss: 1.7690\n",
            "Iteration: 1680; Percent complete: 42.0%; Average loss: 1.5727\n",
            "Iteration: 1681; Percent complete: 42.0%; Average loss: 1.6847\n",
            "Iteration: 1682; Percent complete: 42.0%; Average loss: 1.7753\n",
            "Iteration: 1683; Percent complete: 42.1%; Average loss: 1.7961\n",
            "Iteration: 1684; Percent complete: 42.1%; Average loss: 1.7720\n",
            "Iteration: 1685; Percent complete: 42.1%; Average loss: 1.8627\n",
            "Iteration: 1686; Percent complete: 42.1%; Average loss: 1.8166\n",
            "Iteration: 1687; Percent complete: 42.2%; Average loss: 1.7132\n",
            "Iteration: 1688; Percent complete: 42.2%; Average loss: 1.8576\n",
            "Iteration: 1689; Percent complete: 42.2%; Average loss: 1.8338\n",
            "Iteration: 1690; Percent complete: 42.2%; Average loss: 1.7709\n",
            "Iteration: 1691; Percent complete: 42.3%; Average loss: 1.8591\n",
            "Iteration: 1692; Percent complete: 42.3%; Average loss: 1.6761\n",
            "Iteration: 1693; Percent complete: 42.3%; Average loss: 1.8109\n",
            "Iteration: 1694; Percent complete: 42.4%; Average loss: 1.8356\n",
            "Iteration: 1695; Percent complete: 42.4%; Average loss: 1.6573\n",
            "Iteration: 1696; Percent complete: 42.4%; Average loss: 1.6537\n",
            "Iteration: 1697; Percent complete: 42.4%; Average loss: 1.5833\n",
            "Iteration: 1698; Percent complete: 42.4%; Average loss: 1.6404\n",
            "Iteration: 1699; Percent complete: 42.5%; Average loss: 1.5115\n",
            "Iteration: 1700; Percent complete: 42.5%; Average loss: 1.7829\n",
            "Iteration: 1701; Percent complete: 42.5%; Average loss: 1.5308\n",
            "Iteration: 1702; Percent complete: 42.5%; Average loss: 1.6956\n",
            "Iteration: 1703; Percent complete: 42.6%; Average loss: 1.8015\n",
            "Iteration: 1704; Percent complete: 42.6%; Average loss: 1.5620\n",
            "Iteration: 1705; Percent complete: 42.6%; Average loss: 1.6937\n",
            "Iteration: 1706; Percent complete: 42.6%; Average loss: 1.6873\n",
            "Iteration: 1707; Percent complete: 42.7%; Average loss: 1.7930\n",
            "Iteration: 1708; Percent complete: 42.7%; Average loss: 1.8232\n",
            "Iteration: 1709; Percent complete: 42.7%; Average loss: 1.6740\n",
            "Iteration: 1710; Percent complete: 42.8%; Average loss: 1.5578\n",
            "Iteration: 1711; Percent complete: 42.8%; Average loss: 1.6799\n",
            "Iteration: 1712; Percent complete: 42.8%; Average loss: 1.6693\n",
            "Iteration: 1713; Percent complete: 42.8%; Average loss: 1.5637\n",
            "Iteration: 1714; Percent complete: 42.9%; Average loss: 1.9028\n",
            "Iteration: 1715; Percent complete: 42.9%; Average loss: 1.6866\n",
            "Iteration: 1716; Percent complete: 42.9%; Average loss: 1.8070\n",
            "Iteration: 1717; Percent complete: 42.9%; Average loss: 1.5765\n",
            "Iteration: 1718; Percent complete: 43.0%; Average loss: 1.6185\n",
            "Iteration: 1719; Percent complete: 43.0%; Average loss: 1.6856\n",
            "Iteration: 1720; Percent complete: 43.0%; Average loss: 1.6565\n",
            "Iteration: 1721; Percent complete: 43.0%; Average loss: 1.6501\n",
            "Iteration: 1722; Percent complete: 43.0%; Average loss: 1.5999\n",
            "Iteration: 1723; Percent complete: 43.1%; Average loss: 1.7792\n",
            "Iteration: 1724; Percent complete: 43.1%; Average loss: 1.7699\n",
            "Iteration: 1725; Percent complete: 43.1%; Average loss: 1.6130\n",
            "Iteration: 1726; Percent complete: 43.1%; Average loss: 1.6306\n",
            "Iteration: 1727; Percent complete: 43.2%; Average loss: 1.6159\n",
            "Iteration: 1728; Percent complete: 43.2%; Average loss: 1.7244\n",
            "Iteration: 1729; Percent complete: 43.2%; Average loss: 1.5854\n",
            "Iteration: 1730; Percent complete: 43.2%; Average loss: 1.3949\n",
            "Iteration: 1731; Percent complete: 43.3%; Average loss: 1.6600\n",
            "Iteration: 1732; Percent complete: 43.3%; Average loss: 1.6210\n",
            "Iteration: 1733; Percent complete: 43.3%; Average loss: 1.7641\n",
            "Iteration: 1734; Percent complete: 43.4%; Average loss: 1.6062\n",
            "Iteration: 1735; Percent complete: 43.4%; Average loss: 1.5917\n",
            "Iteration: 1736; Percent complete: 43.4%; Average loss: 1.4978\n",
            "Iteration: 1737; Percent complete: 43.4%; Average loss: 1.6454\n",
            "Iteration: 1738; Percent complete: 43.5%; Average loss: 1.5307\n",
            "Iteration: 1739; Percent complete: 43.5%; Average loss: 1.5622\n",
            "Iteration: 1740; Percent complete: 43.5%; Average loss: 1.5437\n",
            "Iteration: 1741; Percent complete: 43.5%; Average loss: 1.5154\n",
            "Iteration: 1742; Percent complete: 43.5%; Average loss: 1.7044\n",
            "Iteration: 1743; Percent complete: 43.6%; Average loss: 1.7112\n",
            "Iteration: 1744; Percent complete: 43.6%; Average loss: 1.7027\n",
            "Iteration: 1745; Percent complete: 43.6%; Average loss: 1.5736\n",
            "Iteration: 1746; Percent complete: 43.6%; Average loss: 1.7336\n",
            "Iteration: 1747; Percent complete: 43.7%; Average loss: 1.7635\n",
            "Iteration: 1748; Percent complete: 43.7%; Average loss: 1.4429\n",
            "Iteration: 1749; Percent complete: 43.7%; Average loss: 1.5914\n",
            "Iteration: 1750; Percent complete: 43.8%; Average loss: 1.5207\n",
            "Iteration: 1751; Percent complete: 43.8%; Average loss: 1.5717\n",
            "Iteration: 1752; Percent complete: 43.8%; Average loss: 1.5258\n",
            "Iteration: 1753; Percent complete: 43.8%; Average loss: 1.5664\n",
            "Iteration: 1754; Percent complete: 43.9%; Average loss: 1.5489\n",
            "Iteration: 1755; Percent complete: 43.9%; Average loss: 1.6385\n",
            "Iteration: 1756; Percent complete: 43.9%; Average loss: 1.6308\n",
            "Iteration: 1757; Percent complete: 43.9%; Average loss: 1.6048\n",
            "Iteration: 1758; Percent complete: 44.0%; Average loss: 1.5808\n",
            "Iteration: 1759; Percent complete: 44.0%; Average loss: 1.7647\n",
            "Iteration: 1760; Percent complete: 44.0%; Average loss: 1.6968\n",
            "Iteration: 1761; Percent complete: 44.0%; Average loss: 1.6948\n",
            "Iteration: 1762; Percent complete: 44.0%; Average loss: 1.5896\n",
            "Iteration: 1763; Percent complete: 44.1%; Average loss: 1.6139\n",
            "Iteration: 1764; Percent complete: 44.1%; Average loss: 1.5298\n",
            "Iteration: 1765; Percent complete: 44.1%; Average loss: 1.7337\n",
            "Iteration: 1766; Percent complete: 44.1%; Average loss: 1.6336\n",
            "Iteration: 1767; Percent complete: 44.2%; Average loss: 1.6341\n",
            "Iteration: 1768; Percent complete: 44.2%; Average loss: 1.6257\n",
            "Iteration: 1769; Percent complete: 44.2%; Average loss: 1.6112\n",
            "Iteration: 1770; Percent complete: 44.2%; Average loss: 1.6306\n",
            "Iteration: 1771; Percent complete: 44.3%; Average loss: 1.4180\n",
            "Iteration: 1772; Percent complete: 44.3%; Average loss: 1.5082\n",
            "Iteration: 1773; Percent complete: 44.3%; Average loss: 1.5005\n",
            "Iteration: 1774; Percent complete: 44.4%; Average loss: 1.5991\n",
            "Iteration: 1775; Percent complete: 44.4%; Average loss: 1.4790\n",
            "Iteration: 1776; Percent complete: 44.4%; Average loss: 1.5321\n",
            "Iteration: 1777; Percent complete: 44.4%; Average loss: 1.5451\n",
            "Iteration: 1778; Percent complete: 44.5%; Average loss: 1.5169\n",
            "Iteration: 1779; Percent complete: 44.5%; Average loss: 1.5604\n",
            "Iteration: 1780; Percent complete: 44.5%; Average loss: 1.5336\n",
            "Iteration: 1781; Percent complete: 44.5%; Average loss: 1.6443\n",
            "Iteration: 1782; Percent complete: 44.5%; Average loss: 1.6970\n",
            "Iteration: 1783; Percent complete: 44.6%; Average loss: 1.5425\n",
            "Iteration: 1784; Percent complete: 44.6%; Average loss: 1.6186\n",
            "Iteration: 1785; Percent complete: 44.6%; Average loss: 1.4651\n",
            "Iteration: 1786; Percent complete: 44.6%; Average loss: 1.4624\n",
            "Iteration: 1787; Percent complete: 44.7%; Average loss: 1.4583\n",
            "Iteration: 1788; Percent complete: 44.7%; Average loss: 1.5267\n",
            "Iteration: 1789; Percent complete: 44.7%; Average loss: 1.4907\n",
            "Iteration: 1790; Percent complete: 44.8%; Average loss: 1.6206\n",
            "Iteration: 1791; Percent complete: 44.8%; Average loss: 1.5633\n",
            "Iteration: 1792; Percent complete: 44.8%; Average loss: 1.6283\n",
            "Iteration: 1793; Percent complete: 44.8%; Average loss: 1.4155\n",
            "Iteration: 1794; Percent complete: 44.9%; Average loss: 1.6889\n",
            "Iteration: 1795; Percent complete: 44.9%; Average loss: 1.3644\n",
            "Iteration: 1796; Percent complete: 44.9%; Average loss: 1.5246\n",
            "Iteration: 1797; Percent complete: 44.9%; Average loss: 1.4556\n",
            "Iteration: 1798; Percent complete: 45.0%; Average loss: 1.7235\n",
            "Iteration: 1799; Percent complete: 45.0%; Average loss: 1.6402\n",
            "Iteration: 1800; Percent complete: 45.0%; Average loss: 1.5038\n",
            "Iteration: 1801; Percent complete: 45.0%; Average loss: 1.6294\n",
            "Iteration: 1802; Percent complete: 45.1%; Average loss: 1.5439\n",
            "Iteration: 1803; Percent complete: 45.1%; Average loss: 1.7805\n",
            "Iteration: 1804; Percent complete: 45.1%; Average loss: 1.6109\n",
            "Iteration: 1805; Percent complete: 45.1%; Average loss: 1.4052\n",
            "Iteration: 1806; Percent complete: 45.1%; Average loss: 1.5477\n",
            "Iteration: 1807; Percent complete: 45.2%; Average loss: 1.4154\n",
            "Iteration: 1808; Percent complete: 45.2%; Average loss: 1.4294\n",
            "Iteration: 1809; Percent complete: 45.2%; Average loss: 1.5978\n",
            "Iteration: 1810; Percent complete: 45.2%; Average loss: 1.5552\n",
            "Iteration: 1811; Percent complete: 45.3%; Average loss: 1.5574\n",
            "Iteration: 1812; Percent complete: 45.3%; Average loss: 1.5729\n",
            "Iteration: 1813; Percent complete: 45.3%; Average loss: 1.2889\n",
            "Iteration: 1814; Percent complete: 45.4%; Average loss: 1.4355\n",
            "Iteration: 1815; Percent complete: 45.4%; Average loss: 1.6514\n",
            "Iteration: 1816; Percent complete: 45.4%; Average loss: 1.6794\n",
            "Iteration: 1817; Percent complete: 45.4%; Average loss: 1.4294\n",
            "Iteration: 1818; Percent complete: 45.5%; Average loss: 1.4277\n",
            "Iteration: 1819; Percent complete: 45.5%; Average loss: 1.6144\n",
            "Iteration: 1820; Percent complete: 45.5%; Average loss: 1.2650\n",
            "Iteration: 1821; Percent complete: 45.5%; Average loss: 1.6787\n",
            "Iteration: 1822; Percent complete: 45.6%; Average loss: 1.6008\n",
            "Iteration: 1823; Percent complete: 45.6%; Average loss: 1.4583\n",
            "Iteration: 1824; Percent complete: 45.6%; Average loss: 1.5267\n",
            "Iteration: 1825; Percent complete: 45.6%; Average loss: 1.5546\n",
            "Iteration: 1826; Percent complete: 45.6%; Average loss: 1.3160\n",
            "Iteration: 1827; Percent complete: 45.7%; Average loss: 1.4273\n",
            "Iteration: 1828; Percent complete: 45.7%; Average loss: 1.4729\n",
            "Iteration: 1829; Percent complete: 45.7%; Average loss: 1.4853\n",
            "Iteration: 1830; Percent complete: 45.8%; Average loss: 1.4526\n",
            "Iteration: 1831; Percent complete: 45.8%; Average loss: 1.3190\n",
            "Iteration: 1832; Percent complete: 45.8%; Average loss: 1.5844\n",
            "Iteration: 1833; Percent complete: 45.8%; Average loss: 1.4349\n",
            "Iteration: 1834; Percent complete: 45.9%; Average loss: 1.3837\n",
            "Iteration: 1835; Percent complete: 45.9%; Average loss: 1.3495\n",
            "Iteration: 1836; Percent complete: 45.9%; Average loss: 1.4273\n",
            "Iteration: 1837; Percent complete: 45.9%; Average loss: 1.4983\n",
            "Iteration: 1838; Percent complete: 46.0%; Average loss: 1.5021\n",
            "Iteration: 1839; Percent complete: 46.0%; Average loss: 1.4789\n",
            "Iteration: 1840; Percent complete: 46.0%; Average loss: 1.4040\n",
            "Iteration: 1841; Percent complete: 46.0%; Average loss: 1.4082\n",
            "Iteration: 1842; Percent complete: 46.1%; Average loss: 1.4197\n",
            "Iteration: 1843; Percent complete: 46.1%; Average loss: 1.4909\n",
            "Iteration: 1844; Percent complete: 46.1%; Average loss: 1.5614\n",
            "Iteration: 1845; Percent complete: 46.1%; Average loss: 1.3534\n",
            "Iteration: 1846; Percent complete: 46.2%; Average loss: 1.4855\n",
            "Iteration: 1847; Percent complete: 46.2%; Average loss: 1.6671\n",
            "Iteration: 1848; Percent complete: 46.2%; Average loss: 1.3393\n",
            "Iteration: 1849; Percent complete: 46.2%; Average loss: 1.3787\n",
            "Iteration: 1850; Percent complete: 46.2%; Average loss: 1.5220\n",
            "Iteration: 1851; Percent complete: 46.3%; Average loss: 1.5961\n",
            "Iteration: 1852; Percent complete: 46.3%; Average loss: 1.4874\n",
            "Iteration: 1853; Percent complete: 46.3%; Average loss: 1.3340\n",
            "Iteration: 1854; Percent complete: 46.4%; Average loss: 1.5148\n",
            "Iteration: 1855; Percent complete: 46.4%; Average loss: 1.5200\n",
            "Iteration: 1856; Percent complete: 46.4%; Average loss: 1.3826\n",
            "Iteration: 1857; Percent complete: 46.4%; Average loss: 1.3895\n",
            "Iteration: 1858; Percent complete: 46.5%; Average loss: 1.3470\n",
            "Iteration: 1859; Percent complete: 46.5%; Average loss: 1.4644\n",
            "Iteration: 1860; Percent complete: 46.5%; Average loss: 1.7008\n",
            "Iteration: 1861; Percent complete: 46.5%; Average loss: 1.5145\n",
            "Iteration: 1862; Percent complete: 46.6%; Average loss: 1.5144\n",
            "Iteration: 1863; Percent complete: 46.6%; Average loss: 1.4306\n",
            "Iteration: 1864; Percent complete: 46.6%; Average loss: 1.4890\n",
            "Iteration: 1865; Percent complete: 46.6%; Average loss: 1.3269\n",
            "Iteration: 1866; Percent complete: 46.7%; Average loss: 1.4696\n",
            "Iteration: 1867; Percent complete: 46.7%; Average loss: 1.4106\n",
            "Iteration: 1868; Percent complete: 46.7%; Average loss: 1.4469\n",
            "Iteration: 1869; Percent complete: 46.7%; Average loss: 1.2988\n",
            "Iteration: 1870; Percent complete: 46.8%; Average loss: 1.4547\n",
            "Iteration: 1871; Percent complete: 46.8%; Average loss: 1.4338\n",
            "Iteration: 1872; Percent complete: 46.8%; Average loss: 1.3954\n",
            "Iteration: 1873; Percent complete: 46.8%; Average loss: 1.3780\n",
            "Iteration: 1874; Percent complete: 46.9%; Average loss: 1.3183\n",
            "Iteration: 1875; Percent complete: 46.9%; Average loss: 1.5058\n",
            "Iteration: 1876; Percent complete: 46.9%; Average loss: 1.2795\n",
            "Iteration: 1877; Percent complete: 46.9%; Average loss: 1.4001\n",
            "Iteration: 1878; Percent complete: 46.9%; Average loss: 1.4513\n",
            "Iteration: 1879; Percent complete: 47.0%; Average loss: 1.4719\n",
            "Iteration: 1880; Percent complete: 47.0%; Average loss: 1.4199\n",
            "Iteration: 1881; Percent complete: 47.0%; Average loss: 1.3718\n",
            "Iteration: 1882; Percent complete: 47.0%; Average loss: 1.2608\n",
            "Iteration: 1883; Percent complete: 47.1%; Average loss: 1.5344\n",
            "Iteration: 1884; Percent complete: 47.1%; Average loss: 1.4902\n",
            "Iteration: 1885; Percent complete: 47.1%; Average loss: 1.2473\n",
            "Iteration: 1886; Percent complete: 47.1%; Average loss: 1.1884\n",
            "Iteration: 1887; Percent complete: 47.2%; Average loss: 1.3607\n",
            "Iteration: 1888; Percent complete: 47.2%; Average loss: 1.6053\n",
            "Iteration: 1889; Percent complete: 47.2%; Average loss: 1.3689\n",
            "Iteration: 1890; Percent complete: 47.2%; Average loss: 1.4184\n",
            "Iteration: 1891; Percent complete: 47.3%; Average loss: 1.2943\n",
            "Iteration: 1892; Percent complete: 47.3%; Average loss: 1.6245\n",
            "Iteration: 1893; Percent complete: 47.3%; Average loss: 1.3746\n",
            "Iteration: 1894; Percent complete: 47.3%; Average loss: 1.5270\n",
            "Iteration: 1895; Percent complete: 47.4%; Average loss: 1.2998\n",
            "Iteration: 1896; Percent complete: 47.4%; Average loss: 1.3430\n",
            "Iteration: 1897; Percent complete: 47.4%; Average loss: 1.3327\n",
            "Iteration: 1898; Percent complete: 47.4%; Average loss: 1.4296\n",
            "Iteration: 1899; Percent complete: 47.5%; Average loss: 1.3132\n",
            "Iteration: 1900; Percent complete: 47.5%; Average loss: 1.4504\n",
            "Iteration: 1901; Percent complete: 47.5%; Average loss: 1.4715\n",
            "Iteration: 1902; Percent complete: 47.5%; Average loss: 1.3509\n",
            "Iteration: 1903; Percent complete: 47.6%; Average loss: 1.3108\n",
            "Iteration: 1904; Percent complete: 47.6%; Average loss: 1.3668\n",
            "Iteration: 1905; Percent complete: 47.6%; Average loss: 1.3490\n",
            "Iteration: 1906; Percent complete: 47.6%; Average loss: 1.5202\n",
            "Iteration: 1907; Percent complete: 47.7%; Average loss: 1.2269\n",
            "Iteration: 1908; Percent complete: 47.7%; Average loss: 1.3021\n",
            "Iteration: 1909; Percent complete: 47.7%; Average loss: 1.3653\n",
            "Iteration: 1910; Percent complete: 47.8%; Average loss: 1.4327\n",
            "Iteration: 1911; Percent complete: 47.8%; Average loss: 1.4470\n",
            "Iteration: 1912; Percent complete: 47.8%; Average loss: 1.4681\n",
            "Iteration: 1913; Percent complete: 47.8%; Average loss: 1.4257\n",
            "Iteration: 1914; Percent complete: 47.9%; Average loss: 1.4946\n",
            "Iteration: 1915; Percent complete: 47.9%; Average loss: 1.2899\n",
            "Iteration: 1916; Percent complete: 47.9%; Average loss: 1.3929\n",
            "Iteration: 1917; Percent complete: 47.9%; Average loss: 1.3670\n",
            "Iteration: 1918; Percent complete: 47.9%; Average loss: 1.2527\n",
            "Iteration: 1919; Percent complete: 48.0%; Average loss: 1.3109\n",
            "Iteration: 1920; Percent complete: 48.0%; Average loss: 1.4322\n",
            "Iteration: 1921; Percent complete: 48.0%; Average loss: 1.4076\n",
            "Iteration: 1922; Percent complete: 48.0%; Average loss: 1.3405\n",
            "Iteration: 1923; Percent complete: 48.1%; Average loss: 1.3791\n",
            "Iteration: 1924; Percent complete: 48.1%; Average loss: 1.3525\n",
            "Iteration: 1925; Percent complete: 48.1%; Average loss: 1.3907\n",
            "Iteration: 1926; Percent complete: 48.1%; Average loss: 1.2684\n",
            "Iteration: 1927; Percent complete: 48.2%; Average loss: 1.4394\n",
            "Iteration: 1928; Percent complete: 48.2%; Average loss: 1.4305\n",
            "Iteration: 1929; Percent complete: 48.2%; Average loss: 1.4670\n",
            "Iteration: 1930; Percent complete: 48.2%; Average loss: 1.3868\n",
            "Iteration: 1931; Percent complete: 48.3%; Average loss: 1.3473\n",
            "Iteration: 1932; Percent complete: 48.3%; Average loss: 1.2703\n",
            "Iteration: 1933; Percent complete: 48.3%; Average loss: 1.3927\n",
            "Iteration: 1934; Percent complete: 48.4%; Average loss: 1.4320\n",
            "Iteration: 1935; Percent complete: 48.4%; Average loss: 1.2578\n",
            "Iteration: 1936; Percent complete: 48.4%; Average loss: 1.3187\n",
            "Iteration: 1937; Percent complete: 48.4%; Average loss: 1.4463\n",
            "Iteration: 1938; Percent complete: 48.4%; Average loss: 1.1195\n",
            "Iteration: 1939; Percent complete: 48.5%; Average loss: 1.2595\n",
            "Iteration: 1940; Percent complete: 48.5%; Average loss: 1.3189\n",
            "Iteration: 1941; Percent complete: 48.5%; Average loss: 1.2421\n",
            "Iteration: 1942; Percent complete: 48.5%; Average loss: 1.2044\n",
            "Iteration: 1943; Percent complete: 48.6%; Average loss: 1.4587\n",
            "Iteration: 1944; Percent complete: 48.6%; Average loss: 1.3562\n",
            "Iteration: 1945; Percent complete: 48.6%; Average loss: 1.3472\n",
            "Iteration: 1946; Percent complete: 48.6%; Average loss: 1.3592\n",
            "Iteration: 1947; Percent complete: 48.7%; Average loss: 1.3710\n",
            "Iteration: 1948; Percent complete: 48.7%; Average loss: 1.4214\n",
            "Iteration: 1949; Percent complete: 48.7%; Average loss: 1.3355\n",
            "Iteration: 1950; Percent complete: 48.8%; Average loss: 1.2570\n",
            "Iteration: 1951; Percent complete: 48.8%; Average loss: 1.3974\n",
            "Iteration: 1952; Percent complete: 48.8%; Average loss: 1.1298\n",
            "Iteration: 1953; Percent complete: 48.8%; Average loss: 1.3288\n",
            "Iteration: 1954; Percent complete: 48.9%; Average loss: 1.1912\n",
            "Iteration: 1955; Percent complete: 48.9%; Average loss: 1.3672\n",
            "Iteration: 1956; Percent complete: 48.9%; Average loss: 1.2405\n",
            "Iteration: 1957; Percent complete: 48.9%; Average loss: 1.3941\n",
            "Iteration: 1958; Percent complete: 48.9%; Average loss: 1.2614\n",
            "Iteration: 1959; Percent complete: 49.0%; Average loss: 1.2354\n",
            "Iteration: 1960; Percent complete: 49.0%; Average loss: 1.3696\n",
            "Iteration: 1961; Percent complete: 49.0%; Average loss: 1.2930\n",
            "Iteration: 1962; Percent complete: 49.0%; Average loss: 1.3446\n",
            "Iteration: 1963; Percent complete: 49.1%; Average loss: 1.3667\n",
            "Iteration: 1964; Percent complete: 49.1%; Average loss: 1.1648\n",
            "Iteration: 1965; Percent complete: 49.1%; Average loss: 1.3389\n",
            "Iteration: 1966; Percent complete: 49.1%; Average loss: 1.2025\n",
            "Iteration: 1967; Percent complete: 49.2%; Average loss: 1.2071\n",
            "Iteration: 1968; Percent complete: 49.2%; Average loss: 1.2889\n",
            "Iteration: 1969; Percent complete: 49.2%; Average loss: 1.3343\n",
            "Iteration: 1970; Percent complete: 49.2%; Average loss: 1.3377\n",
            "Iteration: 1971; Percent complete: 49.3%; Average loss: 1.3962\n",
            "Iteration: 1972; Percent complete: 49.3%; Average loss: 1.3654\n",
            "Iteration: 1973; Percent complete: 49.3%; Average loss: 1.3069\n",
            "Iteration: 1974; Percent complete: 49.4%; Average loss: 1.2665\n",
            "Iteration: 1975; Percent complete: 49.4%; Average loss: 1.2691\n",
            "Iteration: 1976; Percent complete: 49.4%; Average loss: 1.4423\n",
            "Iteration: 1977; Percent complete: 49.4%; Average loss: 1.3401\n",
            "Iteration: 1978; Percent complete: 49.5%; Average loss: 1.1713\n",
            "Iteration: 1979; Percent complete: 49.5%; Average loss: 1.2113\n",
            "Iteration: 1980; Percent complete: 49.5%; Average loss: 1.2136\n",
            "Iteration: 1981; Percent complete: 49.5%; Average loss: 1.2588\n",
            "Iteration: 1982; Percent complete: 49.5%; Average loss: 1.3735\n",
            "Iteration: 1983; Percent complete: 49.6%; Average loss: 1.2856\n",
            "Iteration: 1984; Percent complete: 49.6%; Average loss: 1.1715\n",
            "Iteration: 1985; Percent complete: 49.6%; Average loss: 1.2327\n",
            "Iteration: 1986; Percent complete: 49.6%; Average loss: 1.3006\n",
            "Iteration: 1987; Percent complete: 49.7%; Average loss: 1.2542\n",
            "Iteration: 1988; Percent complete: 49.7%; Average loss: 1.2187\n",
            "Iteration: 1989; Percent complete: 49.7%; Average loss: 1.1948\n",
            "Iteration: 1990; Percent complete: 49.8%; Average loss: 1.2383\n",
            "Iteration: 1991; Percent complete: 49.8%; Average loss: 1.3185\n",
            "Iteration: 1992; Percent complete: 49.8%; Average loss: 1.2534\n",
            "Iteration: 1993; Percent complete: 49.8%; Average loss: 1.3642\n",
            "Iteration: 1994; Percent complete: 49.9%; Average loss: 1.2675\n",
            "Iteration: 1995; Percent complete: 49.9%; Average loss: 1.2501\n",
            "Iteration: 1996; Percent complete: 49.9%; Average loss: 1.2277\n",
            "Iteration: 1997; Percent complete: 49.9%; Average loss: 1.1847\n",
            "Iteration: 1998; Percent complete: 50.0%; Average loss: 1.1142\n",
            "Iteration: 1999; Percent complete: 50.0%; Average loss: 1.4485\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 1.2986\n",
            "Iteration: 2001; Percent complete: 50.0%; Average loss: 1.0796\n",
            "Iteration: 2002; Percent complete: 50.0%; Average loss: 1.2407\n",
            "Iteration: 2003; Percent complete: 50.1%; Average loss: 1.3190\n",
            "Iteration: 2004; Percent complete: 50.1%; Average loss: 1.1491\n",
            "Iteration: 2005; Percent complete: 50.1%; Average loss: 1.0948\n",
            "Iteration: 2006; Percent complete: 50.1%; Average loss: 1.3040\n",
            "Iteration: 2007; Percent complete: 50.2%; Average loss: 1.2637\n",
            "Iteration: 2008; Percent complete: 50.2%; Average loss: 1.3630\n",
            "Iteration: 2009; Percent complete: 50.2%; Average loss: 1.2532\n",
            "Iteration: 2010; Percent complete: 50.2%; Average loss: 1.2194\n",
            "Iteration: 2011; Percent complete: 50.3%; Average loss: 1.1799\n",
            "Iteration: 2012; Percent complete: 50.3%; Average loss: 1.3362\n",
            "Iteration: 2013; Percent complete: 50.3%; Average loss: 1.1695\n",
            "Iteration: 2014; Percent complete: 50.3%; Average loss: 1.0560\n",
            "Iteration: 2015; Percent complete: 50.4%; Average loss: 1.1522\n",
            "Iteration: 2016; Percent complete: 50.4%; Average loss: 1.2585\n",
            "Iteration: 2017; Percent complete: 50.4%; Average loss: 1.2250\n",
            "Iteration: 2018; Percent complete: 50.4%; Average loss: 1.1819\n",
            "Iteration: 2019; Percent complete: 50.5%; Average loss: 1.2465\n",
            "Iteration: 2020; Percent complete: 50.5%; Average loss: 1.1827\n",
            "Iteration: 2021; Percent complete: 50.5%; Average loss: 1.2802\n",
            "Iteration: 2022; Percent complete: 50.5%; Average loss: 1.1399\n",
            "Iteration: 2023; Percent complete: 50.6%; Average loss: 1.2105\n",
            "Iteration: 2024; Percent complete: 50.6%; Average loss: 1.2347\n",
            "Iteration: 2025; Percent complete: 50.6%; Average loss: 1.2014\n",
            "Iteration: 2026; Percent complete: 50.6%; Average loss: 1.1188\n",
            "Iteration: 2027; Percent complete: 50.7%; Average loss: 1.2215\n",
            "Iteration: 2028; Percent complete: 50.7%; Average loss: 1.2692\n",
            "Iteration: 2029; Percent complete: 50.7%; Average loss: 1.1086\n",
            "Iteration: 2030; Percent complete: 50.7%; Average loss: 1.1921\n",
            "Iteration: 2031; Percent complete: 50.8%; Average loss: 1.2155\n",
            "Iteration: 2032; Percent complete: 50.8%; Average loss: 1.1277\n",
            "Iteration: 2033; Percent complete: 50.8%; Average loss: 1.3146\n",
            "Iteration: 2034; Percent complete: 50.8%; Average loss: 1.2664\n",
            "Iteration: 2035; Percent complete: 50.9%; Average loss: 1.0776\n",
            "Iteration: 2036; Percent complete: 50.9%; Average loss: 1.1024\n",
            "Iteration: 2037; Percent complete: 50.9%; Average loss: 1.1697\n",
            "Iteration: 2038; Percent complete: 50.9%; Average loss: 1.0878\n",
            "Iteration: 2039; Percent complete: 51.0%; Average loss: 1.1496\n",
            "Iteration: 2040; Percent complete: 51.0%; Average loss: 1.2005\n",
            "Iteration: 2041; Percent complete: 51.0%; Average loss: 1.1945\n",
            "Iteration: 2042; Percent complete: 51.0%; Average loss: 1.2716\n",
            "Iteration: 2043; Percent complete: 51.1%; Average loss: 1.1043\n",
            "Iteration: 2044; Percent complete: 51.1%; Average loss: 1.2223\n",
            "Iteration: 2045; Percent complete: 51.1%; Average loss: 1.1538\n",
            "Iteration: 2046; Percent complete: 51.1%; Average loss: 1.1581\n",
            "Iteration: 2047; Percent complete: 51.2%; Average loss: 1.1887\n",
            "Iteration: 2048; Percent complete: 51.2%; Average loss: 1.1360\n",
            "Iteration: 2049; Percent complete: 51.2%; Average loss: 1.3433\n",
            "Iteration: 2050; Percent complete: 51.2%; Average loss: 1.0891\n",
            "Iteration: 2051; Percent complete: 51.3%; Average loss: 1.3033\n",
            "Iteration: 2052; Percent complete: 51.3%; Average loss: 1.0692\n",
            "Iteration: 2053; Percent complete: 51.3%; Average loss: 1.4057\n",
            "Iteration: 2054; Percent complete: 51.3%; Average loss: 1.3261\n",
            "Iteration: 2055; Percent complete: 51.4%; Average loss: 1.1354\n",
            "Iteration: 2056; Percent complete: 51.4%; Average loss: 1.2447\n",
            "Iteration: 2057; Percent complete: 51.4%; Average loss: 1.0490\n",
            "Iteration: 2058; Percent complete: 51.4%; Average loss: 0.9844\n",
            "Iteration: 2059; Percent complete: 51.5%; Average loss: 1.2181\n",
            "Iteration: 2060; Percent complete: 51.5%; Average loss: 1.1806\n",
            "Iteration: 2061; Percent complete: 51.5%; Average loss: 1.3078\n",
            "Iteration: 2062; Percent complete: 51.5%; Average loss: 1.1784\n",
            "Iteration: 2063; Percent complete: 51.6%; Average loss: 1.3124\n",
            "Iteration: 2064; Percent complete: 51.6%; Average loss: 1.2714\n",
            "Iteration: 2065; Percent complete: 51.6%; Average loss: 1.1900\n",
            "Iteration: 2066; Percent complete: 51.6%; Average loss: 1.1808\n",
            "Iteration: 2067; Percent complete: 51.7%; Average loss: 1.4768\n",
            "Iteration: 2068; Percent complete: 51.7%; Average loss: 1.0445\n",
            "Iteration: 2069; Percent complete: 51.7%; Average loss: 1.2355\n",
            "Iteration: 2070; Percent complete: 51.7%; Average loss: 1.0842\n",
            "Iteration: 2071; Percent complete: 51.8%; Average loss: 1.1297\n",
            "Iteration: 2072; Percent complete: 51.8%; Average loss: 1.1102\n",
            "Iteration: 2073; Percent complete: 51.8%; Average loss: 1.0233\n",
            "Iteration: 2074; Percent complete: 51.8%; Average loss: 1.2283\n",
            "Iteration: 2075; Percent complete: 51.9%; Average loss: 1.0827\n",
            "Iteration: 2076; Percent complete: 51.9%; Average loss: 1.1301\n",
            "Iteration: 2077; Percent complete: 51.9%; Average loss: 1.1871\n",
            "Iteration: 2078; Percent complete: 51.9%; Average loss: 1.1706\n",
            "Iteration: 2079; Percent complete: 52.0%; Average loss: 1.2657\n",
            "Iteration: 2080; Percent complete: 52.0%; Average loss: 0.9825\n",
            "Iteration: 2081; Percent complete: 52.0%; Average loss: 1.1523\n",
            "Iteration: 2082; Percent complete: 52.0%; Average loss: 1.0012\n",
            "Iteration: 2083; Percent complete: 52.1%; Average loss: 1.1905\n",
            "Iteration: 2084; Percent complete: 52.1%; Average loss: 1.0811\n",
            "Iteration: 2085; Percent complete: 52.1%; Average loss: 1.1999\n",
            "Iteration: 2086; Percent complete: 52.1%; Average loss: 1.2089\n",
            "Iteration: 2087; Percent complete: 52.2%; Average loss: 1.0576\n",
            "Iteration: 2088; Percent complete: 52.2%; Average loss: 1.1033\n",
            "Iteration: 2089; Percent complete: 52.2%; Average loss: 1.1279\n",
            "Iteration: 2090; Percent complete: 52.2%; Average loss: 1.1398\n",
            "Iteration: 2091; Percent complete: 52.3%; Average loss: 1.1137\n",
            "Iteration: 2092; Percent complete: 52.3%; Average loss: 1.2660\n",
            "Iteration: 2093; Percent complete: 52.3%; Average loss: 1.2242\n",
            "Iteration: 2094; Percent complete: 52.3%; Average loss: 1.1111\n",
            "Iteration: 2095; Percent complete: 52.4%; Average loss: 1.0709\n",
            "Iteration: 2096; Percent complete: 52.4%; Average loss: 1.1759\n",
            "Iteration: 2097; Percent complete: 52.4%; Average loss: 1.0765\n",
            "Iteration: 2098; Percent complete: 52.4%; Average loss: 1.0146\n",
            "Iteration: 2099; Percent complete: 52.5%; Average loss: 0.9878\n",
            "Iteration: 2100; Percent complete: 52.5%; Average loss: 1.1425\n",
            "Iteration: 2101; Percent complete: 52.5%; Average loss: 1.1805\n",
            "Iteration: 2102; Percent complete: 52.5%; Average loss: 1.0819\n",
            "Iteration: 2103; Percent complete: 52.6%; Average loss: 1.2107\n",
            "Iteration: 2104; Percent complete: 52.6%; Average loss: 1.1662\n",
            "Iteration: 2105; Percent complete: 52.6%; Average loss: 1.1256\n",
            "Iteration: 2106; Percent complete: 52.6%; Average loss: 1.1001\n",
            "Iteration: 2107; Percent complete: 52.7%; Average loss: 1.1544\n",
            "Iteration: 2108; Percent complete: 52.7%; Average loss: 1.1904\n",
            "Iteration: 2109; Percent complete: 52.7%; Average loss: 0.9858\n",
            "Iteration: 2110; Percent complete: 52.8%; Average loss: 1.1018\n",
            "Iteration: 2111; Percent complete: 52.8%; Average loss: 1.0778\n",
            "Iteration: 2112; Percent complete: 52.8%; Average loss: 1.0616\n",
            "Iteration: 2113; Percent complete: 52.8%; Average loss: 1.0285\n",
            "Iteration: 2114; Percent complete: 52.8%; Average loss: 1.1177\n",
            "Iteration: 2115; Percent complete: 52.9%; Average loss: 1.0829\n",
            "Iteration: 2116; Percent complete: 52.9%; Average loss: 1.2097\n",
            "Iteration: 2117; Percent complete: 52.9%; Average loss: 1.2432\n",
            "Iteration: 2118; Percent complete: 52.9%; Average loss: 1.0724\n",
            "Iteration: 2119; Percent complete: 53.0%; Average loss: 1.0969\n",
            "Iteration: 2120; Percent complete: 53.0%; Average loss: 1.1837\n",
            "Iteration: 2121; Percent complete: 53.0%; Average loss: 1.2019\n",
            "Iteration: 2122; Percent complete: 53.0%; Average loss: 1.0758\n",
            "Iteration: 2123; Percent complete: 53.1%; Average loss: 1.0352\n",
            "Iteration: 2124; Percent complete: 53.1%; Average loss: 1.0413\n",
            "Iteration: 2125; Percent complete: 53.1%; Average loss: 1.2085\n",
            "Iteration: 2126; Percent complete: 53.1%; Average loss: 1.0720\n",
            "Iteration: 2127; Percent complete: 53.2%; Average loss: 1.0742\n",
            "Iteration: 2128; Percent complete: 53.2%; Average loss: 1.1095\n",
            "Iteration: 2129; Percent complete: 53.2%; Average loss: 1.0855\n",
            "Iteration: 2130; Percent complete: 53.2%; Average loss: 1.1942\n",
            "Iteration: 2131; Percent complete: 53.3%; Average loss: 1.0851\n",
            "Iteration: 2132; Percent complete: 53.3%; Average loss: 1.1350\n",
            "Iteration: 2133; Percent complete: 53.3%; Average loss: 0.9918\n",
            "Iteration: 2134; Percent complete: 53.3%; Average loss: 1.2657\n",
            "Iteration: 2135; Percent complete: 53.4%; Average loss: 1.0187\n",
            "Iteration: 2136; Percent complete: 53.4%; Average loss: 1.0933\n",
            "Iteration: 2137; Percent complete: 53.4%; Average loss: 1.0589\n",
            "Iteration: 2138; Percent complete: 53.4%; Average loss: 1.2049\n",
            "Iteration: 2139; Percent complete: 53.5%; Average loss: 1.0479\n",
            "Iteration: 2140; Percent complete: 53.5%; Average loss: 1.2207\n",
            "Iteration: 2141; Percent complete: 53.5%; Average loss: 1.0651\n",
            "Iteration: 2142; Percent complete: 53.5%; Average loss: 1.1981\n",
            "Iteration: 2143; Percent complete: 53.6%; Average loss: 0.9427\n",
            "Iteration: 2144; Percent complete: 53.6%; Average loss: 1.1383\n",
            "Iteration: 2145; Percent complete: 53.6%; Average loss: 1.1932\n",
            "Iteration: 2146; Percent complete: 53.6%; Average loss: 0.9693\n",
            "Iteration: 2147; Percent complete: 53.7%; Average loss: 1.1453\n",
            "Iteration: 2148; Percent complete: 53.7%; Average loss: 1.0933\n",
            "Iteration: 2149; Percent complete: 53.7%; Average loss: 1.0507\n",
            "Iteration: 2150; Percent complete: 53.8%; Average loss: 1.0731\n",
            "Iteration: 2151; Percent complete: 53.8%; Average loss: 1.0334\n",
            "Iteration: 2152; Percent complete: 53.8%; Average loss: 1.1544\n",
            "Iteration: 2153; Percent complete: 53.8%; Average loss: 1.0427\n",
            "Iteration: 2154; Percent complete: 53.8%; Average loss: 1.1323\n",
            "Iteration: 2155; Percent complete: 53.9%; Average loss: 1.0761\n",
            "Iteration: 2156; Percent complete: 53.9%; Average loss: 0.9300\n",
            "Iteration: 2157; Percent complete: 53.9%; Average loss: 1.0274\n",
            "Iteration: 2158; Percent complete: 53.9%; Average loss: 1.1172\n",
            "Iteration: 2159; Percent complete: 54.0%; Average loss: 1.2456\n",
            "Iteration: 2160; Percent complete: 54.0%; Average loss: 0.9697\n",
            "Iteration: 2161; Percent complete: 54.0%; Average loss: 1.0107\n",
            "Iteration: 2162; Percent complete: 54.0%; Average loss: 0.9803\n",
            "Iteration: 2163; Percent complete: 54.1%; Average loss: 1.0773\n",
            "Iteration: 2164; Percent complete: 54.1%; Average loss: 1.0161\n",
            "Iteration: 2165; Percent complete: 54.1%; Average loss: 1.0750\n",
            "Iteration: 2166; Percent complete: 54.1%; Average loss: 0.9933\n",
            "Iteration: 2167; Percent complete: 54.2%; Average loss: 1.0477\n",
            "Iteration: 2168; Percent complete: 54.2%; Average loss: 1.1806\n",
            "Iteration: 2169; Percent complete: 54.2%; Average loss: 0.9510\n",
            "Iteration: 2170; Percent complete: 54.2%; Average loss: 1.0282\n",
            "Iteration: 2171; Percent complete: 54.3%; Average loss: 1.0559\n",
            "Iteration: 2172; Percent complete: 54.3%; Average loss: 1.0490\n",
            "Iteration: 2173; Percent complete: 54.3%; Average loss: 1.0312\n",
            "Iteration: 2174; Percent complete: 54.4%; Average loss: 1.1696\n",
            "Iteration: 2175; Percent complete: 54.4%; Average loss: 0.9509\n",
            "Iteration: 2176; Percent complete: 54.4%; Average loss: 1.0482\n",
            "Iteration: 2177; Percent complete: 54.4%; Average loss: 1.0501\n",
            "Iteration: 2178; Percent complete: 54.4%; Average loss: 0.9856\n",
            "Iteration: 2179; Percent complete: 54.5%; Average loss: 0.8951\n",
            "Iteration: 2180; Percent complete: 54.5%; Average loss: 1.1111\n",
            "Iteration: 2181; Percent complete: 54.5%; Average loss: 1.2444\n",
            "Iteration: 2182; Percent complete: 54.5%; Average loss: 1.1426\n",
            "Iteration: 2183; Percent complete: 54.6%; Average loss: 1.0265\n",
            "Iteration: 2184; Percent complete: 54.6%; Average loss: 1.0303\n",
            "Iteration: 2185; Percent complete: 54.6%; Average loss: 1.0224\n",
            "Iteration: 2186; Percent complete: 54.6%; Average loss: 0.9083\n",
            "Iteration: 2187; Percent complete: 54.7%; Average loss: 1.0282\n",
            "Iteration: 2188; Percent complete: 54.7%; Average loss: 0.9529\n",
            "Iteration: 2189; Percent complete: 54.7%; Average loss: 0.9990\n",
            "Iteration: 2190; Percent complete: 54.8%; Average loss: 0.9610\n",
            "Iteration: 2191; Percent complete: 54.8%; Average loss: 1.0571\n",
            "Iteration: 2192; Percent complete: 54.8%; Average loss: 0.9631\n",
            "Iteration: 2193; Percent complete: 54.8%; Average loss: 0.9287\n",
            "Iteration: 2194; Percent complete: 54.9%; Average loss: 0.8841\n",
            "Iteration: 2195; Percent complete: 54.9%; Average loss: 0.9071\n",
            "Iteration: 2196; Percent complete: 54.9%; Average loss: 0.9610\n",
            "Iteration: 2197; Percent complete: 54.9%; Average loss: 1.0510\n",
            "Iteration: 2198; Percent complete: 54.9%; Average loss: 0.9375\n",
            "Iteration: 2199; Percent complete: 55.0%; Average loss: 1.0556\n",
            "Iteration: 2200; Percent complete: 55.0%; Average loss: 1.0607\n",
            "Iteration: 2201; Percent complete: 55.0%; Average loss: 0.9290\n",
            "Iteration: 2202; Percent complete: 55.0%; Average loss: 1.0384\n",
            "Iteration: 2203; Percent complete: 55.1%; Average loss: 0.9757\n",
            "Iteration: 2204; Percent complete: 55.1%; Average loss: 1.0479\n",
            "Iteration: 2205; Percent complete: 55.1%; Average loss: 1.0783\n",
            "Iteration: 2206; Percent complete: 55.1%; Average loss: 0.9867\n",
            "Iteration: 2207; Percent complete: 55.2%; Average loss: 0.9016\n",
            "Iteration: 2208; Percent complete: 55.2%; Average loss: 1.0799\n",
            "Iteration: 2209; Percent complete: 55.2%; Average loss: 1.0683\n",
            "Iteration: 2210; Percent complete: 55.2%; Average loss: 1.0330\n",
            "Iteration: 2211; Percent complete: 55.3%; Average loss: 0.8756\n",
            "Iteration: 2212; Percent complete: 55.3%; Average loss: 0.9085\n",
            "Iteration: 2213; Percent complete: 55.3%; Average loss: 1.0282\n",
            "Iteration: 2214; Percent complete: 55.4%; Average loss: 1.0304\n",
            "Iteration: 2215; Percent complete: 55.4%; Average loss: 0.9721\n",
            "Iteration: 2216; Percent complete: 55.4%; Average loss: 1.0356\n",
            "Iteration: 2217; Percent complete: 55.4%; Average loss: 1.0250\n",
            "Iteration: 2218; Percent complete: 55.5%; Average loss: 1.0471\n",
            "Iteration: 2219; Percent complete: 55.5%; Average loss: 0.9477\n",
            "Iteration: 2220; Percent complete: 55.5%; Average loss: 1.0222\n",
            "Iteration: 2221; Percent complete: 55.5%; Average loss: 0.9508\n",
            "Iteration: 2222; Percent complete: 55.5%; Average loss: 1.0875\n",
            "Iteration: 2223; Percent complete: 55.6%; Average loss: 0.8842\n",
            "Iteration: 2224; Percent complete: 55.6%; Average loss: 1.0223\n",
            "Iteration: 2225; Percent complete: 55.6%; Average loss: 0.9132\n",
            "Iteration: 2226; Percent complete: 55.6%; Average loss: 0.8235\n",
            "Iteration: 2227; Percent complete: 55.7%; Average loss: 0.9642\n",
            "Iteration: 2228; Percent complete: 55.7%; Average loss: 0.9538\n",
            "Iteration: 2229; Percent complete: 55.7%; Average loss: 0.8927\n",
            "Iteration: 2230; Percent complete: 55.8%; Average loss: 0.9949\n",
            "Iteration: 2231; Percent complete: 55.8%; Average loss: 0.8760\n",
            "Iteration: 2232; Percent complete: 55.8%; Average loss: 0.9753\n",
            "Iteration: 2233; Percent complete: 55.8%; Average loss: 0.9857\n",
            "Iteration: 2234; Percent complete: 55.9%; Average loss: 1.1493\n",
            "Iteration: 2235; Percent complete: 55.9%; Average loss: 0.9493\n",
            "Iteration: 2236; Percent complete: 55.9%; Average loss: 1.1403\n",
            "Iteration: 2237; Percent complete: 55.9%; Average loss: 0.9361\n",
            "Iteration: 2238; Percent complete: 56.0%; Average loss: 1.0065\n",
            "Iteration: 2239; Percent complete: 56.0%; Average loss: 0.9533\n",
            "Iteration: 2240; Percent complete: 56.0%; Average loss: 0.9249\n",
            "Iteration: 2241; Percent complete: 56.0%; Average loss: 0.9354\n",
            "Iteration: 2242; Percent complete: 56.0%; Average loss: 1.1325\n",
            "Iteration: 2243; Percent complete: 56.1%; Average loss: 0.8900\n",
            "Iteration: 2244; Percent complete: 56.1%; Average loss: 0.9689\n",
            "Iteration: 2245; Percent complete: 56.1%; Average loss: 0.9556\n",
            "Iteration: 2246; Percent complete: 56.1%; Average loss: 0.9378\n",
            "Iteration: 2247; Percent complete: 56.2%; Average loss: 1.0423\n",
            "Iteration: 2248; Percent complete: 56.2%; Average loss: 0.9002\n",
            "Iteration: 2249; Percent complete: 56.2%; Average loss: 0.9393\n",
            "Iteration: 2250; Percent complete: 56.2%; Average loss: 0.9488\n",
            "Iteration: 2251; Percent complete: 56.3%; Average loss: 1.0196\n",
            "Iteration: 2252; Percent complete: 56.3%; Average loss: 0.8747\n",
            "Iteration: 2253; Percent complete: 56.3%; Average loss: 0.9015\n",
            "Iteration: 2254; Percent complete: 56.4%; Average loss: 1.0100\n",
            "Iteration: 2255; Percent complete: 56.4%; Average loss: 0.8449\n",
            "Iteration: 2256; Percent complete: 56.4%; Average loss: 0.8987\n",
            "Iteration: 2257; Percent complete: 56.4%; Average loss: 0.9915\n",
            "Iteration: 2258; Percent complete: 56.5%; Average loss: 0.9060\n",
            "Iteration: 2259; Percent complete: 56.5%; Average loss: 0.7339\n",
            "Iteration: 2260; Percent complete: 56.5%; Average loss: 1.0238\n",
            "Iteration: 2261; Percent complete: 56.5%; Average loss: 0.9914\n",
            "Iteration: 2262; Percent complete: 56.5%; Average loss: 0.8066\n",
            "Iteration: 2263; Percent complete: 56.6%; Average loss: 0.9010\n",
            "Iteration: 2264; Percent complete: 56.6%; Average loss: 0.8791\n",
            "Iteration: 2265; Percent complete: 56.6%; Average loss: 0.9760\n",
            "Iteration: 2266; Percent complete: 56.6%; Average loss: 0.9985\n",
            "Iteration: 2267; Percent complete: 56.7%; Average loss: 0.9797\n",
            "Iteration: 2268; Percent complete: 56.7%; Average loss: 0.9471\n",
            "Iteration: 2269; Percent complete: 56.7%; Average loss: 0.9160\n",
            "Iteration: 2270; Percent complete: 56.8%; Average loss: 0.9276\n",
            "Iteration: 2271; Percent complete: 56.8%; Average loss: 0.9328\n",
            "Iteration: 2272; Percent complete: 56.8%; Average loss: 0.7636\n",
            "Iteration: 2273; Percent complete: 56.8%; Average loss: 0.9500\n",
            "Iteration: 2274; Percent complete: 56.9%; Average loss: 0.9207\n",
            "Iteration: 2275; Percent complete: 56.9%; Average loss: 0.8645\n",
            "Iteration: 2276; Percent complete: 56.9%; Average loss: 0.9310\n",
            "Iteration: 2277; Percent complete: 56.9%; Average loss: 0.9704\n",
            "Iteration: 2278; Percent complete: 57.0%; Average loss: 0.9506\n",
            "Iteration: 2279; Percent complete: 57.0%; Average loss: 0.8654\n",
            "Iteration: 2280; Percent complete: 57.0%; Average loss: 0.9489\n",
            "Iteration: 2281; Percent complete: 57.0%; Average loss: 0.9203\n",
            "Iteration: 2282; Percent complete: 57.0%; Average loss: 0.9741\n",
            "Iteration: 2283; Percent complete: 57.1%; Average loss: 0.8559\n",
            "Iteration: 2284; Percent complete: 57.1%; Average loss: 0.9141\n",
            "Iteration: 2285; Percent complete: 57.1%; Average loss: 0.8448\n",
            "Iteration: 2286; Percent complete: 57.1%; Average loss: 0.8959\n",
            "Iteration: 2287; Percent complete: 57.2%; Average loss: 0.8002\n",
            "Iteration: 2288; Percent complete: 57.2%; Average loss: 0.8949\n",
            "Iteration: 2289; Percent complete: 57.2%; Average loss: 0.9902\n",
            "Iteration: 2290; Percent complete: 57.2%; Average loss: 0.9578\n",
            "Iteration: 2291; Percent complete: 57.3%; Average loss: 1.0180\n",
            "Iteration: 2292; Percent complete: 57.3%; Average loss: 0.8570\n",
            "Iteration: 2293; Percent complete: 57.3%; Average loss: 1.0323\n",
            "Iteration: 2294; Percent complete: 57.4%; Average loss: 0.8343\n",
            "Iteration: 2295; Percent complete: 57.4%; Average loss: 0.8746\n",
            "Iteration: 2296; Percent complete: 57.4%; Average loss: 0.8438\n",
            "Iteration: 2297; Percent complete: 57.4%; Average loss: 0.9373\n",
            "Iteration: 2298; Percent complete: 57.5%; Average loss: 0.9149\n",
            "Iteration: 2299; Percent complete: 57.5%; Average loss: 1.0010\n",
            "Iteration: 2300; Percent complete: 57.5%; Average loss: 0.8573\n",
            "Iteration: 2301; Percent complete: 57.5%; Average loss: 0.8886\n",
            "Iteration: 2302; Percent complete: 57.6%; Average loss: 0.9555\n",
            "Iteration: 2303; Percent complete: 57.6%; Average loss: 0.8819\n",
            "Iteration: 2304; Percent complete: 57.6%; Average loss: 0.9593\n",
            "Iteration: 2305; Percent complete: 57.6%; Average loss: 0.9312\n",
            "Iteration: 2306; Percent complete: 57.6%; Average loss: 0.9029\n",
            "Iteration: 2307; Percent complete: 57.7%; Average loss: 0.8909\n",
            "Iteration: 2308; Percent complete: 57.7%; Average loss: 0.8890\n",
            "Iteration: 2309; Percent complete: 57.7%; Average loss: 0.8801\n",
            "Iteration: 2310; Percent complete: 57.8%; Average loss: 0.7947\n",
            "Iteration: 2311; Percent complete: 57.8%; Average loss: 0.8579\n",
            "Iteration: 2312; Percent complete: 57.8%; Average loss: 0.8552\n",
            "Iteration: 2313; Percent complete: 57.8%; Average loss: 0.9217\n",
            "Iteration: 2314; Percent complete: 57.9%; Average loss: 0.8554\n",
            "Iteration: 2315; Percent complete: 57.9%; Average loss: 0.8609\n",
            "Iteration: 2316; Percent complete: 57.9%; Average loss: 0.9220\n",
            "Iteration: 2317; Percent complete: 57.9%; Average loss: 0.8489\n",
            "Iteration: 2318; Percent complete: 58.0%; Average loss: 0.9333\n",
            "Iteration: 2319; Percent complete: 58.0%; Average loss: 0.8171\n",
            "Iteration: 2320; Percent complete: 58.0%; Average loss: 0.7940\n",
            "Iteration: 2321; Percent complete: 58.0%; Average loss: 0.7848\n",
            "Iteration: 2322; Percent complete: 58.1%; Average loss: 0.7885\n",
            "Iteration: 2323; Percent complete: 58.1%; Average loss: 0.7958\n",
            "Iteration: 2324; Percent complete: 58.1%; Average loss: 0.9171\n",
            "Iteration: 2325; Percent complete: 58.1%; Average loss: 1.1444\n",
            "Iteration: 2326; Percent complete: 58.1%; Average loss: 0.8210\n",
            "Iteration: 2327; Percent complete: 58.2%; Average loss: 0.7744\n",
            "Iteration: 2328; Percent complete: 58.2%; Average loss: 0.8268\n",
            "Iteration: 2329; Percent complete: 58.2%; Average loss: 0.8508\n",
            "Iteration: 2330; Percent complete: 58.2%; Average loss: 0.9791\n",
            "Iteration: 2331; Percent complete: 58.3%; Average loss: 0.8056\n",
            "Iteration: 2332; Percent complete: 58.3%; Average loss: 0.8361\n",
            "Iteration: 2333; Percent complete: 58.3%; Average loss: 0.8992\n",
            "Iteration: 2334; Percent complete: 58.4%; Average loss: 0.9174\n",
            "Iteration: 2335; Percent complete: 58.4%; Average loss: 0.9741\n",
            "Iteration: 2336; Percent complete: 58.4%; Average loss: 0.7210\n",
            "Iteration: 2337; Percent complete: 58.4%; Average loss: 0.9648\n",
            "Iteration: 2338; Percent complete: 58.5%; Average loss: 0.8375\n",
            "Iteration: 2339; Percent complete: 58.5%; Average loss: 0.9056\n",
            "Iteration: 2340; Percent complete: 58.5%; Average loss: 0.9089\n",
            "Iteration: 2341; Percent complete: 58.5%; Average loss: 0.8090\n",
            "Iteration: 2342; Percent complete: 58.6%; Average loss: 0.9099\n",
            "Iteration: 2343; Percent complete: 58.6%; Average loss: 0.8620\n",
            "Iteration: 2344; Percent complete: 58.6%; Average loss: 0.7947\n",
            "Iteration: 2345; Percent complete: 58.6%; Average loss: 0.8960\n",
            "Iteration: 2346; Percent complete: 58.7%; Average loss: 0.9319\n",
            "Iteration: 2347; Percent complete: 58.7%; Average loss: 0.9630\n",
            "Iteration: 2348; Percent complete: 58.7%; Average loss: 0.8689\n",
            "Iteration: 2349; Percent complete: 58.7%; Average loss: 0.8710\n",
            "Iteration: 2350; Percent complete: 58.8%; Average loss: 0.8037\n",
            "Iteration: 2351; Percent complete: 58.8%; Average loss: 0.8507\n",
            "Iteration: 2352; Percent complete: 58.8%; Average loss: 0.8846\n",
            "Iteration: 2353; Percent complete: 58.8%; Average loss: 0.8054\n",
            "Iteration: 2354; Percent complete: 58.9%; Average loss: 0.8309\n",
            "Iteration: 2355; Percent complete: 58.9%; Average loss: 0.9820\n",
            "Iteration: 2356; Percent complete: 58.9%; Average loss: 0.7587\n",
            "Iteration: 2357; Percent complete: 58.9%; Average loss: 0.8602\n",
            "Iteration: 2358; Percent complete: 59.0%; Average loss: 0.8025\n",
            "Iteration: 2359; Percent complete: 59.0%; Average loss: 0.7734\n",
            "Iteration: 2360; Percent complete: 59.0%; Average loss: 0.8412\n",
            "Iteration: 2361; Percent complete: 59.0%; Average loss: 1.0338\n",
            "Iteration: 2362; Percent complete: 59.1%; Average loss: 0.8187\n",
            "Iteration: 2363; Percent complete: 59.1%; Average loss: 0.7045\n",
            "Iteration: 2364; Percent complete: 59.1%; Average loss: 0.9164\n",
            "Iteration: 2365; Percent complete: 59.1%; Average loss: 0.7047\n",
            "Iteration: 2366; Percent complete: 59.2%; Average loss: 0.8267\n",
            "Iteration: 2367; Percent complete: 59.2%; Average loss: 0.7770\n",
            "Iteration: 2368; Percent complete: 59.2%; Average loss: 0.8581\n",
            "Iteration: 2369; Percent complete: 59.2%; Average loss: 0.8623\n",
            "Iteration: 2370; Percent complete: 59.2%; Average loss: 0.9332\n",
            "Iteration: 2371; Percent complete: 59.3%; Average loss: 0.8601\n",
            "Iteration: 2372; Percent complete: 59.3%; Average loss: 0.8014\n",
            "Iteration: 2373; Percent complete: 59.3%; Average loss: 0.9692\n",
            "Iteration: 2374; Percent complete: 59.4%; Average loss: 0.8318\n",
            "Iteration: 2375; Percent complete: 59.4%; Average loss: 0.7023\n",
            "Iteration: 2376; Percent complete: 59.4%; Average loss: 0.8669\n",
            "Iteration: 2377; Percent complete: 59.4%; Average loss: 0.7616\n",
            "Iteration: 2378; Percent complete: 59.5%; Average loss: 0.8441\n",
            "Iteration: 2379; Percent complete: 59.5%; Average loss: 0.7503\n",
            "Iteration: 2380; Percent complete: 59.5%; Average loss: 0.8241\n",
            "Iteration: 2381; Percent complete: 59.5%; Average loss: 0.7565\n",
            "Iteration: 2382; Percent complete: 59.6%; Average loss: 0.8121\n",
            "Iteration: 2383; Percent complete: 59.6%; Average loss: 0.7770\n",
            "Iteration: 2384; Percent complete: 59.6%; Average loss: 0.7646\n",
            "Iteration: 2385; Percent complete: 59.6%; Average loss: 0.8671\n",
            "Iteration: 2386; Percent complete: 59.7%; Average loss: 0.9665\n",
            "Iteration: 2387; Percent complete: 59.7%; Average loss: 0.7236\n",
            "Iteration: 2388; Percent complete: 59.7%; Average loss: 0.8425\n",
            "Iteration: 2389; Percent complete: 59.7%; Average loss: 0.9139\n",
            "Iteration: 2390; Percent complete: 59.8%; Average loss: 0.9055\n",
            "Iteration: 2391; Percent complete: 59.8%; Average loss: 0.7453\n",
            "Iteration: 2392; Percent complete: 59.8%; Average loss: 0.8085\n",
            "Iteration: 2393; Percent complete: 59.8%; Average loss: 0.7074\n",
            "Iteration: 2394; Percent complete: 59.9%; Average loss: 0.6648\n",
            "Iteration: 2395; Percent complete: 59.9%; Average loss: 0.8794\n",
            "Iteration: 2396; Percent complete: 59.9%; Average loss: 0.8019\n",
            "Iteration: 2397; Percent complete: 59.9%; Average loss: 0.8999\n",
            "Iteration: 2398; Percent complete: 60.0%; Average loss: 0.7925\n",
            "Iteration: 2399; Percent complete: 60.0%; Average loss: 0.7865\n",
            "Iteration: 2400; Percent complete: 60.0%; Average loss: 0.7876\n",
            "Iteration: 2401; Percent complete: 60.0%; Average loss: 0.8075\n",
            "Iteration: 2402; Percent complete: 60.1%; Average loss: 0.9372\n",
            "Iteration: 2403; Percent complete: 60.1%; Average loss: 0.7935\n",
            "Iteration: 2404; Percent complete: 60.1%; Average loss: 0.7999\n",
            "Iteration: 2405; Percent complete: 60.1%; Average loss: 0.7759\n",
            "Iteration: 2406; Percent complete: 60.2%; Average loss: 0.7018\n",
            "Iteration: 2407; Percent complete: 60.2%; Average loss: 0.8146\n",
            "Iteration: 2408; Percent complete: 60.2%; Average loss: 0.7434\n",
            "Iteration: 2409; Percent complete: 60.2%; Average loss: 0.7018\n",
            "Iteration: 2410; Percent complete: 60.2%; Average loss: 0.7845\n",
            "Iteration: 2411; Percent complete: 60.3%; Average loss: 0.7391\n",
            "Iteration: 2412; Percent complete: 60.3%; Average loss: 0.8977\n",
            "Iteration: 2413; Percent complete: 60.3%; Average loss: 0.8466\n",
            "Iteration: 2414; Percent complete: 60.4%; Average loss: 0.8082\n",
            "Iteration: 2415; Percent complete: 60.4%; Average loss: 0.8029\n",
            "Iteration: 2416; Percent complete: 60.4%; Average loss: 0.6887\n",
            "Iteration: 2417; Percent complete: 60.4%; Average loss: 0.7815\n",
            "Iteration: 2418; Percent complete: 60.5%; Average loss: 0.7870\n",
            "Iteration: 2419; Percent complete: 60.5%; Average loss: 0.8025\n",
            "Iteration: 2420; Percent complete: 60.5%; Average loss: 0.8701\n",
            "Iteration: 2421; Percent complete: 60.5%; Average loss: 0.7374\n",
            "Iteration: 2422; Percent complete: 60.6%; Average loss: 0.7764\n",
            "Iteration: 2423; Percent complete: 60.6%; Average loss: 0.8388\n",
            "Iteration: 2424; Percent complete: 60.6%; Average loss: 0.7065\n",
            "Iteration: 2425; Percent complete: 60.6%; Average loss: 0.7939\n",
            "Iteration: 2426; Percent complete: 60.7%; Average loss: 0.6912\n",
            "Iteration: 2427; Percent complete: 60.7%; Average loss: 0.9081\n",
            "Iteration: 2428; Percent complete: 60.7%; Average loss: 0.8306\n",
            "Iteration: 2429; Percent complete: 60.7%; Average loss: 0.7141\n",
            "Iteration: 2430; Percent complete: 60.8%; Average loss: 0.7191\n",
            "Iteration: 2431; Percent complete: 60.8%; Average loss: 0.8279\n",
            "Iteration: 2432; Percent complete: 60.8%; Average loss: 0.8116\n",
            "Iteration: 2433; Percent complete: 60.8%; Average loss: 0.8083\n",
            "Iteration: 2434; Percent complete: 60.9%; Average loss: 0.7780\n",
            "Iteration: 2435; Percent complete: 60.9%; Average loss: 0.7644\n",
            "Iteration: 2436; Percent complete: 60.9%; Average loss: 0.8344\n",
            "Iteration: 2437; Percent complete: 60.9%; Average loss: 0.7598\n",
            "Iteration: 2438; Percent complete: 61.0%; Average loss: 0.7671\n",
            "Iteration: 2439; Percent complete: 61.0%; Average loss: 0.7756\n",
            "Iteration: 2440; Percent complete: 61.0%; Average loss: 0.6803\n",
            "Iteration: 2441; Percent complete: 61.0%; Average loss: 0.7647\n",
            "Iteration: 2442; Percent complete: 61.1%; Average loss: 0.7901\n",
            "Iteration: 2443; Percent complete: 61.1%; Average loss: 0.7144\n",
            "Iteration: 2444; Percent complete: 61.1%; Average loss: 0.7250\n",
            "Iteration: 2445; Percent complete: 61.1%; Average loss: 0.7624\n",
            "Iteration: 2446; Percent complete: 61.2%; Average loss: 0.8319\n",
            "Iteration: 2447; Percent complete: 61.2%; Average loss: 0.7434\n",
            "Iteration: 2448; Percent complete: 61.2%; Average loss: 0.9018\n",
            "Iteration: 2449; Percent complete: 61.2%; Average loss: 0.8263\n",
            "Iteration: 2450; Percent complete: 61.3%; Average loss: 0.7181\n",
            "Iteration: 2451; Percent complete: 61.3%; Average loss: 0.7260\n",
            "Iteration: 2452; Percent complete: 61.3%; Average loss: 0.6700\n",
            "Iteration: 2453; Percent complete: 61.3%; Average loss: 0.8584\n",
            "Iteration: 2454; Percent complete: 61.4%; Average loss: 0.7705\n",
            "Iteration: 2455; Percent complete: 61.4%; Average loss: 0.6661\n",
            "Iteration: 2456; Percent complete: 61.4%; Average loss: 0.8264\n",
            "Iteration: 2457; Percent complete: 61.4%; Average loss: 0.7933\n",
            "Iteration: 2458; Percent complete: 61.5%; Average loss: 0.8128\n",
            "Iteration: 2459; Percent complete: 61.5%; Average loss: 0.6725\n",
            "Iteration: 2460; Percent complete: 61.5%; Average loss: 0.6767\n",
            "Iteration: 2461; Percent complete: 61.5%; Average loss: 0.6792\n",
            "Iteration: 2462; Percent complete: 61.6%; Average loss: 0.8659\n",
            "Iteration: 2463; Percent complete: 61.6%; Average loss: 0.8489\n",
            "Iteration: 2464; Percent complete: 61.6%; Average loss: 0.8547\n",
            "Iteration: 2465; Percent complete: 61.6%; Average loss: 0.6887\n",
            "Iteration: 2466; Percent complete: 61.7%; Average loss: 0.7932\n",
            "Iteration: 2467; Percent complete: 61.7%; Average loss: 0.7454\n",
            "Iteration: 2468; Percent complete: 61.7%; Average loss: 0.7945\n",
            "Iteration: 2469; Percent complete: 61.7%; Average loss: 0.7554\n",
            "Iteration: 2470; Percent complete: 61.8%; Average loss: 0.8136\n",
            "Iteration: 2471; Percent complete: 61.8%; Average loss: 0.7586\n",
            "Iteration: 2472; Percent complete: 61.8%; Average loss: 0.8080\n",
            "Iteration: 2473; Percent complete: 61.8%; Average loss: 0.8036\n",
            "Iteration: 2474; Percent complete: 61.9%; Average loss: 0.6936\n",
            "Iteration: 2475; Percent complete: 61.9%; Average loss: 0.7281\n",
            "Iteration: 2476; Percent complete: 61.9%; Average loss: 0.6914\n",
            "Iteration: 2477; Percent complete: 61.9%; Average loss: 0.8849\n",
            "Iteration: 2478; Percent complete: 62.0%; Average loss: 0.7650\n",
            "Iteration: 2479; Percent complete: 62.0%; Average loss: 0.6969\n",
            "Iteration: 2480; Percent complete: 62.0%; Average loss: 0.7266\n",
            "Iteration: 2481; Percent complete: 62.0%; Average loss: 0.7490\n",
            "Iteration: 2482; Percent complete: 62.1%; Average loss: 0.7420\n",
            "Iteration: 2483; Percent complete: 62.1%; Average loss: 0.8423\n",
            "Iteration: 2484; Percent complete: 62.1%; Average loss: 0.7308\n",
            "Iteration: 2485; Percent complete: 62.1%; Average loss: 0.7373\n",
            "Iteration: 2486; Percent complete: 62.2%; Average loss: 0.7419\n",
            "Iteration: 2487; Percent complete: 62.2%; Average loss: 0.7824\n",
            "Iteration: 2488; Percent complete: 62.2%; Average loss: 0.6895\n",
            "Iteration: 2489; Percent complete: 62.2%; Average loss: 0.7909\n",
            "Iteration: 2490; Percent complete: 62.3%; Average loss: 0.6996\n",
            "Iteration: 2491; Percent complete: 62.3%; Average loss: 0.7346\n",
            "Iteration: 2492; Percent complete: 62.3%; Average loss: 0.6558\n",
            "Iteration: 2493; Percent complete: 62.3%; Average loss: 0.7380\n",
            "Iteration: 2494; Percent complete: 62.4%; Average loss: 0.6149\n",
            "Iteration: 2495; Percent complete: 62.4%; Average loss: 0.6898\n",
            "Iteration: 2496; Percent complete: 62.4%; Average loss: 0.7506\n",
            "Iteration: 2497; Percent complete: 62.4%; Average loss: 0.7206\n",
            "Iteration: 2498; Percent complete: 62.5%; Average loss: 0.7056\n",
            "Iteration: 2499; Percent complete: 62.5%; Average loss: 0.6420\n",
            "Iteration: 2500; Percent complete: 62.5%; Average loss: 0.7766\n",
            "Iteration: 2501; Percent complete: 62.5%; Average loss: 0.7815\n",
            "Iteration: 2502; Percent complete: 62.5%; Average loss: 0.6830\n",
            "Iteration: 2503; Percent complete: 62.6%; Average loss: 0.6544\n",
            "Iteration: 2504; Percent complete: 62.6%; Average loss: 0.6952\n",
            "Iteration: 2505; Percent complete: 62.6%; Average loss: 0.6823\n",
            "Iteration: 2506; Percent complete: 62.6%; Average loss: 0.7117\n",
            "Iteration: 2507; Percent complete: 62.7%; Average loss: 0.7399\n",
            "Iteration: 2508; Percent complete: 62.7%; Average loss: 0.6356\n",
            "Iteration: 2509; Percent complete: 62.7%; Average loss: 0.8844\n",
            "Iteration: 2510; Percent complete: 62.7%; Average loss: 0.6641\n",
            "Iteration: 2511; Percent complete: 62.8%; Average loss: 0.7779\n",
            "Iteration: 2512; Percent complete: 62.8%; Average loss: 0.7232\n",
            "Iteration: 2513; Percent complete: 62.8%; Average loss: 0.7715\n",
            "Iteration: 2514; Percent complete: 62.8%; Average loss: 0.6470\n",
            "Iteration: 2515; Percent complete: 62.9%; Average loss: 0.7066\n",
            "Iteration: 2516; Percent complete: 62.9%; Average loss: 0.6935\n",
            "Iteration: 2517; Percent complete: 62.9%; Average loss: 0.7356\n",
            "Iteration: 2518; Percent complete: 62.9%; Average loss: 0.7661\n",
            "Iteration: 2519; Percent complete: 63.0%; Average loss: 0.7266\n",
            "Iteration: 2520; Percent complete: 63.0%; Average loss: 0.7329\n",
            "Iteration: 2521; Percent complete: 63.0%; Average loss: 0.7782\n",
            "Iteration: 2522; Percent complete: 63.0%; Average loss: 0.7306\n",
            "Iteration: 2523; Percent complete: 63.1%; Average loss: 0.6468\n",
            "Iteration: 2524; Percent complete: 63.1%; Average loss: 0.6915\n",
            "Iteration: 2525; Percent complete: 63.1%; Average loss: 0.7347\n",
            "Iteration: 2526; Percent complete: 63.1%; Average loss: 0.8074\n",
            "Iteration: 2527; Percent complete: 63.2%; Average loss: 0.6350\n",
            "Iteration: 2528; Percent complete: 63.2%; Average loss: 0.7990\n",
            "Iteration: 2529; Percent complete: 63.2%; Average loss: 0.6455\n",
            "Iteration: 2530; Percent complete: 63.2%; Average loss: 0.6833\n",
            "Iteration: 2531; Percent complete: 63.3%; Average loss: 0.6512\n",
            "Iteration: 2532; Percent complete: 63.3%; Average loss: 0.5971\n",
            "Iteration: 2533; Percent complete: 63.3%; Average loss: 0.8271\n",
            "Iteration: 2534; Percent complete: 63.3%; Average loss: 0.6457\n",
            "Iteration: 2535; Percent complete: 63.4%; Average loss: 0.6249\n",
            "Iteration: 2536; Percent complete: 63.4%; Average loss: 0.7310\n",
            "Iteration: 2537; Percent complete: 63.4%; Average loss: 0.6892\n",
            "Iteration: 2538; Percent complete: 63.4%; Average loss: 0.6137\n",
            "Iteration: 2539; Percent complete: 63.5%; Average loss: 0.6519\n",
            "Iteration: 2540; Percent complete: 63.5%; Average loss: 0.7834\n",
            "Iteration: 2541; Percent complete: 63.5%; Average loss: 0.6172\n",
            "Iteration: 2542; Percent complete: 63.5%; Average loss: 0.6581\n",
            "Iteration: 2543; Percent complete: 63.6%; Average loss: 0.6384\n",
            "Iteration: 2544; Percent complete: 63.6%; Average loss: 0.6143\n",
            "Iteration: 2545; Percent complete: 63.6%; Average loss: 0.6505\n",
            "Iteration: 2546; Percent complete: 63.6%; Average loss: 0.6677\n",
            "Iteration: 2547; Percent complete: 63.7%; Average loss: 0.6303\n",
            "Iteration: 2548; Percent complete: 63.7%; Average loss: 0.6728\n",
            "Iteration: 2549; Percent complete: 63.7%; Average loss: 0.6454\n",
            "Iteration: 2550; Percent complete: 63.7%; Average loss: 0.6753\n",
            "Iteration: 2551; Percent complete: 63.8%; Average loss: 0.5884\n",
            "Iteration: 2552; Percent complete: 63.8%; Average loss: 0.6908\n",
            "Iteration: 2553; Percent complete: 63.8%; Average loss: 0.7558\n",
            "Iteration: 2554; Percent complete: 63.8%; Average loss: 0.7496\n",
            "Iteration: 2555; Percent complete: 63.9%; Average loss: 0.6364\n",
            "Iteration: 2556; Percent complete: 63.9%; Average loss: 0.7060\n",
            "Iteration: 2557; Percent complete: 63.9%; Average loss: 0.6447\n",
            "Iteration: 2558; Percent complete: 63.9%; Average loss: 0.7314\n",
            "Iteration: 2559; Percent complete: 64.0%; Average loss: 0.6924\n",
            "Iteration: 2560; Percent complete: 64.0%; Average loss: 0.6860\n",
            "Iteration: 2561; Percent complete: 64.0%; Average loss: 0.5830\n",
            "Iteration: 2562; Percent complete: 64.0%; Average loss: 0.6092\n",
            "Iteration: 2563; Percent complete: 64.1%; Average loss: 0.6218\n",
            "Iteration: 2564; Percent complete: 64.1%; Average loss: 0.6297\n",
            "Iteration: 2565; Percent complete: 64.1%; Average loss: 0.7181\n",
            "Iteration: 2566; Percent complete: 64.1%; Average loss: 0.6028\n",
            "Iteration: 2567; Percent complete: 64.2%; Average loss: 0.6524\n",
            "Iteration: 2568; Percent complete: 64.2%; Average loss: 0.5839\n",
            "Iteration: 2569; Percent complete: 64.2%; Average loss: 0.5483\n",
            "Iteration: 2570; Percent complete: 64.2%; Average loss: 0.7094\n",
            "Iteration: 2571; Percent complete: 64.3%; Average loss: 0.6577\n",
            "Iteration: 2572; Percent complete: 64.3%; Average loss: 0.7285\n",
            "Iteration: 2573; Percent complete: 64.3%; Average loss: 0.6414\n",
            "Iteration: 2574; Percent complete: 64.3%; Average loss: 0.6324\n",
            "Iteration: 2575; Percent complete: 64.4%; Average loss: 0.6821\n",
            "Iteration: 2576; Percent complete: 64.4%; Average loss: 0.5963\n",
            "Iteration: 2577; Percent complete: 64.4%; Average loss: 0.6669\n",
            "Iteration: 2578; Percent complete: 64.5%; Average loss: 0.6277\n",
            "Iteration: 2579; Percent complete: 64.5%; Average loss: 0.7073\n",
            "Iteration: 2580; Percent complete: 64.5%; Average loss: 0.5954\n",
            "Iteration: 2581; Percent complete: 64.5%; Average loss: 0.6119\n",
            "Iteration: 2582; Percent complete: 64.5%; Average loss: 0.6766\n",
            "Iteration: 2583; Percent complete: 64.6%; Average loss: 0.6218\n",
            "Iteration: 2584; Percent complete: 64.6%; Average loss: 0.6934\n",
            "Iteration: 2585; Percent complete: 64.6%; Average loss: 0.6187\n",
            "Iteration: 2586; Percent complete: 64.6%; Average loss: 0.6116\n",
            "Iteration: 2587; Percent complete: 64.7%; Average loss: 0.7222\n",
            "Iteration: 2588; Percent complete: 64.7%; Average loss: 0.6660\n",
            "Iteration: 2589; Percent complete: 64.7%; Average loss: 0.6726\n",
            "Iteration: 2590; Percent complete: 64.8%; Average loss: 0.7406\n",
            "Iteration: 2591; Percent complete: 64.8%; Average loss: 0.6686\n",
            "Iteration: 2592; Percent complete: 64.8%; Average loss: 0.5735\n",
            "Iteration: 2593; Percent complete: 64.8%; Average loss: 0.6684\n",
            "Iteration: 2594; Percent complete: 64.8%; Average loss: 0.5520\n",
            "Iteration: 2595; Percent complete: 64.9%; Average loss: 0.5920\n",
            "Iteration: 2596; Percent complete: 64.9%; Average loss: 0.5988\n",
            "Iteration: 2597; Percent complete: 64.9%; Average loss: 0.6274\n",
            "Iteration: 2598; Percent complete: 65.0%; Average loss: 0.6507\n",
            "Iteration: 2599; Percent complete: 65.0%; Average loss: 0.5725\n",
            "Iteration: 2600; Percent complete: 65.0%; Average loss: 0.7013\n",
            "Iteration: 2601; Percent complete: 65.0%; Average loss: 0.6290\n",
            "Iteration: 2602; Percent complete: 65.0%; Average loss: 0.5671\n",
            "Iteration: 2603; Percent complete: 65.1%; Average loss: 0.6003\n",
            "Iteration: 2604; Percent complete: 65.1%; Average loss: 0.6175\n",
            "Iteration: 2605; Percent complete: 65.1%; Average loss: 0.6281\n",
            "Iteration: 2606; Percent complete: 65.1%; Average loss: 0.6184\n",
            "Iteration: 2607; Percent complete: 65.2%; Average loss: 0.6429\n",
            "Iteration: 2608; Percent complete: 65.2%; Average loss: 0.6163\n",
            "Iteration: 2609; Percent complete: 65.2%; Average loss: 0.6804\n",
            "Iteration: 2610; Percent complete: 65.2%; Average loss: 0.5363\n",
            "Iteration: 2611; Percent complete: 65.3%; Average loss: 0.6296\n",
            "Iteration: 2612; Percent complete: 65.3%; Average loss: 0.6059\n",
            "Iteration: 2613; Percent complete: 65.3%; Average loss: 0.6146\n",
            "Iteration: 2614; Percent complete: 65.3%; Average loss: 0.6045\n",
            "Iteration: 2615; Percent complete: 65.4%; Average loss: 0.6202\n",
            "Iteration: 2616; Percent complete: 65.4%; Average loss: 0.7712\n",
            "Iteration: 2617; Percent complete: 65.4%; Average loss: 0.5542\n",
            "Iteration: 2618; Percent complete: 65.5%; Average loss: 0.5782\n",
            "Iteration: 2619; Percent complete: 65.5%; Average loss: 0.5967\n",
            "Iteration: 2620; Percent complete: 65.5%; Average loss: 0.7019\n",
            "Iteration: 2621; Percent complete: 65.5%; Average loss: 0.6300\n",
            "Iteration: 2622; Percent complete: 65.5%; Average loss: 0.5536\n",
            "Iteration: 2623; Percent complete: 65.6%; Average loss: 0.6248\n",
            "Iteration: 2624; Percent complete: 65.6%; Average loss: 0.6019\n",
            "Iteration: 2625; Percent complete: 65.6%; Average loss: 0.7270\n",
            "Iteration: 2626; Percent complete: 65.6%; Average loss: 0.5792\n",
            "Iteration: 2627; Percent complete: 65.7%; Average loss: 0.6288\n",
            "Iteration: 2628; Percent complete: 65.7%; Average loss: 0.7038\n",
            "Iteration: 2629; Percent complete: 65.7%; Average loss: 0.5609\n",
            "Iteration: 2630; Percent complete: 65.8%; Average loss: 0.5798\n",
            "Iteration: 2631; Percent complete: 65.8%; Average loss: 0.5718\n",
            "Iteration: 2632; Percent complete: 65.8%; Average loss: 0.5927\n",
            "Iteration: 2633; Percent complete: 65.8%; Average loss: 0.5946\n",
            "Iteration: 2634; Percent complete: 65.8%; Average loss: 0.5873\n",
            "Iteration: 2635; Percent complete: 65.9%; Average loss: 0.5896\n",
            "Iteration: 2636; Percent complete: 65.9%; Average loss: 0.5470\n",
            "Iteration: 2637; Percent complete: 65.9%; Average loss: 0.6207\n",
            "Iteration: 2638; Percent complete: 66.0%; Average loss: 0.7139\n",
            "Iteration: 2639; Percent complete: 66.0%; Average loss: 0.5954\n",
            "Iteration: 2640; Percent complete: 66.0%; Average loss: 0.5604\n",
            "Iteration: 2641; Percent complete: 66.0%; Average loss: 0.5390\n",
            "Iteration: 2642; Percent complete: 66.0%; Average loss: 0.7162\n",
            "Iteration: 2643; Percent complete: 66.1%; Average loss: 0.5920\n",
            "Iteration: 2644; Percent complete: 66.1%; Average loss: 0.5339\n",
            "Iteration: 2645; Percent complete: 66.1%; Average loss: 0.7376\n",
            "Iteration: 2646; Percent complete: 66.1%; Average loss: 0.6291\n",
            "Iteration: 2647; Percent complete: 66.2%; Average loss: 0.6134\n",
            "Iteration: 2648; Percent complete: 66.2%; Average loss: 0.6083\n",
            "Iteration: 2649; Percent complete: 66.2%; Average loss: 0.6007\n",
            "Iteration: 2650; Percent complete: 66.2%; Average loss: 0.5921\n",
            "Iteration: 2651; Percent complete: 66.3%; Average loss: 0.5866\n",
            "Iteration: 2652; Percent complete: 66.3%; Average loss: 0.7433\n",
            "Iteration: 2653; Percent complete: 66.3%; Average loss: 0.5943\n",
            "Iteration: 2654; Percent complete: 66.3%; Average loss: 0.6036\n",
            "Iteration: 2655; Percent complete: 66.4%; Average loss: 0.6454\n",
            "Iteration: 2656; Percent complete: 66.4%; Average loss: 0.6334\n",
            "Iteration: 2657; Percent complete: 66.4%; Average loss: 0.6086\n",
            "Iteration: 2658; Percent complete: 66.5%; Average loss: 0.5458\n",
            "Iteration: 2659; Percent complete: 66.5%; Average loss: 0.5841\n",
            "Iteration: 2660; Percent complete: 66.5%; Average loss: 0.6964\n",
            "Iteration: 2661; Percent complete: 66.5%; Average loss: 0.5741\n",
            "Iteration: 2662; Percent complete: 66.5%; Average loss: 0.5337\n",
            "Iteration: 2663; Percent complete: 66.6%; Average loss: 0.5716\n",
            "Iteration: 2664; Percent complete: 66.6%; Average loss: 0.5650\n",
            "Iteration: 2665; Percent complete: 66.6%; Average loss: 0.6250\n",
            "Iteration: 2666; Percent complete: 66.6%; Average loss: 0.5471\n",
            "Iteration: 2667; Percent complete: 66.7%; Average loss: 0.6168\n",
            "Iteration: 2668; Percent complete: 66.7%; Average loss: 0.6133\n",
            "Iteration: 2669; Percent complete: 66.7%; Average loss: 0.5898\n",
            "Iteration: 2670; Percent complete: 66.8%; Average loss: 0.5779\n",
            "Iteration: 2671; Percent complete: 66.8%; Average loss: 0.6425\n",
            "Iteration: 2672; Percent complete: 66.8%; Average loss: 0.5525\n",
            "Iteration: 2673; Percent complete: 66.8%; Average loss: 0.6073\n",
            "Iteration: 2674; Percent complete: 66.8%; Average loss: 0.5737\n",
            "Iteration: 2675; Percent complete: 66.9%; Average loss: 0.5540\n",
            "Iteration: 2676; Percent complete: 66.9%; Average loss: 0.5713\n",
            "Iteration: 2677; Percent complete: 66.9%; Average loss: 0.5935\n",
            "Iteration: 2678; Percent complete: 67.0%; Average loss: 0.6683\n",
            "Iteration: 2679; Percent complete: 67.0%; Average loss: 0.6091\n",
            "Iteration: 2680; Percent complete: 67.0%; Average loss: 0.5619\n",
            "Iteration: 2681; Percent complete: 67.0%; Average loss: 0.6108\n",
            "Iteration: 2682; Percent complete: 67.0%; Average loss: 0.6295\n",
            "Iteration: 2683; Percent complete: 67.1%; Average loss: 0.5329\n",
            "Iteration: 2684; Percent complete: 67.1%; Average loss: 0.6256\n",
            "Iteration: 2685; Percent complete: 67.1%; Average loss: 0.5975\n",
            "Iteration: 2686; Percent complete: 67.2%; Average loss: 0.5852\n",
            "Iteration: 2687; Percent complete: 67.2%; Average loss: 0.4425\n",
            "Iteration: 2688; Percent complete: 67.2%; Average loss: 0.5311\n",
            "Iteration: 2689; Percent complete: 67.2%; Average loss: 0.6517\n",
            "Iteration: 2690; Percent complete: 67.2%; Average loss: 0.5583\n",
            "Iteration: 2691; Percent complete: 67.3%; Average loss: 0.5890\n",
            "Iteration: 2692; Percent complete: 67.3%; Average loss: 0.6042\n",
            "Iteration: 2693; Percent complete: 67.3%; Average loss: 0.6572\n",
            "Iteration: 2694; Percent complete: 67.3%; Average loss: 0.5178\n",
            "Iteration: 2695; Percent complete: 67.4%; Average loss: 0.5426\n",
            "Iteration: 2696; Percent complete: 67.4%; Average loss: 0.5430\n",
            "Iteration: 2697; Percent complete: 67.4%; Average loss: 0.6585\n",
            "Iteration: 2698; Percent complete: 67.5%; Average loss: 0.5594\n",
            "Iteration: 2699; Percent complete: 67.5%; Average loss: 0.5991\n",
            "Iteration: 2700; Percent complete: 67.5%; Average loss: 0.5666\n",
            "Iteration: 2701; Percent complete: 67.5%; Average loss: 0.5296\n",
            "Iteration: 2702; Percent complete: 67.5%; Average loss: 0.5924\n",
            "Iteration: 2703; Percent complete: 67.6%; Average loss: 0.6331\n",
            "Iteration: 2704; Percent complete: 67.6%; Average loss: 0.5894\n",
            "Iteration: 2705; Percent complete: 67.6%; Average loss: 0.4953\n",
            "Iteration: 2706; Percent complete: 67.7%; Average loss: 0.4291\n",
            "Iteration: 2707; Percent complete: 67.7%; Average loss: 0.5361\n",
            "Iteration: 2708; Percent complete: 67.7%; Average loss: 0.5656\n",
            "Iteration: 2709; Percent complete: 67.7%; Average loss: 0.6250\n",
            "Iteration: 2710; Percent complete: 67.8%; Average loss: 0.5305\n",
            "Iteration: 2711; Percent complete: 67.8%; Average loss: 0.5925\n",
            "Iteration: 2712; Percent complete: 67.8%; Average loss: 0.6245\n",
            "Iteration: 2713; Percent complete: 67.8%; Average loss: 0.6602\n",
            "Iteration: 2714; Percent complete: 67.8%; Average loss: 0.5694\n",
            "Iteration: 2715; Percent complete: 67.9%; Average loss: 0.6490\n",
            "Iteration: 2716; Percent complete: 67.9%; Average loss: 0.6322\n",
            "Iteration: 2717; Percent complete: 67.9%; Average loss: 0.5654\n",
            "Iteration: 2718; Percent complete: 68.0%; Average loss: 0.5619\n",
            "Iteration: 2719; Percent complete: 68.0%; Average loss: 0.5328\n",
            "Iteration: 2720; Percent complete: 68.0%; Average loss: 0.6191\n",
            "Iteration: 2721; Percent complete: 68.0%; Average loss: 0.5438\n",
            "Iteration: 2722; Percent complete: 68.0%; Average loss: 0.4496\n",
            "Iteration: 2723; Percent complete: 68.1%; Average loss: 0.5587\n",
            "Iteration: 2724; Percent complete: 68.1%; Average loss: 0.5442\n",
            "Iteration: 2725; Percent complete: 68.1%; Average loss: 0.6213\n",
            "Iteration: 2726; Percent complete: 68.2%; Average loss: 0.5485\n",
            "Iteration: 2727; Percent complete: 68.2%; Average loss: 0.5442\n",
            "Iteration: 2728; Percent complete: 68.2%; Average loss: 0.5113\n",
            "Iteration: 2729; Percent complete: 68.2%; Average loss: 0.5838\n",
            "Iteration: 2730; Percent complete: 68.2%; Average loss: 0.5720\n",
            "Iteration: 2731; Percent complete: 68.3%; Average loss: 0.5207\n",
            "Iteration: 2732; Percent complete: 68.3%; Average loss: 0.5209\n",
            "Iteration: 2733; Percent complete: 68.3%; Average loss: 0.6097\n",
            "Iteration: 2734; Percent complete: 68.3%; Average loss: 0.6292\n",
            "Iteration: 2735; Percent complete: 68.4%; Average loss: 0.5090\n",
            "Iteration: 2736; Percent complete: 68.4%; Average loss: 0.5448\n",
            "Iteration: 2737; Percent complete: 68.4%; Average loss: 0.4705\n",
            "Iteration: 2738; Percent complete: 68.5%; Average loss: 0.5157\n",
            "Iteration: 2739; Percent complete: 68.5%; Average loss: 0.4721\n",
            "Iteration: 2740; Percent complete: 68.5%; Average loss: 0.5223\n",
            "Iteration: 2741; Percent complete: 68.5%; Average loss: 0.6413\n",
            "Iteration: 2742; Percent complete: 68.5%; Average loss: 0.5420\n",
            "Iteration: 2743; Percent complete: 68.6%; Average loss: 0.5628\n",
            "Iteration: 2744; Percent complete: 68.6%; Average loss: 0.5308\n",
            "Iteration: 2745; Percent complete: 68.6%; Average loss: 0.4856\n",
            "Iteration: 2746; Percent complete: 68.7%; Average loss: 0.5116\n",
            "Iteration: 2747; Percent complete: 68.7%; Average loss: 0.5502\n",
            "Iteration: 2748; Percent complete: 68.7%; Average loss: 0.4616\n",
            "Iteration: 2749; Percent complete: 68.7%; Average loss: 0.5127\n",
            "Iteration: 2750; Percent complete: 68.8%; Average loss: 0.5541\n",
            "Iteration: 2751; Percent complete: 68.8%; Average loss: 0.5902\n",
            "Iteration: 2752; Percent complete: 68.8%; Average loss: 0.4768\n",
            "Iteration: 2753; Percent complete: 68.8%; Average loss: 0.4907\n",
            "Iteration: 2754; Percent complete: 68.8%; Average loss: 0.5307\n",
            "Iteration: 2755; Percent complete: 68.9%; Average loss: 0.5325\n",
            "Iteration: 2756; Percent complete: 68.9%; Average loss: 0.4876\n",
            "Iteration: 2757; Percent complete: 68.9%; Average loss: 0.5184\n",
            "Iteration: 2758; Percent complete: 69.0%; Average loss: 0.6076\n",
            "Iteration: 2759; Percent complete: 69.0%; Average loss: 0.4876\n",
            "Iteration: 2760; Percent complete: 69.0%; Average loss: 0.4647\n",
            "Iteration: 2761; Percent complete: 69.0%; Average loss: 0.6722\n",
            "Iteration: 2762; Percent complete: 69.0%; Average loss: 0.5084\n",
            "Iteration: 2763; Percent complete: 69.1%; Average loss: 0.6509\n",
            "Iteration: 2764; Percent complete: 69.1%; Average loss: 0.7181\n",
            "Iteration: 2765; Percent complete: 69.1%; Average loss: 0.5723\n",
            "Iteration: 2766; Percent complete: 69.2%; Average loss: 0.5741\n",
            "Iteration: 2767; Percent complete: 69.2%; Average loss: 0.4892\n",
            "Iteration: 2768; Percent complete: 69.2%; Average loss: 0.5196\n",
            "Iteration: 2769; Percent complete: 69.2%; Average loss: 0.5909\n",
            "Iteration: 2770; Percent complete: 69.2%; Average loss: 0.4909\n",
            "Iteration: 2771; Percent complete: 69.3%; Average loss: 0.6004\n",
            "Iteration: 2772; Percent complete: 69.3%; Average loss: 0.5127\n",
            "Iteration: 2773; Percent complete: 69.3%; Average loss: 0.5059\n",
            "Iteration: 2774; Percent complete: 69.3%; Average loss: 0.5704\n",
            "Iteration: 2775; Percent complete: 69.4%; Average loss: 0.5628\n",
            "Iteration: 2776; Percent complete: 69.4%; Average loss: 0.4313\n",
            "Iteration: 2777; Percent complete: 69.4%; Average loss: 0.5783\n",
            "Iteration: 2778; Percent complete: 69.5%; Average loss: 0.5452\n",
            "Iteration: 2779; Percent complete: 69.5%; Average loss: 0.5058\n",
            "Iteration: 2780; Percent complete: 69.5%; Average loss: 0.5244\n",
            "Iteration: 2781; Percent complete: 69.5%; Average loss: 0.4603\n",
            "Iteration: 2782; Percent complete: 69.5%; Average loss: 0.5122\n",
            "Iteration: 2783; Percent complete: 69.6%; Average loss: 0.5992\n",
            "Iteration: 2784; Percent complete: 69.6%; Average loss: 0.5118\n",
            "Iteration: 2785; Percent complete: 69.6%; Average loss: 0.5987\n",
            "Iteration: 2786; Percent complete: 69.7%; Average loss: 0.5187\n",
            "Iteration: 2787; Percent complete: 69.7%; Average loss: 0.4799\n",
            "Iteration: 2788; Percent complete: 69.7%; Average loss: 0.5260\n",
            "Iteration: 2789; Percent complete: 69.7%; Average loss: 0.5160\n",
            "Iteration: 2790; Percent complete: 69.8%; Average loss: 0.4703\n",
            "Iteration: 2791; Percent complete: 69.8%; Average loss: 0.4816\n",
            "Iteration: 2792; Percent complete: 69.8%; Average loss: 0.4891\n",
            "Iteration: 2793; Percent complete: 69.8%; Average loss: 0.4955\n",
            "Iteration: 2794; Percent complete: 69.8%; Average loss: 0.5875\n",
            "Iteration: 2795; Percent complete: 69.9%; Average loss: 0.6212\n",
            "Iteration: 2796; Percent complete: 69.9%; Average loss: 0.4684\n",
            "Iteration: 2797; Percent complete: 69.9%; Average loss: 0.4764\n",
            "Iteration: 2798; Percent complete: 70.0%; Average loss: 0.4644\n",
            "Iteration: 2799; Percent complete: 70.0%; Average loss: 0.5470\n",
            "Iteration: 2800; Percent complete: 70.0%; Average loss: 0.5165\n",
            "Iteration: 2801; Percent complete: 70.0%; Average loss: 0.4404\n",
            "Iteration: 2802; Percent complete: 70.0%; Average loss: 0.4465\n",
            "Iteration: 2803; Percent complete: 70.1%; Average loss: 0.5252\n",
            "Iteration: 2804; Percent complete: 70.1%; Average loss: 0.4982\n",
            "Iteration: 2805; Percent complete: 70.1%; Average loss: 0.5001\n",
            "Iteration: 2806; Percent complete: 70.2%; Average loss: 0.5305\n",
            "Iteration: 2807; Percent complete: 70.2%; Average loss: 0.4499\n",
            "Iteration: 2808; Percent complete: 70.2%; Average loss: 0.4841\n",
            "Iteration: 2809; Percent complete: 70.2%; Average loss: 0.4770\n",
            "Iteration: 2810; Percent complete: 70.2%; Average loss: 0.5055\n",
            "Iteration: 2811; Percent complete: 70.3%; Average loss: 0.5064\n",
            "Iteration: 2812; Percent complete: 70.3%; Average loss: 0.5261\n",
            "Iteration: 2813; Percent complete: 70.3%; Average loss: 0.5648\n",
            "Iteration: 2814; Percent complete: 70.3%; Average loss: 0.6046\n",
            "Iteration: 2815; Percent complete: 70.4%; Average loss: 0.4832\n",
            "Iteration: 2816; Percent complete: 70.4%; Average loss: 0.4756\n",
            "Iteration: 2817; Percent complete: 70.4%; Average loss: 0.4648\n",
            "Iteration: 2818; Percent complete: 70.5%; Average loss: 0.5001\n",
            "Iteration: 2819; Percent complete: 70.5%; Average loss: 0.5216\n",
            "Iteration: 2820; Percent complete: 70.5%; Average loss: 0.4541\n",
            "Iteration: 2821; Percent complete: 70.5%; Average loss: 0.4803\n",
            "Iteration: 2822; Percent complete: 70.5%; Average loss: 0.5338\n",
            "Iteration: 2823; Percent complete: 70.6%; Average loss: 0.5565\n",
            "Iteration: 2824; Percent complete: 70.6%; Average loss: 0.4901\n",
            "Iteration: 2825; Percent complete: 70.6%; Average loss: 0.4581\n",
            "Iteration: 2826; Percent complete: 70.7%; Average loss: 0.5529\n",
            "Iteration: 2827; Percent complete: 70.7%; Average loss: 0.4705\n",
            "Iteration: 2828; Percent complete: 70.7%; Average loss: 0.4950\n",
            "Iteration: 2829; Percent complete: 70.7%; Average loss: 0.3977\n",
            "Iteration: 2830; Percent complete: 70.8%; Average loss: 0.4473\n",
            "Iteration: 2831; Percent complete: 70.8%; Average loss: 0.4344\n",
            "Iteration: 2832; Percent complete: 70.8%; Average loss: 0.3810\n",
            "Iteration: 2833; Percent complete: 70.8%; Average loss: 0.5270\n",
            "Iteration: 2834; Percent complete: 70.9%; Average loss: 0.4257\n",
            "Iteration: 2835; Percent complete: 70.9%; Average loss: 0.4729\n",
            "Iteration: 2836; Percent complete: 70.9%; Average loss: 0.4427\n",
            "Iteration: 2837; Percent complete: 70.9%; Average loss: 0.5131\n",
            "Iteration: 2838; Percent complete: 71.0%; Average loss: 0.4943\n",
            "Iteration: 2839; Percent complete: 71.0%; Average loss: 0.4915\n",
            "Iteration: 2840; Percent complete: 71.0%; Average loss: 0.5145\n",
            "Iteration: 2841; Percent complete: 71.0%; Average loss: 0.4816\n",
            "Iteration: 2842; Percent complete: 71.0%; Average loss: 0.4671\n",
            "Iteration: 2843; Percent complete: 71.1%; Average loss: 0.4672\n",
            "Iteration: 2844; Percent complete: 71.1%; Average loss: 0.4626\n",
            "Iteration: 2845; Percent complete: 71.1%; Average loss: 0.4917\n",
            "Iteration: 2846; Percent complete: 71.2%; Average loss: 0.5542\n",
            "Iteration: 2847; Percent complete: 71.2%; Average loss: 0.4627\n",
            "Iteration: 2848; Percent complete: 71.2%; Average loss: 0.5644\n",
            "Iteration: 2849; Percent complete: 71.2%; Average loss: 0.4712\n",
            "Iteration: 2850; Percent complete: 71.2%; Average loss: 0.4651\n",
            "Iteration: 2851; Percent complete: 71.3%; Average loss: 0.5070\n",
            "Iteration: 2852; Percent complete: 71.3%; Average loss: 0.4945\n",
            "Iteration: 2853; Percent complete: 71.3%; Average loss: 0.4373\n",
            "Iteration: 2854; Percent complete: 71.4%; Average loss: 0.4918\n",
            "Iteration: 2855; Percent complete: 71.4%; Average loss: 0.4901\n",
            "Iteration: 2856; Percent complete: 71.4%; Average loss: 0.5166\n",
            "Iteration: 2857; Percent complete: 71.4%; Average loss: 0.5291\n",
            "Iteration: 2858; Percent complete: 71.5%; Average loss: 0.4867\n",
            "Iteration: 2859; Percent complete: 71.5%; Average loss: 0.4673\n",
            "Iteration: 2860; Percent complete: 71.5%; Average loss: 0.4743\n",
            "Iteration: 2861; Percent complete: 71.5%; Average loss: 0.4567\n",
            "Iteration: 2862; Percent complete: 71.5%; Average loss: 0.4109\n",
            "Iteration: 2863; Percent complete: 71.6%; Average loss: 0.4550\n",
            "Iteration: 2864; Percent complete: 71.6%; Average loss: 0.4750\n",
            "Iteration: 2865; Percent complete: 71.6%; Average loss: 0.4575\n",
            "Iteration: 2866; Percent complete: 71.7%; Average loss: 0.4118\n",
            "Iteration: 2867; Percent complete: 71.7%; Average loss: 0.4590\n",
            "Iteration: 2868; Percent complete: 71.7%; Average loss: 0.5324\n",
            "Iteration: 2869; Percent complete: 71.7%; Average loss: 0.4777\n",
            "Iteration: 2870; Percent complete: 71.8%; Average loss: 0.4502\n",
            "Iteration: 2871; Percent complete: 71.8%; Average loss: 0.4137\n",
            "Iteration: 2872; Percent complete: 71.8%; Average loss: 0.4785\n",
            "Iteration: 2873; Percent complete: 71.8%; Average loss: 0.4152\n",
            "Iteration: 2874; Percent complete: 71.9%; Average loss: 0.4556\n",
            "Iteration: 2875; Percent complete: 71.9%; Average loss: 0.4391\n",
            "Iteration: 2876; Percent complete: 71.9%; Average loss: 0.4536\n",
            "Iteration: 2877; Percent complete: 71.9%; Average loss: 0.5521\n",
            "Iteration: 2878; Percent complete: 72.0%; Average loss: 0.5596\n",
            "Iteration: 2879; Percent complete: 72.0%; Average loss: 0.5030\n",
            "Iteration: 2880; Percent complete: 72.0%; Average loss: 0.5206\n",
            "Iteration: 2881; Percent complete: 72.0%; Average loss: 0.4931\n",
            "Iteration: 2882; Percent complete: 72.0%; Average loss: 0.5341\n",
            "Iteration: 2883; Percent complete: 72.1%; Average loss: 0.4953\n",
            "Iteration: 2884; Percent complete: 72.1%; Average loss: 0.4914\n",
            "Iteration: 2885; Percent complete: 72.1%; Average loss: 0.4589\n",
            "Iteration: 2886; Percent complete: 72.2%; Average loss: 0.4564\n",
            "Iteration: 2887; Percent complete: 72.2%; Average loss: 0.4926\n",
            "Iteration: 2888; Percent complete: 72.2%; Average loss: 0.4752\n",
            "Iteration: 2889; Percent complete: 72.2%; Average loss: 0.4302\n",
            "Iteration: 2890; Percent complete: 72.2%; Average loss: 0.4176\n",
            "Iteration: 2891; Percent complete: 72.3%; Average loss: 0.4442\n",
            "Iteration: 2892; Percent complete: 72.3%; Average loss: 0.5415\n",
            "Iteration: 2893; Percent complete: 72.3%; Average loss: 0.4879\n",
            "Iteration: 2894; Percent complete: 72.4%; Average loss: 0.4925\n",
            "Iteration: 2895; Percent complete: 72.4%; Average loss: 0.4529\n",
            "Iteration: 2896; Percent complete: 72.4%; Average loss: 0.4330\n",
            "Iteration: 2897; Percent complete: 72.4%; Average loss: 0.3966\n",
            "Iteration: 2898; Percent complete: 72.5%; Average loss: 0.4065\n",
            "Iteration: 2899; Percent complete: 72.5%; Average loss: 0.5005\n",
            "Iteration: 2900; Percent complete: 72.5%; Average loss: 0.4014\n",
            "Iteration: 2901; Percent complete: 72.5%; Average loss: 0.4479\n",
            "Iteration: 2902; Percent complete: 72.5%; Average loss: 0.4709\n",
            "Iteration: 2903; Percent complete: 72.6%; Average loss: 0.4638\n",
            "Iteration: 2904; Percent complete: 72.6%; Average loss: 0.4606\n",
            "Iteration: 2905; Percent complete: 72.6%; Average loss: 0.5898\n",
            "Iteration: 2906; Percent complete: 72.7%; Average loss: 0.4578\n",
            "Iteration: 2907; Percent complete: 72.7%; Average loss: 0.4193\n",
            "Iteration: 2908; Percent complete: 72.7%; Average loss: 0.4320\n",
            "Iteration: 2909; Percent complete: 72.7%; Average loss: 0.4735\n",
            "Iteration: 2910; Percent complete: 72.8%; Average loss: 0.4808\n",
            "Iteration: 2911; Percent complete: 72.8%; Average loss: 0.5072\n",
            "Iteration: 2912; Percent complete: 72.8%; Average loss: 0.4158\n",
            "Iteration: 2913; Percent complete: 72.8%; Average loss: 0.4200\n",
            "Iteration: 2914; Percent complete: 72.9%; Average loss: 0.4886\n",
            "Iteration: 2915; Percent complete: 72.9%; Average loss: 0.4269\n",
            "Iteration: 2916; Percent complete: 72.9%; Average loss: 0.5344\n",
            "Iteration: 2917; Percent complete: 72.9%; Average loss: 0.3802\n",
            "Iteration: 2918; Percent complete: 73.0%; Average loss: 0.4965\n",
            "Iteration: 2919; Percent complete: 73.0%; Average loss: 0.5047\n",
            "Iteration: 2920; Percent complete: 73.0%; Average loss: 0.4512\n",
            "Iteration: 2921; Percent complete: 73.0%; Average loss: 0.3983\n",
            "Iteration: 2922; Percent complete: 73.0%; Average loss: 0.4974\n",
            "Iteration: 2923; Percent complete: 73.1%; Average loss: 0.4471\n",
            "Iteration: 2924; Percent complete: 73.1%; Average loss: 0.4746\n",
            "Iteration: 2925; Percent complete: 73.1%; Average loss: 0.3885\n",
            "Iteration: 2926; Percent complete: 73.2%; Average loss: 0.4264\n",
            "Iteration: 2927; Percent complete: 73.2%; Average loss: 0.4075\n",
            "Iteration: 2928; Percent complete: 73.2%; Average loss: 0.4640\n",
            "Iteration: 2929; Percent complete: 73.2%; Average loss: 0.4643\n",
            "Iteration: 2930; Percent complete: 73.2%; Average loss: 0.4461\n",
            "Iteration: 2931; Percent complete: 73.3%; Average loss: 0.4279\n",
            "Iteration: 2932; Percent complete: 73.3%; Average loss: 0.4191\n",
            "Iteration: 2933; Percent complete: 73.3%; Average loss: 0.4663\n",
            "Iteration: 2934; Percent complete: 73.4%; Average loss: 0.4001\n",
            "Iteration: 2935; Percent complete: 73.4%; Average loss: 0.4334\n",
            "Iteration: 2936; Percent complete: 73.4%; Average loss: 0.4107\n",
            "Iteration: 2937; Percent complete: 73.4%; Average loss: 0.4083\n",
            "Iteration: 2938; Percent complete: 73.5%; Average loss: 0.4397\n",
            "Iteration: 2939; Percent complete: 73.5%; Average loss: 0.3959\n",
            "Iteration: 2940; Percent complete: 73.5%; Average loss: 0.4888\n",
            "Iteration: 2941; Percent complete: 73.5%; Average loss: 0.4709\n",
            "Iteration: 2942; Percent complete: 73.6%; Average loss: 0.4347\n",
            "Iteration: 2943; Percent complete: 73.6%; Average loss: 0.4160\n",
            "Iteration: 2944; Percent complete: 73.6%; Average loss: 0.4317\n",
            "Iteration: 2945; Percent complete: 73.6%; Average loss: 0.3890\n",
            "Iteration: 2946; Percent complete: 73.7%; Average loss: 0.4586\n",
            "Iteration: 2947; Percent complete: 73.7%; Average loss: 0.4625\n",
            "Iteration: 2948; Percent complete: 73.7%; Average loss: 0.4645\n",
            "Iteration: 2949; Percent complete: 73.7%; Average loss: 0.3908\n",
            "Iteration: 2950; Percent complete: 73.8%; Average loss: 0.4506\n",
            "Iteration: 2951; Percent complete: 73.8%; Average loss: 0.4546\n",
            "Iteration: 2952; Percent complete: 73.8%; Average loss: 0.4331\n",
            "Iteration: 2953; Percent complete: 73.8%; Average loss: 0.3984\n",
            "Iteration: 2954; Percent complete: 73.9%; Average loss: 0.4985\n",
            "Iteration: 2955; Percent complete: 73.9%; Average loss: 0.4524\n",
            "Iteration: 2956; Percent complete: 73.9%; Average loss: 0.4179\n",
            "Iteration: 2957; Percent complete: 73.9%; Average loss: 0.4734\n",
            "Iteration: 2958; Percent complete: 74.0%; Average loss: 0.4436\n",
            "Iteration: 2959; Percent complete: 74.0%; Average loss: 0.4200\n",
            "Iteration: 2960; Percent complete: 74.0%; Average loss: 0.5016\n",
            "Iteration: 2961; Percent complete: 74.0%; Average loss: 0.4405\n",
            "Iteration: 2962; Percent complete: 74.1%; Average loss: 0.4260\n",
            "Iteration: 2963; Percent complete: 74.1%; Average loss: 0.3955\n",
            "Iteration: 2964; Percent complete: 74.1%; Average loss: 0.4825\n",
            "Iteration: 2965; Percent complete: 74.1%; Average loss: 0.4800\n",
            "Iteration: 2966; Percent complete: 74.2%; Average loss: 0.4350\n",
            "Iteration: 2967; Percent complete: 74.2%; Average loss: 0.3955\n",
            "Iteration: 2968; Percent complete: 74.2%; Average loss: 0.4218\n",
            "Iteration: 2969; Percent complete: 74.2%; Average loss: 0.4254\n",
            "Iteration: 2970; Percent complete: 74.2%; Average loss: 0.3987\n",
            "Iteration: 2971; Percent complete: 74.3%; Average loss: 0.4372\n",
            "Iteration: 2972; Percent complete: 74.3%; Average loss: 0.4154\n",
            "Iteration: 2973; Percent complete: 74.3%; Average loss: 0.3702\n",
            "Iteration: 2974; Percent complete: 74.4%; Average loss: 0.4088\n",
            "Iteration: 2975; Percent complete: 74.4%; Average loss: 0.4138\n",
            "Iteration: 2976; Percent complete: 74.4%; Average loss: 0.3794\n",
            "Iteration: 2977; Percent complete: 74.4%; Average loss: 0.3538\n",
            "Iteration: 2978; Percent complete: 74.5%; Average loss: 0.4479\n",
            "Iteration: 2979; Percent complete: 74.5%; Average loss: 0.4016\n",
            "Iteration: 2980; Percent complete: 74.5%; Average loss: 0.4007\n",
            "Iteration: 2981; Percent complete: 74.5%; Average loss: 0.4248\n",
            "Iteration: 2982; Percent complete: 74.6%; Average loss: 0.3872\n",
            "Iteration: 2983; Percent complete: 74.6%; Average loss: 0.3916\n",
            "Iteration: 2984; Percent complete: 74.6%; Average loss: 0.3641\n",
            "Iteration: 2985; Percent complete: 74.6%; Average loss: 0.4259\n",
            "Iteration: 2986; Percent complete: 74.7%; Average loss: 0.3559\n",
            "Iteration: 2987; Percent complete: 74.7%; Average loss: 0.4251\n",
            "Iteration: 2988; Percent complete: 74.7%; Average loss: 0.4257\n",
            "Iteration: 2989; Percent complete: 74.7%; Average loss: 0.4407\n",
            "Iteration: 2990; Percent complete: 74.8%; Average loss: 0.3634\n",
            "Iteration: 2991; Percent complete: 74.8%; Average loss: 0.4212\n",
            "Iteration: 2992; Percent complete: 74.8%; Average loss: 0.4104\n",
            "Iteration: 2993; Percent complete: 74.8%; Average loss: 0.3798\n",
            "Iteration: 2994; Percent complete: 74.9%; Average loss: 0.5267\n",
            "Iteration: 2995; Percent complete: 74.9%; Average loss: 0.3462\n",
            "Iteration: 2996; Percent complete: 74.9%; Average loss: 0.4578\n",
            "Iteration: 2997; Percent complete: 74.9%; Average loss: 0.3666\n",
            "Iteration: 2998; Percent complete: 75.0%; Average loss: 0.4442\n",
            "Iteration: 2999; Percent complete: 75.0%; Average loss: 0.4194\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 0.3701\n",
            "Iteration: 3001; Percent complete: 75.0%; Average loss: 0.4035\n",
            "Iteration: 3002; Percent complete: 75.0%; Average loss: 0.3767\n",
            "Iteration: 3003; Percent complete: 75.1%; Average loss: 0.4275\n",
            "Iteration: 3004; Percent complete: 75.1%; Average loss: 0.4341\n",
            "Iteration: 3005; Percent complete: 75.1%; Average loss: 0.3995\n",
            "Iteration: 3006; Percent complete: 75.1%; Average loss: 0.3606\n",
            "Iteration: 3007; Percent complete: 75.2%; Average loss: 0.4398\n",
            "Iteration: 3008; Percent complete: 75.2%; Average loss: 0.3678\n",
            "Iteration: 3009; Percent complete: 75.2%; Average loss: 0.4040\n",
            "Iteration: 3010; Percent complete: 75.2%; Average loss: 0.4344\n",
            "Iteration: 3011; Percent complete: 75.3%; Average loss: 0.3669\n",
            "Iteration: 3012; Percent complete: 75.3%; Average loss: 0.4145\n",
            "Iteration: 3013; Percent complete: 75.3%; Average loss: 0.3593\n",
            "Iteration: 3014; Percent complete: 75.3%; Average loss: 0.4822\n",
            "Iteration: 3015; Percent complete: 75.4%; Average loss: 0.4077\n",
            "Iteration: 3016; Percent complete: 75.4%; Average loss: 0.3872\n",
            "Iteration: 3017; Percent complete: 75.4%; Average loss: 0.3704\n",
            "Iteration: 3018; Percent complete: 75.4%; Average loss: 0.3742\n",
            "Iteration: 3019; Percent complete: 75.5%; Average loss: 0.3805\n",
            "Iteration: 3020; Percent complete: 75.5%; Average loss: 0.4009\n",
            "Iteration: 3021; Percent complete: 75.5%; Average loss: 0.3973\n",
            "Iteration: 3022; Percent complete: 75.5%; Average loss: 0.3857\n",
            "Iteration: 3023; Percent complete: 75.6%; Average loss: 0.4365\n",
            "Iteration: 3024; Percent complete: 75.6%; Average loss: 0.2848\n",
            "Iteration: 3025; Percent complete: 75.6%; Average loss: 0.3690\n",
            "Iteration: 3026; Percent complete: 75.6%; Average loss: 0.4078\n",
            "Iteration: 3027; Percent complete: 75.7%; Average loss: 0.3075\n",
            "Iteration: 3028; Percent complete: 75.7%; Average loss: 0.3857\n",
            "Iteration: 3029; Percent complete: 75.7%; Average loss: 0.3368\n",
            "Iteration: 3030; Percent complete: 75.8%; Average loss: 0.4295\n",
            "Iteration: 3031; Percent complete: 75.8%; Average loss: 0.3913\n",
            "Iteration: 3032; Percent complete: 75.8%; Average loss: 0.3898\n",
            "Iteration: 3033; Percent complete: 75.8%; Average loss: 0.3453\n",
            "Iteration: 3034; Percent complete: 75.8%; Average loss: 0.3826\n",
            "Iteration: 3035; Percent complete: 75.9%; Average loss: 0.4510\n",
            "Iteration: 3036; Percent complete: 75.9%; Average loss: 0.4118\n",
            "Iteration: 3037; Percent complete: 75.9%; Average loss: 0.3428\n",
            "Iteration: 3038; Percent complete: 75.9%; Average loss: 0.3356\n",
            "Iteration: 3039; Percent complete: 76.0%; Average loss: 0.3570\n",
            "Iteration: 3040; Percent complete: 76.0%; Average loss: 0.3756\n",
            "Iteration: 3041; Percent complete: 76.0%; Average loss: 0.3619\n",
            "Iteration: 3042; Percent complete: 76.0%; Average loss: 0.4268\n",
            "Iteration: 3043; Percent complete: 76.1%; Average loss: 0.4033\n",
            "Iteration: 3044; Percent complete: 76.1%; Average loss: 0.3419\n",
            "Iteration: 3045; Percent complete: 76.1%; Average loss: 0.3712\n",
            "Iteration: 3046; Percent complete: 76.1%; Average loss: 0.3926\n",
            "Iteration: 3047; Percent complete: 76.2%; Average loss: 0.3485\n",
            "Iteration: 3048; Percent complete: 76.2%; Average loss: 0.3566\n",
            "Iteration: 3049; Percent complete: 76.2%; Average loss: 0.3453\n",
            "Iteration: 3050; Percent complete: 76.2%; Average loss: 0.3280\n",
            "Iteration: 3051; Percent complete: 76.3%; Average loss: 0.3828\n",
            "Iteration: 3052; Percent complete: 76.3%; Average loss: 0.3257\n",
            "Iteration: 3053; Percent complete: 76.3%; Average loss: 0.3856\n",
            "Iteration: 3054; Percent complete: 76.3%; Average loss: 0.4079\n",
            "Iteration: 3055; Percent complete: 76.4%; Average loss: 0.3779\n",
            "Iteration: 3056; Percent complete: 76.4%; Average loss: 0.3526\n",
            "Iteration: 3057; Percent complete: 76.4%; Average loss: 0.3458\n",
            "Iteration: 3058; Percent complete: 76.4%; Average loss: 0.3996\n",
            "Iteration: 3059; Percent complete: 76.5%; Average loss: 0.4366\n",
            "Iteration: 3060; Percent complete: 76.5%; Average loss: 0.3465\n",
            "Iteration: 3061; Percent complete: 76.5%; Average loss: 0.4092\n",
            "Iteration: 3062; Percent complete: 76.5%; Average loss: 0.3531\n",
            "Iteration: 3063; Percent complete: 76.6%; Average loss: 0.3868\n",
            "Iteration: 3064; Percent complete: 76.6%; Average loss: 0.3282\n",
            "Iteration: 3065; Percent complete: 76.6%; Average loss: 0.3122\n",
            "Iteration: 3066; Percent complete: 76.6%; Average loss: 0.3546\n",
            "Iteration: 3067; Percent complete: 76.7%; Average loss: 0.4148\n",
            "Iteration: 3068; Percent complete: 76.7%; Average loss: 0.3593\n",
            "Iteration: 3069; Percent complete: 76.7%; Average loss: 0.3419\n",
            "Iteration: 3070; Percent complete: 76.8%; Average loss: 0.3547\n",
            "Iteration: 3071; Percent complete: 76.8%; Average loss: 0.3891\n",
            "Iteration: 3072; Percent complete: 76.8%; Average loss: 0.4100\n",
            "Iteration: 3073; Percent complete: 76.8%; Average loss: 0.4258\n",
            "Iteration: 3074; Percent complete: 76.8%; Average loss: 0.3465\n",
            "Iteration: 3075; Percent complete: 76.9%; Average loss: 0.3798\n",
            "Iteration: 3076; Percent complete: 76.9%; Average loss: 0.3670\n",
            "Iteration: 3077; Percent complete: 76.9%; Average loss: 0.3526\n",
            "Iteration: 3078; Percent complete: 77.0%; Average loss: 0.3812\n",
            "Iteration: 3079; Percent complete: 77.0%; Average loss: 0.3848\n",
            "Iteration: 3080; Percent complete: 77.0%; Average loss: 0.3915\n",
            "Iteration: 3081; Percent complete: 77.0%; Average loss: 0.3715\n",
            "Iteration: 3082; Percent complete: 77.0%; Average loss: 0.4103\n",
            "Iteration: 3083; Percent complete: 77.1%; Average loss: 0.3438\n",
            "Iteration: 3084; Percent complete: 77.1%; Average loss: 0.3382\n",
            "Iteration: 3085; Percent complete: 77.1%; Average loss: 0.3518\n",
            "Iteration: 3086; Percent complete: 77.1%; Average loss: 0.3783\n",
            "Iteration: 3087; Percent complete: 77.2%; Average loss: 0.3394\n",
            "Iteration: 3088; Percent complete: 77.2%; Average loss: 0.3589\n",
            "Iteration: 3089; Percent complete: 77.2%; Average loss: 0.3251\n",
            "Iteration: 3090; Percent complete: 77.2%; Average loss: 0.3218\n",
            "Iteration: 3091; Percent complete: 77.3%; Average loss: 0.3322\n",
            "Iteration: 3092; Percent complete: 77.3%; Average loss: 0.3207\n",
            "Iteration: 3093; Percent complete: 77.3%; Average loss: 0.3455\n",
            "Iteration: 3094; Percent complete: 77.3%; Average loss: 0.3746\n",
            "Iteration: 3095; Percent complete: 77.4%; Average loss: 0.3848\n",
            "Iteration: 3096; Percent complete: 77.4%; Average loss: 0.3310\n",
            "Iteration: 3097; Percent complete: 77.4%; Average loss: 0.3219\n",
            "Iteration: 3098; Percent complete: 77.5%; Average loss: 0.3296\n",
            "Iteration: 3099; Percent complete: 77.5%; Average loss: 0.4108\n",
            "Iteration: 3100; Percent complete: 77.5%; Average loss: 0.3743\n",
            "Iteration: 3101; Percent complete: 77.5%; Average loss: 0.3834\n",
            "Iteration: 3102; Percent complete: 77.5%; Average loss: 0.3647\n",
            "Iteration: 3103; Percent complete: 77.6%; Average loss: 0.3540\n",
            "Iteration: 3104; Percent complete: 77.6%; Average loss: 0.3747\n",
            "Iteration: 3105; Percent complete: 77.6%; Average loss: 0.3468\n",
            "Iteration: 3106; Percent complete: 77.6%; Average loss: 0.3335\n",
            "Iteration: 3107; Percent complete: 77.7%; Average loss: 0.4058\n",
            "Iteration: 3108; Percent complete: 77.7%; Average loss: 0.3974\n",
            "Iteration: 3109; Percent complete: 77.7%; Average loss: 0.3191\n",
            "Iteration: 3110; Percent complete: 77.8%; Average loss: 0.3118\n",
            "Iteration: 3111; Percent complete: 77.8%; Average loss: 0.3595\n",
            "Iteration: 3112; Percent complete: 77.8%; Average loss: 0.3824\n",
            "Iteration: 3113; Percent complete: 77.8%; Average loss: 0.3058\n",
            "Iteration: 3114; Percent complete: 77.8%; Average loss: 0.3159\n",
            "Iteration: 3115; Percent complete: 77.9%; Average loss: 0.3640\n",
            "Iteration: 3116; Percent complete: 77.9%; Average loss: 0.3327\n",
            "Iteration: 3117; Percent complete: 77.9%; Average loss: 0.3826\n",
            "Iteration: 3118; Percent complete: 78.0%; Average loss: 0.3564\n",
            "Iteration: 3119; Percent complete: 78.0%; Average loss: 0.2932\n",
            "Iteration: 3120; Percent complete: 78.0%; Average loss: 0.4011\n",
            "Iteration: 3121; Percent complete: 78.0%; Average loss: 0.3697\n",
            "Iteration: 3122; Percent complete: 78.0%; Average loss: 0.3097\n",
            "Iteration: 3123; Percent complete: 78.1%; Average loss: 0.3108\n",
            "Iteration: 3124; Percent complete: 78.1%; Average loss: 0.3190\n",
            "Iteration: 3125; Percent complete: 78.1%; Average loss: 0.3950\n",
            "Iteration: 3126; Percent complete: 78.1%; Average loss: 0.3496\n",
            "Iteration: 3127; Percent complete: 78.2%; Average loss: 0.3362\n",
            "Iteration: 3128; Percent complete: 78.2%; Average loss: 0.3507\n",
            "Iteration: 3129; Percent complete: 78.2%; Average loss: 0.3231\n",
            "Iteration: 3130; Percent complete: 78.2%; Average loss: 0.3411\n",
            "Iteration: 3131; Percent complete: 78.3%; Average loss: 0.3132\n",
            "Iteration: 3132; Percent complete: 78.3%; Average loss: 0.3563\n",
            "Iteration: 3133; Percent complete: 78.3%; Average loss: 0.3812\n",
            "Iteration: 3134; Percent complete: 78.3%; Average loss: 0.3367\n",
            "Iteration: 3135; Percent complete: 78.4%; Average loss: 0.3471\n",
            "Iteration: 3136; Percent complete: 78.4%; Average loss: 0.3023\n",
            "Iteration: 3137; Percent complete: 78.4%; Average loss: 0.3642\n",
            "Iteration: 3138; Percent complete: 78.5%; Average loss: 0.4017\n",
            "Iteration: 3139; Percent complete: 78.5%; Average loss: 0.3742\n",
            "Iteration: 3140; Percent complete: 78.5%; Average loss: 0.3355\n",
            "Iteration: 3141; Percent complete: 78.5%; Average loss: 0.2999\n",
            "Iteration: 3142; Percent complete: 78.5%; Average loss: 0.3501\n",
            "Iteration: 3143; Percent complete: 78.6%; Average loss: 0.3185\n",
            "Iteration: 3144; Percent complete: 78.6%; Average loss: 0.3096\n",
            "Iteration: 3145; Percent complete: 78.6%; Average loss: 0.3148\n",
            "Iteration: 3146; Percent complete: 78.6%; Average loss: 0.3709\n",
            "Iteration: 3147; Percent complete: 78.7%; Average loss: 0.3416\n",
            "Iteration: 3148; Percent complete: 78.7%; Average loss: 0.3351\n",
            "Iteration: 3149; Percent complete: 78.7%; Average loss: 0.3383\n",
            "Iteration: 3150; Percent complete: 78.8%; Average loss: 0.3579\n",
            "Iteration: 3151; Percent complete: 78.8%; Average loss: 0.3074\n",
            "Iteration: 3152; Percent complete: 78.8%; Average loss: 0.3135\n",
            "Iteration: 3153; Percent complete: 78.8%; Average loss: 0.3735\n",
            "Iteration: 3154; Percent complete: 78.8%; Average loss: 0.2838\n",
            "Iteration: 3155; Percent complete: 78.9%; Average loss: 0.3682\n",
            "Iteration: 3156; Percent complete: 78.9%; Average loss: 0.2979\n",
            "Iteration: 3157; Percent complete: 78.9%; Average loss: 0.3302\n",
            "Iteration: 3158; Percent complete: 79.0%; Average loss: 0.3140\n",
            "Iteration: 3159; Percent complete: 79.0%; Average loss: 0.3533\n",
            "Iteration: 3160; Percent complete: 79.0%; Average loss: 0.3108\n",
            "Iteration: 3161; Percent complete: 79.0%; Average loss: 0.3423\n",
            "Iteration: 3162; Percent complete: 79.0%; Average loss: 0.3349\n",
            "Iteration: 3163; Percent complete: 79.1%; Average loss: 0.3038\n",
            "Iteration: 3164; Percent complete: 79.1%; Average loss: 0.2946\n",
            "Iteration: 3165; Percent complete: 79.1%; Average loss: 0.3672\n",
            "Iteration: 3166; Percent complete: 79.1%; Average loss: 0.2896\n",
            "Iteration: 3167; Percent complete: 79.2%; Average loss: 0.3085\n",
            "Iteration: 3168; Percent complete: 79.2%; Average loss: 0.3622\n",
            "Iteration: 3169; Percent complete: 79.2%; Average loss: 0.3293\n",
            "Iteration: 3170; Percent complete: 79.2%; Average loss: 0.3206\n",
            "Iteration: 3171; Percent complete: 79.3%; Average loss: 0.2776\n",
            "Iteration: 3172; Percent complete: 79.3%; Average loss: 0.3323\n",
            "Iteration: 3173; Percent complete: 79.3%; Average loss: 0.3181\n",
            "Iteration: 3174; Percent complete: 79.3%; Average loss: 0.3099\n",
            "Iteration: 3175; Percent complete: 79.4%; Average loss: 0.2891\n",
            "Iteration: 3176; Percent complete: 79.4%; Average loss: 0.2915\n",
            "Iteration: 3177; Percent complete: 79.4%; Average loss: 0.3018\n",
            "Iteration: 3178; Percent complete: 79.5%; Average loss: 0.3431\n",
            "Iteration: 3179; Percent complete: 79.5%; Average loss: 0.3086\n",
            "Iteration: 3180; Percent complete: 79.5%; Average loss: 0.2688\n",
            "Iteration: 3181; Percent complete: 79.5%; Average loss: 0.3286\n",
            "Iteration: 3182; Percent complete: 79.5%; Average loss: 0.3239\n",
            "Iteration: 3183; Percent complete: 79.6%; Average loss: 0.3099\n",
            "Iteration: 3184; Percent complete: 79.6%; Average loss: 0.3137\n",
            "Iteration: 3185; Percent complete: 79.6%; Average loss: 0.2812\n",
            "Iteration: 3186; Percent complete: 79.7%; Average loss: 0.3432\n",
            "Iteration: 3187; Percent complete: 79.7%; Average loss: 0.3189\n",
            "Iteration: 3188; Percent complete: 79.7%; Average loss: 0.3157\n",
            "Iteration: 3189; Percent complete: 79.7%; Average loss: 0.3278\n",
            "Iteration: 3190; Percent complete: 79.8%; Average loss: 0.3633\n",
            "Iteration: 3191; Percent complete: 79.8%; Average loss: 0.3259\n",
            "Iteration: 3192; Percent complete: 79.8%; Average loss: 0.3365\n",
            "Iteration: 3193; Percent complete: 79.8%; Average loss: 0.3146\n",
            "Iteration: 3194; Percent complete: 79.8%; Average loss: 0.2851\n",
            "Iteration: 3195; Percent complete: 79.9%; Average loss: 0.3635\n",
            "Iteration: 3196; Percent complete: 79.9%; Average loss: 0.3458\n",
            "Iteration: 3197; Percent complete: 79.9%; Average loss: 0.3783\n",
            "Iteration: 3198; Percent complete: 80.0%; Average loss: 0.3108\n",
            "Iteration: 3199; Percent complete: 80.0%; Average loss: 0.3035\n",
            "Iteration: 3200; Percent complete: 80.0%; Average loss: 0.3741\n",
            "Iteration: 3201; Percent complete: 80.0%; Average loss: 0.2853\n",
            "Iteration: 3202; Percent complete: 80.0%; Average loss: 0.3367\n",
            "Iteration: 3203; Percent complete: 80.1%; Average loss: 0.2901\n",
            "Iteration: 3204; Percent complete: 80.1%; Average loss: 0.2876\n",
            "Iteration: 3205; Percent complete: 80.1%; Average loss: 0.2889\n",
            "Iteration: 3206; Percent complete: 80.2%; Average loss: 0.3103\n",
            "Iteration: 3207; Percent complete: 80.2%; Average loss: 0.3563\n",
            "Iteration: 3208; Percent complete: 80.2%; Average loss: 0.3181\n",
            "Iteration: 3209; Percent complete: 80.2%; Average loss: 0.2875\n",
            "Iteration: 3210; Percent complete: 80.2%; Average loss: 0.3024\n",
            "Iteration: 3211; Percent complete: 80.3%; Average loss: 0.2633\n",
            "Iteration: 3212; Percent complete: 80.3%; Average loss: 0.2950\n",
            "Iteration: 3213; Percent complete: 80.3%; Average loss: 0.3047\n",
            "Iteration: 3214; Percent complete: 80.3%; Average loss: 0.3325\n",
            "Iteration: 3215; Percent complete: 80.4%; Average loss: 0.3354\n",
            "Iteration: 3216; Percent complete: 80.4%; Average loss: 0.3176\n",
            "Iteration: 3217; Percent complete: 80.4%; Average loss: 0.3432\n",
            "Iteration: 3218; Percent complete: 80.5%; Average loss: 0.2819\n",
            "Iteration: 3219; Percent complete: 80.5%; Average loss: 0.3493\n",
            "Iteration: 3220; Percent complete: 80.5%; Average loss: 0.2663\n",
            "Iteration: 3221; Percent complete: 80.5%; Average loss: 0.3090\n",
            "Iteration: 3222; Percent complete: 80.5%; Average loss: 0.3302\n",
            "Iteration: 3223; Percent complete: 80.6%; Average loss: 0.2921\n",
            "Iteration: 3224; Percent complete: 80.6%; Average loss: 0.3166\n",
            "Iteration: 3225; Percent complete: 80.6%; Average loss: 0.3308\n",
            "Iteration: 3226; Percent complete: 80.7%; Average loss: 0.3364\n",
            "Iteration: 3227; Percent complete: 80.7%; Average loss: 0.3266\n",
            "Iteration: 3228; Percent complete: 80.7%; Average loss: 0.2847\n",
            "Iteration: 3229; Percent complete: 80.7%; Average loss: 0.2843\n",
            "Iteration: 3230; Percent complete: 80.8%; Average loss: 0.3029\n",
            "Iteration: 3231; Percent complete: 80.8%; Average loss: 0.3330\n",
            "Iteration: 3232; Percent complete: 80.8%; Average loss: 0.3230\n",
            "Iteration: 3233; Percent complete: 80.8%; Average loss: 0.3427\n",
            "Iteration: 3234; Percent complete: 80.8%; Average loss: 0.3291\n",
            "Iteration: 3235; Percent complete: 80.9%; Average loss: 0.2616\n",
            "Iteration: 3236; Percent complete: 80.9%; Average loss: 0.2848\n",
            "Iteration: 3237; Percent complete: 80.9%; Average loss: 0.3022\n",
            "Iteration: 3238; Percent complete: 81.0%; Average loss: 0.2968\n",
            "Iteration: 3239; Percent complete: 81.0%; Average loss: 0.2951\n",
            "Iteration: 3240; Percent complete: 81.0%; Average loss: 0.3216\n",
            "Iteration: 3241; Percent complete: 81.0%; Average loss: 0.3177\n",
            "Iteration: 3242; Percent complete: 81.0%; Average loss: 0.2521\n",
            "Iteration: 3243; Percent complete: 81.1%; Average loss: 0.2964\n",
            "Iteration: 3244; Percent complete: 81.1%; Average loss: 0.2692\n",
            "Iteration: 3245; Percent complete: 81.1%; Average loss: 0.3370\n",
            "Iteration: 3246; Percent complete: 81.2%; Average loss: 0.2530\n",
            "Iteration: 3247; Percent complete: 81.2%; Average loss: 0.3355\n",
            "Iteration: 3248; Percent complete: 81.2%; Average loss: 0.2991\n",
            "Iteration: 3249; Percent complete: 81.2%; Average loss: 0.3060\n",
            "Iteration: 3250; Percent complete: 81.2%; Average loss: 0.2951\n",
            "Iteration: 3251; Percent complete: 81.3%; Average loss: 0.2958\n",
            "Iteration: 3252; Percent complete: 81.3%; Average loss: 0.2642\n",
            "Iteration: 3253; Percent complete: 81.3%; Average loss: 0.3320\n",
            "Iteration: 3254; Percent complete: 81.3%; Average loss: 0.2729\n",
            "Iteration: 3255; Percent complete: 81.4%; Average loss: 0.3065\n",
            "Iteration: 3256; Percent complete: 81.4%; Average loss: 0.3214\n",
            "Iteration: 3257; Percent complete: 81.4%; Average loss: 0.2828\n",
            "Iteration: 3258; Percent complete: 81.5%; Average loss: 0.3095\n",
            "Iteration: 3259; Percent complete: 81.5%; Average loss: 0.3076\n",
            "Iteration: 3260; Percent complete: 81.5%; Average loss: 0.3078\n",
            "Iteration: 3261; Percent complete: 81.5%; Average loss: 0.3313\n",
            "Iteration: 3262; Percent complete: 81.5%; Average loss: 0.3151\n",
            "Iteration: 3263; Percent complete: 81.6%; Average loss: 0.2716\n",
            "Iteration: 3264; Percent complete: 81.6%; Average loss: 0.2751\n",
            "Iteration: 3265; Percent complete: 81.6%; Average loss: 0.2972\n",
            "Iteration: 3266; Percent complete: 81.7%; Average loss: 0.2867\n",
            "Iteration: 3267; Percent complete: 81.7%; Average loss: 0.2653\n",
            "Iteration: 3268; Percent complete: 81.7%; Average loss: 0.2947\n",
            "Iteration: 3269; Percent complete: 81.7%; Average loss: 0.2716\n",
            "Iteration: 3270; Percent complete: 81.8%; Average loss: 0.2511\n",
            "Iteration: 3271; Percent complete: 81.8%; Average loss: 0.2457\n",
            "Iteration: 3272; Percent complete: 81.8%; Average loss: 0.2638\n",
            "Iteration: 3273; Percent complete: 81.8%; Average loss: 0.2719\n",
            "Iteration: 3274; Percent complete: 81.8%; Average loss: 0.3087\n",
            "Iteration: 3275; Percent complete: 81.9%; Average loss: 0.2412\n",
            "Iteration: 3276; Percent complete: 81.9%; Average loss: 0.3423\n",
            "Iteration: 3277; Percent complete: 81.9%; Average loss: 0.2665\n",
            "Iteration: 3278; Percent complete: 82.0%; Average loss: 0.2832\n",
            "Iteration: 3279; Percent complete: 82.0%; Average loss: 0.3022\n",
            "Iteration: 3280; Percent complete: 82.0%; Average loss: 0.3325\n",
            "Iteration: 3281; Percent complete: 82.0%; Average loss: 0.3010\n",
            "Iteration: 3282; Percent complete: 82.0%; Average loss: 0.2538\n",
            "Iteration: 3283; Percent complete: 82.1%; Average loss: 0.2633\n",
            "Iteration: 3284; Percent complete: 82.1%; Average loss: 0.3532\n",
            "Iteration: 3285; Percent complete: 82.1%; Average loss: 0.3186\n",
            "Iteration: 3286; Percent complete: 82.2%; Average loss: 0.2574\n",
            "Iteration: 3287; Percent complete: 82.2%; Average loss: 0.2782\n",
            "Iteration: 3288; Percent complete: 82.2%; Average loss: 0.3340\n",
            "Iteration: 3289; Percent complete: 82.2%; Average loss: 0.3300\n",
            "Iteration: 3290; Percent complete: 82.2%; Average loss: 0.3133\n",
            "Iteration: 3291; Percent complete: 82.3%; Average loss: 0.2561\n",
            "Iteration: 3292; Percent complete: 82.3%; Average loss: 0.3007\n",
            "Iteration: 3293; Percent complete: 82.3%; Average loss: 0.2619\n",
            "Iteration: 3294; Percent complete: 82.3%; Average loss: 0.3131\n",
            "Iteration: 3295; Percent complete: 82.4%; Average loss: 0.2532\n",
            "Iteration: 3296; Percent complete: 82.4%; Average loss: 0.2848\n",
            "Iteration: 3297; Percent complete: 82.4%; Average loss: 0.2400\n",
            "Iteration: 3298; Percent complete: 82.5%; Average loss: 0.2511\n",
            "Iteration: 3299; Percent complete: 82.5%; Average loss: 0.2165\n",
            "Iteration: 3300; Percent complete: 82.5%; Average loss: 0.2555\n",
            "Iteration: 3301; Percent complete: 82.5%; Average loss: 0.2737\n",
            "Iteration: 3302; Percent complete: 82.5%; Average loss: 0.3069\n",
            "Iteration: 3303; Percent complete: 82.6%; Average loss: 0.2808\n",
            "Iteration: 3304; Percent complete: 82.6%; Average loss: 0.3414\n",
            "Iteration: 3305; Percent complete: 82.6%; Average loss: 0.3035\n",
            "Iteration: 3306; Percent complete: 82.7%; Average loss: 0.2717\n",
            "Iteration: 3307; Percent complete: 82.7%; Average loss: 0.2571\n",
            "Iteration: 3308; Percent complete: 82.7%; Average loss: 0.2451\n",
            "Iteration: 3309; Percent complete: 82.7%; Average loss: 0.3296\n",
            "Iteration: 3310; Percent complete: 82.8%; Average loss: 0.2934\n",
            "Iteration: 3311; Percent complete: 82.8%; Average loss: 0.2671\n",
            "Iteration: 3312; Percent complete: 82.8%; Average loss: 0.2875\n",
            "Iteration: 3313; Percent complete: 82.8%; Average loss: 0.2880\n",
            "Iteration: 3314; Percent complete: 82.8%; Average loss: 0.2637\n",
            "Iteration: 3315; Percent complete: 82.9%; Average loss: 0.3032\n",
            "Iteration: 3316; Percent complete: 82.9%; Average loss: 0.2797\n",
            "Iteration: 3317; Percent complete: 82.9%; Average loss: 0.2792\n",
            "Iteration: 3318; Percent complete: 83.0%; Average loss: 0.2345\n",
            "Iteration: 3319; Percent complete: 83.0%; Average loss: 0.2619\n",
            "Iteration: 3320; Percent complete: 83.0%; Average loss: 0.2660\n",
            "Iteration: 3321; Percent complete: 83.0%; Average loss: 0.2495\n",
            "Iteration: 3322; Percent complete: 83.0%; Average loss: 0.2307\n",
            "Iteration: 3323; Percent complete: 83.1%; Average loss: 0.3080\n",
            "Iteration: 3324; Percent complete: 83.1%; Average loss: 0.2799\n",
            "Iteration: 3325; Percent complete: 83.1%; Average loss: 0.2757\n",
            "Iteration: 3326; Percent complete: 83.2%; Average loss: 0.2830\n",
            "Iteration: 3327; Percent complete: 83.2%; Average loss: 0.2867\n",
            "Iteration: 3328; Percent complete: 83.2%; Average loss: 0.2816\n",
            "Iteration: 3329; Percent complete: 83.2%; Average loss: 0.2372\n",
            "Iteration: 3330; Percent complete: 83.2%; Average loss: 0.2645\n",
            "Iteration: 3331; Percent complete: 83.3%; Average loss: 0.2404\n",
            "Iteration: 3332; Percent complete: 83.3%; Average loss: 0.2723\n",
            "Iteration: 3333; Percent complete: 83.3%; Average loss: 0.2450\n",
            "Iteration: 3334; Percent complete: 83.4%; Average loss: 0.3418\n",
            "Iteration: 3335; Percent complete: 83.4%; Average loss: 0.2762\n",
            "Iteration: 3336; Percent complete: 83.4%; Average loss: 0.2445\n",
            "Iteration: 3337; Percent complete: 83.4%; Average loss: 0.2918\n",
            "Iteration: 3338; Percent complete: 83.5%; Average loss: 0.3156\n",
            "Iteration: 3339; Percent complete: 83.5%; Average loss: 0.2901\n",
            "Iteration: 3340; Percent complete: 83.5%; Average loss: 0.2543\n",
            "Iteration: 3341; Percent complete: 83.5%; Average loss: 0.2914\n",
            "Iteration: 3342; Percent complete: 83.5%; Average loss: 0.2474\n",
            "Iteration: 3343; Percent complete: 83.6%; Average loss: 0.2392\n",
            "Iteration: 3344; Percent complete: 83.6%; Average loss: 0.2609\n",
            "Iteration: 3345; Percent complete: 83.6%; Average loss: 0.2159\n",
            "Iteration: 3346; Percent complete: 83.7%; Average loss: 0.2651\n",
            "Iteration: 3347; Percent complete: 83.7%; Average loss: 0.2962\n",
            "Iteration: 3348; Percent complete: 83.7%; Average loss: 0.2299\n",
            "Iteration: 3349; Percent complete: 83.7%; Average loss: 0.2467\n",
            "Iteration: 3350; Percent complete: 83.8%; Average loss: 0.2326\n",
            "Iteration: 3351; Percent complete: 83.8%; Average loss: 0.2691\n",
            "Iteration: 3352; Percent complete: 83.8%; Average loss: 0.2357\n",
            "Iteration: 3353; Percent complete: 83.8%; Average loss: 0.2326\n",
            "Iteration: 3354; Percent complete: 83.9%; Average loss: 0.2567\n",
            "Iteration: 3355; Percent complete: 83.9%; Average loss: 0.2681\n",
            "Iteration: 3356; Percent complete: 83.9%; Average loss: 0.2384\n",
            "Iteration: 3357; Percent complete: 83.9%; Average loss: 0.2405\n",
            "Iteration: 3358; Percent complete: 84.0%; Average loss: 0.2547\n",
            "Iteration: 3359; Percent complete: 84.0%; Average loss: 0.2603\n",
            "Iteration: 3360; Percent complete: 84.0%; Average loss: 0.2451\n",
            "Iteration: 3361; Percent complete: 84.0%; Average loss: 0.2609\n",
            "Iteration: 3362; Percent complete: 84.0%; Average loss: 0.2719\n",
            "Iteration: 3363; Percent complete: 84.1%; Average loss: 0.2453\n",
            "Iteration: 3364; Percent complete: 84.1%; Average loss: 0.2205\n",
            "Iteration: 3365; Percent complete: 84.1%; Average loss: 0.2518\n",
            "Iteration: 3366; Percent complete: 84.2%; Average loss: 0.2652\n",
            "Iteration: 3367; Percent complete: 84.2%; Average loss: 0.2610\n",
            "Iteration: 3368; Percent complete: 84.2%; Average loss: 0.2757\n",
            "Iteration: 3369; Percent complete: 84.2%; Average loss: 0.2377\n",
            "Iteration: 3370; Percent complete: 84.2%; Average loss: 0.2561\n",
            "Iteration: 3371; Percent complete: 84.3%; Average loss: 0.2505\n",
            "Iteration: 3372; Percent complete: 84.3%; Average loss: 0.2464\n",
            "Iteration: 3373; Percent complete: 84.3%; Average loss: 0.2799\n",
            "Iteration: 3374; Percent complete: 84.4%; Average loss: 0.2374\n",
            "Iteration: 3375; Percent complete: 84.4%; Average loss: 0.2354\n",
            "Iteration: 3376; Percent complete: 84.4%; Average loss: 0.2382\n",
            "Iteration: 3377; Percent complete: 84.4%; Average loss: 0.2475\n",
            "Iteration: 3378; Percent complete: 84.5%; Average loss: 0.2383\n",
            "Iteration: 3379; Percent complete: 84.5%; Average loss: 0.2300\n",
            "Iteration: 3380; Percent complete: 84.5%; Average loss: 0.2480\n",
            "Iteration: 3381; Percent complete: 84.5%; Average loss: 0.3109\n",
            "Iteration: 3382; Percent complete: 84.5%; Average loss: 0.2613\n",
            "Iteration: 3383; Percent complete: 84.6%; Average loss: 0.2527\n",
            "Iteration: 3384; Percent complete: 84.6%; Average loss: 0.2640\n",
            "Iteration: 3385; Percent complete: 84.6%; Average loss: 0.2396\n",
            "Iteration: 3386; Percent complete: 84.7%; Average loss: 0.2790\n",
            "Iteration: 3387; Percent complete: 84.7%; Average loss: 0.2442\n",
            "Iteration: 3388; Percent complete: 84.7%; Average loss: 0.2101\n",
            "Iteration: 3389; Percent complete: 84.7%; Average loss: 0.2545\n",
            "Iteration: 3390; Percent complete: 84.8%; Average loss: 0.3113\n",
            "Iteration: 3391; Percent complete: 84.8%; Average loss: 0.2898\n",
            "Iteration: 3392; Percent complete: 84.8%; Average loss: 0.1936\n",
            "Iteration: 3393; Percent complete: 84.8%; Average loss: 0.2671\n",
            "Iteration: 3394; Percent complete: 84.9%; Average loss: 0.2151\n",
            "Iteration: 3395; Percent complete: 84.9%; Average loss: 0.2190\n",
            "Iteration: 3396; Percent complete: 84.9%; Average loss: 0.2204\n",
            "Iteration: 3397; Percent complete: 84.9%; Average loss: 0.2568\n",
            "Iteration: 3398; Percent complete: 85.0%; Average loss: 0.2442\n",
            "Iteration: 3399; Percent complete: 85.0%; Average loss: 0.2238\n",
            "Iteration: 3400; Percent complete: 85.0%; Average loss: 0.2643\n",
            "Iteration: 3401; Percent complete: 85.0%; Average loss: 0.2435\n",
            "Iteration: 3402; Percent complete: 85.0%; Average loss: 0.2636\n",
            "Iteration: 3403; Percent complete: 85.1%; Average loss: 0.2444\n",
            "Iteration: 3404; Percent complete: 85.1%; Average loss: 0.2561\n",
            "Iteration: 3405; Percent complete: 85.1%; Average loss: 0.2646\n",
            "Iteration: 3406; Percent complete: 85.2%; Average loss: 0.2181\n",
            "Iteration: 3407; Percent complete: 85.2%; Average loss: 0.2189\n",
            "Iteration: 3408; Percent complete: 85.2%; Average loss: 0.2675\n",
            "Iteration: 3409; Percent complete: 85.2%; Average loss: 0.2164\n",
            "Iteration: 3410; Percent complete: 85.2%; Average loss: 0.2213\n",
            "Iteration: 3411; Percent complete: 85.3%; Average loss: 0.2500\n",
            "Iteration: 3412; Percent complete: 85.3%; Average loss: 0.2655\n",
            "Iteration: 3413; Percent complete: 85.3%; Average loss: 0.1958\n",
            "Iteration: 3414; Percent complete: 85.4%; Average loss: 0.2334\n",
            "Iteration: 3415; Percent complete: 85.4%; Average loss: 0.2496\n",
            "Iteration: 3416; Percent complete: 85.4%; Average loss: 0.2493\n",
            "Iteration: 3417; Percent complete: 85.4%; Average loss: 0.2112\n",
            "Iteration: 3418; Percent complete: 85.5%; Average loss: 0.2361\n",
            "Iteration: 3419; Percent complete: 85.5%; Average loss: 0.2485\n",
            "Iteration: 3420; Percent complete: 85.5%; Average loss: 0.2791\n",
            "Iteration: 3421; Percent complete: 85.5%; Average loss: 0.2269\n",
            "Iteration: 3422; Percent complete: 85.5%; Average loss: 0.2556\n",
            "Iteration: 3423; Percent complete: 85.6%; Average loss: 0.2307\n",
            "Iteration: 3424; Percent complete: 85.6%; Average loss: 0.2550\n",
            "Iteration: 3425; Percent complete: 85.6%; Average loss: 0.2177\n",
            "Iteration: 3426; Percent complete: 85.7%; Average loss: 0.2048\n",
            "Iteration: 3427; Percent complete: 85.7%; Average loss: 0.2438\n",
            "Iteration: 3428; Percent complete: 85.7%; Average loss: 0.2349\n",
            "Iteration: 3429; Percent complete: 85.7%; Average loss: 0.2121\n",
            "Iteration: 3430; Percent complete: 85.8%; Average loss: 0.1966\n",
            "Iteration: 3431; Percent complete: 85.8%; Average loss: 0.1983\n",
            "Iteration: 3432; Percent complete: 85.8%; Average loss: 0.2298\n",
            "Iteration: 3433; Percent complete: 85.8%; Average loss: 0.2513\n",
            "Iteration: 3434; Percent complete: 85.9%; Average loss: 0.2165\n",
            "Iteration: 3435; Percent complete: 85.9%; Average loss: 0.2105\n",
            "Iteration: 3436; Percent complete: 85.9%; Average loss: 0.2373\n",
            "Iteration: 3437; Percent complete: 85.9%; Average loss: 0.2366\n",
            "Iteration: 3438; Percent complete: 86.0%; Average loss: 0.2704\n",
            "Iteration: 3439; Percent complete: 86.0%; Average loss: 0.2219\n",
            "Iteration: 3440; Percent complete: 86.0%; Average loss: 0.2382\n",
            "Iteration: 3441; Percent complete: 86.0%; Average loss: 0.2172\n",
            "Iteration: 3442; Percent complete: 86.1%; Average loss: 0.2244\n",
            "Iteration: 3443; Percent complete: 86.1%; Average loss: 0.2367\n",
            "Iteration: 3444; Percent complete: 86.1%; Average loss: 0.2182\n",
            "Iteration: 3445; Percent complete: 86.1%; Average loss: 0.2181\n",
            "Iteration: 3446; Percent complete: 86.2%; Average loss: 0.2483\n",
            "Iteration: 3447; Percent complete: 86.2%; Average loss: 0.2405\n",
            "Iteration: 3448; Percent complete: 86.2%; Average loss: 0.2017\n",
            "Iteration: 3449; Percent complete: 86.2%; Average loss: 0.2191\n",
            "Iteration: 3450; Percent complete: 86.2%; Average loss: 0.1905\n",
            "Iteration: 3451; Percent complete: 86.3%; Average loss: 0.2199\n",
            "Iteration: 3452; Percent complete: 86.3%; Average loss: 0.2071\n",
            "Iteration: 3453; Percent complete: 86.3%; Average loss: 0.2232\n",
            "Iteration: 3454; Percent complete: 86.4%; Average loss: 0.2334\n",
            "Iteration: 3455; Percent complete: 86.4%; Average loss: 0.2088\n",
            "Iteration: 3456; Percent complete: 86.4%; Average loss: 0.2384\n",
            "Iteration: 3457; Percent complete: 86.4%; Average loss: 0.2185\n",
            "Iteration: 3458; Percent complete: 86.5%; Average loss: 0.2340\n",
            "Iteration: 3459; Percent complete: 86.5%; Average loss: 0.2394\n",
            "Iteration: 3460; Percent complete: 86.5%; Average loss: 0.2245\n",
            "Iteration: 3461; Percent complete: 86.5%; Average loss: 0.2150\n",
            "Iteration: 3462; Percent complete: 86.6%; Average loss: 0.2475\n",
            "Iteration: 3463; Percent complete: 86.6%; Average loss: 0.2143\n",
            "Iteration: 3464; Percent complete: 86.6%; Average loss: 0.2104\n",
            "Iteration: 3465; Percent complete: 86.6%; Average loss: 0.1839\n",
            "Iteration: 3466; Percent complete: 86.7%; Average loss: 0.2914\n",
            "Iteration: 3467; Percent complete: 86.7%; Average loss: 0.2126\n",
            "Iteration: 3468; Percent complete: 86.7%; Average loss: 0.2337\n",
            "Iteration: 3469; Percent complete: 86.7%; Average loss: 0.1896\n",
            "Iteration: 3470; Percent complete: 86.8%; Average loss: 0.2035\n",
            "Iteration: 3471; Percent complete: 86.8%; Average loss: 0.2258\n",
            "Iteration: 3472; Percent complete: 86.8%; Average loss: 0.1760\n",
            "Iteration: 3473; Percent complete: 86.8%; Average loss: 0.2055\n",
            "Iteration: 3474; Percent complete: 86.9%; Average loss: 0.2308\n",
            "Iteration: 3475; Percent complete: 86.9%; Average loss: 0.2243\n",
            "Iteration: 3476; Percent complete: 86.9%; Average loss: 0.1981\n",
            "Iteration: 3477; Percent complete: 86.9%; Average loss: 0.2169\n",
            "Iteration: 3478; Percent complete: 87.0%; Average loss: 0.1980\n",
            "Iteration: 3479; Percent complete: 87.0%; Average loss: 0.2145\n",
            "Iteration: 3480; Percent complete: 87.0%; Average loss: 0.2109\n",
            "Iteration: 3481; Percent complete: 87.0%; Average loss: 0.1864\n",
            "Iteration: 3482; Percent complete: 87.1%; Average loss: 0.2009\n",
            "Iteration: 3483; Percent complete: 87.1%; Average loss: 0.1854\n",
            "Iteration: 3484; Percent complete: 87.1%; Average loss: 0.1959\n",
            "Iteration: 3485; Percent complete: 87.1%; Average loss: 0.2262\n",
            "Iteration: 3486; Percent complete: 87.2%; Average loss: 0.2089\n",
            "Iteration: 3487; Percent complete: 87.2%; Average loss: 0.2327\n",
            "Iteration: 3488; Percent complete: 87.2%; Average loss: 0.2570\n",
            "Iteration: 3489; Percent complete: 87.2%; Average loss: 0.2245\n",
            "Iteration: 3490; Percent complete: 87.2%; Average loss: 0.1902\n",
            "Iteration: 3491; Percent complete: 87.3%; Average loss: 0.2159\n",
            "Iteration: 3492; Percent complete: 87.3%; Average loss: 0.2109\n",
            "Iteration: 3493; Percent complete: 87.3%; Average loss: 0.2240\n",
            "Iteration: 3494; Percent complete: 87.4%; Average loss: 0.1969\n",
            "Iteration: 3495; Percent complete: 87.4%; Average loss: 0.2140\n",
            "Iteration: 3496; Percent complete: 87.4%; Average loss: 0.1925\n",
            "Iteration: 3497; Percent complete: 87.4%; Average loss: 0.2244\n",
            "Iteration: 3498; Percent complete: 87.5%; Average loss: 0.1929\n",
            "Iteration: 3499; Percent complete: 87.5%; Average loss: 0.1984\n",
            "Iteration: 3500; Percent complete: 87.5%; Average loss: 0.2104\n",
            "Iteration: 3501; Percent complete: 87.5%; Average loss: 0.2461\n",
            "Iteration: 3502; Percent complete: 87.5%; Average loss: 0.2148\n",
            "Iteration: 3503; Percent complete: 87.6%; Average loss: 0.2459\n",
            "Iteration: 3504; Percent complete: 87.6%; Average loss: 0.2536\n",
            "Iteration: 3505; Percent complete: 87.6%; Average loss: 0.2335\n",
            "Iteration: 3506; Percent complete: 87.6%; Average loss: 0.1953\n",
            "Iteration: 3507; Percent complete: 87.7%; Average loss: 0.2174\n",
            "Iteration: 3508; Percent complete: 87.7%; Average loss: 0.1787\n",
            "Iteration: 3509; Percent complete: 87.7%; Average loss: 0.2348\n",
            "Iteration: 3510; Percent complete: 87.8%; Average loss: 0.2003\n",
            "Iteration: 3511; Percent complete: 87.8%; Average loss: 0.1843\n",
            "Iteration: 3512; Percent complete: 87.8%; Average loss: 0.2037\n",
            "Iteration: 3513; Percent complete: 87.8%; Average loss: 0.1981\n",
            "Iteration: 3514; Percent complete: 87.8%; Average loss: 0.1811\n",
            "Iteration: 3515; Percent complete: 87.9%; Average loss: 0.2521\n",
            "Iteration: 3516; Percent complete: 87.9%; Average loss: 0.2430\n",
            "Iteration: 3517; Percent complete: 87.9%; Average loss: 0.2094\n",
            "Iteration: 3518; Percent complete: 87.9%; Average loss: 0.2016\n",
            "Iteration: 3519; Percent complete: 88.0%; Average loss: 0.2372\n",
            "Iteration: 3520; Percent complete: 88.0%; Average loss: 0.2265\n",
            "Iteration: 3521; Percent complete: 88.0%; Average loss: 0.1791\n",
            "Iteration: 3522; Percent complete: 88.0%; Average loss: 0.2113\n",
            "Iteration: 3523; Percent complete: 88.1%; Average loss: 0.2116\n",
            "Iteration: 3524; Percent complete: 88.1%; Average loss: 0.2173\n",
            "Iteration: 3525; Percent complete: 88.1%; Average loss: 0.2471\n",
            "Iteration: 3526; Percent complete: 88.1%; Average loss: 0.1760\n",
            "Iteration: 3527; Percent complete: 88.2%; Average loss: 0.1532\n",
            "Iteration: 3528; Percent complete: 88.2%; Average loss: 0.1961\n",
            "Iteration: 3529; Percent complete: 88.2%; Average loss: 0.2365\n",
            "Iteration: 3530; Percent complete: 88.2%; Average loss: 0.1945\n",
            "Iteration: 3531; Percent complete: 88.3%; Average loss: 0.1751\n",
            "Iteration: 3532; Percent complete: 88.3%; Average loss: 0.1959\n",
            "Iteration: 3533; Percent complete: 88.3%; Average loss: 0.1882\n",
            "Iteration: 3534; Percent complete: 88.3%; Average loss: 0.2180\n",
            "Iteration: 3535; Percent complete: 88.4%; Average loss: 0.2416\n",
            "Iteration: 3536; Percent complete: 88.4%; Average loss: 0.2479\n",
            "Iteration: 3537; Percent complete: 88.4%; Average loss: 0.2003\n",
            "Iteration: 3538; Percent complete: 88.4%; Average loss: 0.2056\n",
            "Iteration: 3539; Percent complete: 88.5%; Average loss: 0.2235\n",
            "Iteration: 3540; Percent complete: 88.5%; Average loss: 0.2359\n",
            "Iteration: 3541; Percent complete: 88.5%; Average loss: 0.2044\n",
            "Iteration: 3542; Percent complete: 88.5%; Average loss: 0.2304\n",
            "Iteration: 3543; Percent complete: 88.6%; Average loss: 0.1985\n",
            "Iteration: 3544; Percent complete: 88.6%; Average loss: 0.2024\n",
            "Iteration: 3545; Percent complete: 88.6%; Average loss: 0.1788\n",
            "Iteration: 3546; Percent complete: 88.6%; Average loss: 0.2519\n",
            "Iteration: 3547; Percent complete: 88.7%; Average loss: 0.2236\n",
            "Iteration: 3548; Percent complete: 88.7%; Average loss: 0.1634\n",
            "Iteration: 3549; Percent complete: 88.7%; Average loss: 0.2431\n",
            "Iteration: 3550; Percent complete: 88.8%; Average loss: 0.2073\n",
            "Iteration: 3551; Percent complete: 88.8%; Average loss: 0.1804\n",
            "Iteration: 3552; Percent complete: 88.8%; Average loss: 0.2048\n",
            "Iteration: 3553; Percent complete: 88.8%; Average loss: 0.2399\n",
            "Iteration: 3554; Percent complete: 88.8%; Average loss: 0.1980\n",
            "Iteration: 3555; Percent complete: 88.9%; Average loss: 0.2149\n",
            "Iteration: 3556; Percent complete: 88.9%; Average loss: 0.1903\n",
            "Iteration: 3557; Percent complete: 88.9%; Average loss: 0.1780\n",
            "Iteration: 3558; Percent complete: 88.9%; Average loss: 0.2492\n",
            "Iteration: 3559; Percent complete: 89.0%; Average loss: 0.2277\n",
            "Iteration: 3560; Percent complete: 89.0%; Average loss: 0.2098\n",
            "Iteration: 3561; Percent complete: 89.0%; Average loss: 0.2039\n",
            "Iteration: 3562; Percent complete: 89.0%; Average loss: 0.2259\n",
            "Iteration: 3563; Percent complete: 89.1%; Average loss: 0.2042\n",
            "Iteration: 3564; Percent complete: 89.1%; Average loss: 0.1942\n",
            "Iteration: 3565; Percent complete: 89.1%; Average loss: 0.2090\n",
            "Iteration: 3566; Percent complete: 89.1%; Average loss: 0.2025\n",
            "Iteration: 3567; Percent complete: 89.2%; Average loss: 0.1979\n",
            "Iteration: 3568; Percent complete: 89.2%; Average loss: 0.1841\n",
            "Iteration: 3569; Percent complete: 89.2%; Average loss: 0.1798\n",
            "Iteration: 3570; Percent complete: 89.2%; Average loss: 0.2049\n",
            "Iteration: 3571; Percent complete: 89.3%; Average loss: 0.2179\n",
            "Iteration: 3572; Percent complete: 89.3%; Average loss: 0.2379\n",
            "Iteration: 3573; Percent complete: 89.3%; Average loss: 0.1851\n",
            "Iteration: 3574; Percent complete: 89.3%; Average loss: 0.1936\n",
            "Iteration: 3575; Percent complete: 89.4%; Average loss: 0.2305\n",
            "Iteration: 3576; Percent complete: 89.4%; Average loss: 0.2139\n",
            "Iteration: 3577; Percent complete: 89.4%; Average loss: 0.1836\n",
            "Iteration: 3578; Percent complete: 89.5%; Average loss: 0.1786\n",
            "Iteration: 3579; Percent complete: 89.5%; Average loss: 0.2002\n",
            "Iteration: 3580; Percent complete: 89.5%; Average loss: 0.1991\n",
            "Iteration: 3581; Percent complete: 89.5%; Average loss: 0.1928\n",
            "Iteration: 3582; Percent complete: 89.5%; Average loss: 0.1748\n",
            "Iteration: 3583; Percent complete: 89.6%; Average loss: 0.1842\n",
            "Iteration: 3584; Percent complete: 89.6%; Average loss: 0.1930\n",
            "Iteration: 3585; Percent complete: 89.6%; Average loss: 0.2012\n",
            "Iteration: 3586; Percent complete: 89.6%; Average loss: 0.1923\n",
            "Iteration: 3587; Percent complete: 89.7%; Average loss: 0.2012\n",
            "Iteration: 3588; Percent complete: 89.7%; Average loss: 0.1712\n",
            "Iteration: 3589; Percent complete: 89.7%; Average loss: 0.1742\n",
            "Iteration: 3590; Percent complete: 89.8%; Average loss: 0.1585\n",
            "Iteration: 3591; Percent complete: 89.8%; Average loss: 0.2058\n",
            "Iteration: 3592; Percent complete: 89.8%; Average loss: 0.2161\n",
            "Iteration: 3593; Percent complete: 89.8%; Average loss: 0.2173\n",
            "Iteration: 3594; Percent complete: 89.8%; Average loss: 0.1935\n",
            "Iteration: 3595; Percent complete: 89.9%; Average loss: 0.1966\n",
            "Iteration: 3596; Percent complete: 89.9%; Average loss: 0.1721\n",
            "Iteration: 3597; Percent complete: 89.9%; Average loss: 0.1965\n",
            "Iteration: 3598; Percent complete: 90.0%; Average loss: 0.1887\n",
            "Iteration: 3599; Percent complete: 90.0%; Average loss: 0.1901\n",
            "Iteration: 3600; Percent complete: 90.0%; Average loss: 0.2073\n",
            "Iteration: 3601; Percent complete: 90.0%; Average loss: 0.1902\n",
            "Iteration: 3602; Percent complete: 90.0%; Average loss: 0.1916\n",
            "Iteration: 3603; Percent complete: 90.1%; Average loss: 0.1814\n",
            "Iteration: 3604; Percent complete: 90.1%; Average loss: 0.2128\n",
            "Iteration: 3605; Percent complete: 90.1%; Average loss: 0.1810\n",
            "Iteration: 3606; Percent complete: 90.1%; Average loss: 0.2140\n",
            "Iteration: 3607; Percent complete: 90.2%; Average loss: 0.1749\n",
            "Iteration: 3608; Percent complete: 90.2%; Average loss: 0.2185\n",
            "Iteration: 3609; Percent complete: 90.2%; Average loss: 0.1936\n",
            "Iteration: 3610; Percent complete: 90.2%; Average loss: 0.2164\n",
            "Iteration: 3611; Percent complete: 90.3%; Average loss: 0.2073\n",
            "Iteration: 3612; Percent complete: 90.3%; Average loss: 0.3004\n",
            "Iteration: 3613; Percent complete: 90.3%; Average loss: 0.2149\n",
            "Iteration: 3614; Percent complete: 90.3%; Average loss: 0.1851\n",
            "Iteration: 3615; Percent complete: 90.4%; Average loss: 0.1633\n",
            "Iteration: 3616; Percent complete: 90.4%; Average loss: 0.2210\n",
            "Iteration: 3617; Percent complete: 90.4%; Average loss: 0.1720\n",
            "Iteration: 3618; Percent complete: 90.5%; Average loss: 0.2030\n",
            "Iteration: 3619; Percent complete: 90.5%; Average loss: 0.2014\n",
            "Iteration: 3620; Percent complete: 90.5%; Average loss: 0.1801\n",
            "Iteration: 3621; Percent complete: 90.5%; Average loss: 0.1935\n",
            "Iteration: 3622; Percent complete: 90.5%; Average loss: 0.1764\n",
            "Iteration: 3623; Percent complete: 90.6%; Average loss: 0.1703\n",
            "Iteration: 3624; Percent complete: 90.6%; Average loss: 0.2300\n",
            "Iteration: 3625; Percent complete: 90.6%; Average loss: 0.2091\n",
            "Iteration: 3626; Percent complete: 90.6%; Average loss: 0.1997\n",
            "Iteration: 3627; Percent complete: 90.7%; Average loss: 0.1719\n",
            "Iteration: 3628; Percent complete: 90.7%; Average loss: 0.2520\n",
            "Iteration: 3629; Percent complete: 90.7%; Average loss: 0.1748\n",
            "Iteration: 3630; Percent complete: 90.8%; Average loss: 0.1918\n",
            "Iteration: 3631; Percent complete: 90.8%; Average loss: 0.1997\n",
            "Iteration: 3632; Percent complete: 90.8%; Average loss: 0.1656\n",
            "Iteration: 3633; Percent complete: 90.8%; Average loss: 0.1975\n",
            "Iteration: 3634; Percent complete: 90.8%; Average loss: 0.2228\n",
            "Iteration: 3635; Percent complete: 90.9%; Average loss: 0.1882\n",
            "Iteration: 3636; Percent complete: 90.9%; Average loss: 0.2139\n",
            "Iteration: 3637; Percent complete: 90.9%; Average loss: 0.1798\n",
            "Iteration: 3638; Percent complete: 91.0%; Average loss: 0.1930\n",
            "Iteration: 3639; Percent complete: 91.0%; Average loss: 0.1824\n",
            "Iteration: 3640; Percent complete: 91.0%; Average loss: 0.1751\n",
            "Iteration: 3641; Percent complete: 91.0%; Average loss: 0.1760\n",
            "Iteration: 3642; Percent complete: 91.0%; Average loss: 0.1860\n",
            "Iteration: 3643; Percent complete: 91.1%; Average loss: 0.1685\n",
            "Iteration: 3644; Percent complete: 91.1%; Average loss: 0.1745\n",
            "Iteration: 3645; Percent complete: 91.1%; Average loss: 0.2285\n",
            "Iteration: 3646; Percent complete: 91.1%; Average loss: 0.1891\n",
            "Iteration: 3647; Percent complete: 91.2%; Average loss: 0.2024\n",
            "Iteration: 3648; Percent complete: 91.2%; Average loss: 0.1835\n",
            "Iteration: 3649; Percent complete: 91.2%; Average loss: 0.2335\n",
            "Iteration: 3650; Percent complete: 91.2%; Average loss: 0.1632\n",
            "Iteration: 3651; Percent complete: 91.3%; Average loss: 0.2089\n",
            "Iteration: 3652; Percent complete: 91.3%; Average loss: 0.1676\n",
            "Iteration: 3653; Percent complete: 91.3%; Average loss: 0.1866\n",
            "Iteration: 3654; Percent complete: 91.3%; Average loss: 0.1878\n",
            "Iteration: 3655; Percent complete: 91.4%; Average loss: 0.1988\n",
            "Iteration: 3656; Percent complete: 91.4%; Average loss: 0.2110\n",
            "Iteration: 3657; Percent complete: 91.4%; Average loss: 0.2219\n",
            "Iteration: 3658; Percent complete: 91.5%; Average loss: 0.1471\n",
            "Iteration: 3659; Percent complete: 91.5%; Average loss: 0.1883\n",
            "Iteration: 3660; Percent complete: 91.5%; Average loss: 0.1647\n",
            "Iteration: 3661; Percent complete: 91.5%; Average loss: 0.1600\n",
            "Iteration: 3662; Percent complete: 91.5%; Average loss: 0.2191\n",
            "Iteration: 3663; Percent complete: 91.6%; Average loss: 0.1851\n",
            "Iteration: 3664; Percent complete: 91.6%; Average loss: 0.1871\n",
            "Iteration: 3665; Percent complete: 91.6%; Average loss: 0.1849\n",
            "Iteration: 3666; Percent complete: 91.6%; Average loss: 0.1853\n",
            "Iteration: 3667; Percent complete: 91.7%; Average loss: 0.2139\n",
            "Iteration: 3668; Percent complete: 91.7%; Average loss: 0.2088\n",
            "Iteration: 3669; Percent complete: 91.7%; Average loss: 0.1703\n",
            "Iteration: 3670; Percent complete: 91.8%; Average loss: 0.1935\n",
            "Iteration: 3671; Percent complete: 91.8%; Average loss: 0.1880\n",
            "Iteration: 3672; Percent complete: 91.8%; Average loss: 0.1713\n",
            "Iteration: 3673; Percent complete: 91.8%; Average loss: 0.1747\n",
            "Iteration: 3674; Percent complete: 91.8%; Average loss: 0.2137\n",
            "Iteration: 3675; Percent complete: 91.9%; Average loss: 0.1693\n",
            "Iteration: 3676; Percent complete: 91.9%; Average loss: 0.1811\n",
            "Iteration: 3677; Percent complete: 91.9%; Average loss: 0.1691\n",
            "Iteration: 3678; Percent complete: 92.0%; Average loss: 0.1662\n",
            "Iteration: 3679; Percent complete: 92.0%; Average loss: 0.1941\n",
            "Iteration: 3680; Percent complete: 92.0%; Average loss: 0.1690\n",
            "Iteration: 3681; Percent complete: 92.0%; Average loss: 0.1666\n",
            "Iteration: 3682; Percent complete: 92.0%; Average loss: 0.1881\n",
            "Iteration: 3683; Percent complete: 92.1%; Average loss: 0.1706\n",
            "Iteration: 3684; Percent complete: 92.1%; Average loss: 0.1891\n",
            "Iteration: 3685; Percent complete: 92.1%; Average loss: 0.1964\n",
            "Iteration: 3686; Percent complete: 92.2%; Average loss: 0.1836\n",
            "Iteration: 3687; Percent complete: 92.2%; Average loss: 0.2217\n",
            "Iteration: 3688; Percent complete: 92.2%; Average loss: 0.1759\n",
            "Iteration: 3689; Percent complete: 92.2%; Average loss: 0.1838\n",
            "Iteration: 3690; Percent complete: 92.2%; Average loss: 0.1719\n",
            "Iteration: 3691; Percent complete: 92.3%; Average loss: 0.1736\n",
            "Iteration: 3692; Percent complete: 92.3%; Average loss: 0.1699\n",
            "Iteration: 3693; Percent complete: 92.3%; Average loss: 0.1448\n",
            "Iteration: 3694; Percent complete: 92.3%; Average loss: 0.1792\n",
            "Iteration: 3695; Percent complete: 92.4%; Average loss: 0.1877\n",
            "Iteration: 3696; Percent complete: 92.4%; Average loss: 0.1836\n",
            "Iteration: 3697; Percent complete: 92.4%; Average loss: 0.1707\n",
            "Iteration: 3698; Percent complete: 92.5%; Average loss: 0.1513\n",
            "Iteration: 3699; Percent complete: 92.5%; Average loss: 0.1905\n",
            "Iteration: 3700; Percent complete: 92.5%; Average loss: 0.1898\n",
            "Iteration: 3701; Percent complete: 92.5%; Average loss: 0.1705\n",
            "Iteration: 3702; Percent complete: 92.5%; Average loss: 0.1869\n",
            "Iteration: 3703; Percent complete: 92.6%; Average loss: 0.1619\n",
            "Iteration: 3704; Percent complete: 92.6%; Average loss: 0.1634\n",
            "Iteration: 3705; Percent complete: 92.6%; Average loss: 0.2084\n",
            "Iteration: 3706; Percent complete: 92.7%; Average loss: 0.1807\n",
            "Iteration: 3707; Percent complete: 92.7%; Average loss: 0.2182\n",
            "Iteration: 3708; Percent complete: 92.7%; Average loss: 0.1958\n",
            "Iteration: 3709; Percent complete: 92.7%; Average loss: 0.1534\n",
            "Iteration: 3710; Percent complete: 92.8%; Average loss: 0.1447\n",
            "Iteration: 3711; Percent complete: 92.8%; Average loss: 0.1797\n",
            "Iteration: 3712; Percent complete: 92.8%; Average loss: 0.1535\n",
            "Iteration: 3713; Percent complete: 92.8%; Average loss: 0.1830\n",
            "Iteration: 3714; Percent complete: 92.8%; Average loss: 0.1679\n",
            "Iteration: 3715; Percent complete: 92.9%; Average loss: 0.1548\n",
            "Iteration: 3716; Percent complete: 92.9%; Average loss: 0.1618\n",
            "Iteration: 3717; Percent complete: 92.9%; Average loss: 0.2086\n",
            "Iteration: 3718; Percent complete: 93.0%; Average loss: 0.1983\n",
            "Iteration: 3719; Percent complete: 93.0%; Average loss: 0.1772\n",
            "Iteration: 3720; Percent complete: 93.0%; Average loss: 0.1644\n",
            "Iteration: 3721; Percent complete: 93.0%; Average loss: 0.1598\n",
            "Iteration: 3722; Percent complete: 93.0%; Average loss: 0.1672\n",
            "Iteration: 3723; Percent complete: 93.1%; Average loss: 0.1422\n",
            "Iteration: 3724; Percent complete: 93.1%; Average loss: 0.1806\n",
            "Iteration: 3725; Percent complete: 93.1%; Average loss: 0.1558\n",
            "Iteration: 3726; Percent complete: 93.2%; Average loss: 0.1835\n",
            "Iteration: 3727; Percent complete: 93.2%; Average loss: 0.1628\n",
            "Iteration: 3728; Percent complete: 93.2%; Average loss: 0.1797\n",
            "Iteration: 3729; Percent complete: 93.2%; Average loss: 0.1802\n",
            "Iteration: 3730; Percent complete: 93.2%; Average loss: 0.1752\n",
            "Iteration: 3731; Percent complete: 93.3%; Average loss: 0.1585\n",
            "Iteration: 3732; Percent complete: 93.3%; Average loss: 0.1768\n",
            "Iteration: 3733; Percent complete: 93.3%; Average loss: 0.1640\n",
            "Iteration: 3734; Percent complete: 93.3%; Average loss: 0.1465\n",
            "Iteration: 3735; Percent complete: 93.4%; Average loss: 0.1549\n",
            "Iteration: 3736; Percent complete: 93.4%; Average loss: 0.1641\n",
            "Iteration: 3737; Percent complete: 93.4%; Average loss: 0.1805\n",
            "Iteration: 3738; Percent complete: 93.5%; Average loss: 0.1876\n",
            "Iteration: 3739; Percent complete: 93.5%; Average loss: 0.1720\n",
            "Iteration: 3740; Percent complete: 93.5%; Average loss: 0.1439\n",
            "Iteration: 3741; Percent complete: 93.5%; Average loss: 0.1726\n",
            "Iteration: 3742; Percent complete: 93.5%; Average loss: 0.2302\n",
            "Iteration: 3743; Percent complete: 93.6%; Average loss: 0.1707\n",
            "Iteration: 3744; Percent complete: 93.6%; Average loss: 0.1821\n",
            "Iteration: 3745; Percent complete: 93.6%; Average loss: 0.1364\n",
            "Iteration: 3746; Percent complete: 93.7%; Average loss: 0.1666\n",
            "Iteration: 3747; Percent complete: 93.7%; Average loss: 0.1574\n",
            "Iteration: 3748; Percent complete: 93.7%; Average loss: 0.1665\n",
            "Iteration: 3749; Percent complete: 93.7%; Average loss: 0.1636\n",
            "Iteration: 3750; Percent complete: 93.8%; Average loss: 0.1991\n",
            "Iteration: 3751; Percent complete: 93.8%; Average loss: 0.1525\n",
            "Iteration: 3752; Percent complete: 93.8%; Average loss: 0.1664\n",
            "Iteration: 3753; Percent complete: 93.8%; Average loss: 0.1867\n",
            "Iteration: 3754; Percent complete: 93.8%; Average loss: 0.1575\n",
            "Iteration: 3755; Percent complete: 93.9%; Average loss: 0.1672\n",
            "Iteration: 3756; Percent complete: 93.9%; Average loss: 0.1826\n",
            "Iteration: 3757; Percent complete: 93.9%; Average loss: 0.1549\n",
            "Iteration: 3758; Percent complete: 94.0%; Average loss: 0.1636\n",
            "Iteration: 3759; Percent complete: 94.0%; Average loss: 0.1930\n",
            "Iteration: 3760; Percent complete: 94.0%; Average loss: 0.1762\n",
            "Iteration: 3761; Percent complete: 94.0%; Average loss: 0.1775\n",
            "Iteration: 3762; Percent complete: 94.0%; Average loss: 0.1589\n",
            "Iteration: 3763; Percent complete: 94.1%; Average loss: 0.1570\n",
            "Iteration: 3764; Percent complete: 94.1%; Average loss: 0.1879\n",
            "Iteration: 3765; Percent complete: 94.1%; Average loss: 0.1698\n",
            "Iteration: 3766; Percent complete: 94.2%; Average loss: 0.1766\n",
            "Iteration: 3767; Percent complete: 94.2%; Average loss: 0.1334\n",
            "Iteration: 3768; Percent complete: 94.2%; Average loss: 0.1870\n",
            "Iteration: 3769; Percent complete: 94.2%; Average loss: 0.1457\n",
            "Iteration: 3770; Percent complete: 94.2%; Average loss: 0.1504\n",
            "Iteration: 3771; Percent complete: 94.3%; Average loss: 0.1723\n",
            "Iteration: 3772; Percent complete: 94.3%; Average loss: 0.1609\n",
            "Iteration: 3773; Percent complete: 94.3%; Average loss: 0.1623\n",
            "Iteration: 3774; Percent complete: 94.3%; Average loss: 0.1631\n",
            "Iteration: 3775; Percent complete: 94.4%; Average loss: 0.1654\n",
            "Iteration: 3776; Percent complete: 94.4%; Average loss: 0.1622\n",
            "Iteration: 3777; Percent complete: 94.4%; Average loss: 0.1558\n",
            "Iteration: 3778; Percent complete: 94.5%; Average loss: 0.1771\n",
            "Iteration: 3779; Percent complete: 94.5%; Average loss: 0.1472\n",
            "Iteration: 3780; Percent complete: 94.5%; Average loss: 0.1232\n",
            "Iteration: 3781; Percent complete: 94.5%; Average loss: 0.1911\n",
            "Iteration: 3782; Percent complete: 94.5%; Average loss: 0.1715\n",
            "Iteration: 3783; Percent complete: 94.6%; Average loss: 0.1449\n",
            "Iteration: 3784; Percent complete: 94.6%; Average loss: 0.1688\n",
            "Iteration: 3785; Percent complete: 94.6%; Average loss: 0.1563\n",
            "Iteration: 3786; Percent complete: 94.7%; Average loss: 0.1600\n",
            "Iteration: 3787; Percent complete: 94.7%; Average loss: 0.1403\n",
            "Iteration: 3788; Percent complete: 94.7%; Average loss: 0.1633\n",
            "Iteration: 3789; Percent complete: 94.7%; Average loss: 0.1415\n",
            "Iteration: 3790; Percent complete: 94.8%; Average loss: 0.1533\n",
            "Iteration: 3791; Percent complete: 94.8%; Average loss: 0.1487\n",
            "Iteration: 3792; Percent complete: 94.8%; Average loss: 0.1414\n",
            "Iteration: 3793; Percent complete: 94.8%; Average loss: 0.1595\n",
            "Iteration: 3794; Percent complete: 94.8%; Average loss: 0.1492\n",
            "Iteration: 3795; Percent complete: 94.9%; Average loss: 0.1613\n",
            "Iteration: 3796; Percent complete: 94.9%; Average loss: 0.1669\n",
            "Iteration: 3797; Percent complete: 94.9%; Average loss: 0.1278\n",
            "Iteration: 3798; Percent complete: 95.0%; Average loss: 0.1540\n",
            "Iteration: 3799; Percent complete: 95.0%; Average loss: 0.1184\n",
            "Iteration: 3800; Percent complete: 95.0%; Average loss: 0.1579\n",
            "Iteration: 3801; Percent complete: 95.0%; Average loss: 0.1431\n",
            "Iteration: 3802; Percent complete: 95.0%; Average loss: 0.1682\n",
            "Iteration: 3803; Percent complete: 95.1%; Average loss: 0.1289\n",
            "Iteration: 3804; Percent complete: 95.1%; Average loss: 0.1792\n",
            "Iteration: 3805; Percent complete: 95.1%; Average loss: 0.1425\n",
            "Iteration: 3806; Percent complete: 95.2%; Average loss: 0.1628\n",
            "Iteration: 3807; Percent complete: 95.2%; Average loss: 0.1742\n",
            "Iteration: 3808; Percent complete: 95.2%; Average loss: 0.1270\n",
            "Iteration: 3809; Percent complete: 95.2%; Average loss: 0.1594\n",
            "Iteration: 3810; Percent complete: 95.2%; Average loss: 0.1461\n",
            "Iteration: 3811; Percent complete: 95.3%; Average loss: 0.1456\n",
            "Iteration: 3812; Percent complete: 95.3%; Average loss: 0.1107\n",
            "Iteration: 3813; Percent complete: 95.3%; Average loss: 0.1489\n",
            "Iteration: 3814; Percent complete: 95.3%; Average loss: 0.1313\n",
            "Iteration: 3815; Percent complete: 95.4%; Average loss: 0.1554\n",
            "Iteration: 3816; Percent complete: 95.4%; Average loss: 0.1583\n",
            "Iteration: 3817; Percent complete: 95.4%; Average loss: 0.1440\n",
            "Iteration: 3818; Percent complete: 95.5%; Average loss: 0.1493\n",
            "Iteration: 3819; Percent complete: 95.5%; Average loss: 0.1446\n",
            "Iteration: 3820; Percent complete: 95.5%; Average loss: 0.1559\n",
            "Iteration: 3821; Percent complete: 95.5%; Average loss: 0.1531\n",
            "Iteration: 3822; Percent complete: 95.5%; Average loss: 0.1341\n",
            "Iteration: 3823; Percent complete: 95.6%; Average loss: 0.1329\n",
            "Iteration: 3824; Percent complete: 95.6%; Average loss: 0.1491\n",
            "Iteration: 3825; Percent complete: 95.6%; Average loss: 0.1482\n",
            "Iteration: 3826; Percent complete: 95.7%; Average loss: 0.1669\n",
            "Iteration: 3827; Percent complete: 95.7%; Average loss: 0.1335\n",
            "Iteration: 3828; Percent complete: 95.7%; Average loss: 0.1555\n",
            "Iteration: 3829; Percent complete: 95.7%; Average loss: 0.1550\n",
            "Iteration: 3830; Percent complete: 95.8%; Average loss: 0.1517\n",
            "Iteration: 3831; Percent complete: 95.8%; Average loss: 0.1398\n",
            "Iteration: 3832; Percent complete: 95.8%; Average loss: 0.1491\n",
            "Iteration: 3833; Percent complete: 95.8%; Average loss: 0.1235\n",
            "Iteration: 3834; Percent complete: 95.9%; Average loss: 0.1684\n",
            "Iteration: 3835; Percent complete: 95.9%; Average loss: 0.1487\n",
            "Iteration: 3836; Percent complete: 95.9%; Average loss: 0.1320\n",
            "Iteration: 3837; Percent complete: 95.9%; Average loss: 0.1460\n",
            "Iteration: 3838; Percent complete: 96.0%; Average loss: 0.1628\n",
            "Iteration: 3839; Percent complete: 96.0%; Average loss: 0.1397\n",
            "Iteration: 3840; Percent complete: 96.0%; Average loss: 0.1254\n",
            "Iteration: 3841; Percent complete: 96.0%; Average loss: 0.1687\n",
            "Iteration: 3842; Percent complete: 96.0%; Average loss: 0.1344\n",
            "Iteration: 3843; Percent complete: 96.1%; Average loss: 0.1274\n",
            "Iteration: 3844; Percent complete: 96.1%; Average loss: 0.1488\n",
            "Iteration: 3845; Percent complete: 96.1%; Average loss: 0.1413\n",
            "Iteration: 3846; Percent complete: 96.2%; Average loss: 0.1847\n",
            "Iteration: 3847; Percent complete: 96.2%; Average loss: 0.1868\n",
            "Iteration: 3848; Percent complete: 96.2%; Average loss: 0.1839\n",
            "Iteration: 3849; Percent complete: 96.2%; Average loss: 0.1621\n",
            "Iteration: 3850; Percent complete: 96.2%; Average loss: 0.1442\n",
            "Iteration: 3851; Percent complete: 96.3%; Average loss: 0.1299\n",
            "Iteration: 3852; Percent complete: 96.3%; Average loss: 0.1417\n",
            "Iteration: 3853; Percent complete: 96.3%; Average loss: 0.1555\n",
            "Iteration: 3854; Percent complete: 96.4%; Average loss: 0.1375\n",
            "Iteration: 3855; Percent complete: 96.4%; Average loss: 0.1388\n",
            "Iteration: 3856; Percent complete: 96.4%; Average loss: 0.1497\n",
            "Iteration: 3857; Percent complete: 96.4%; Average loss: 0.1304\n",
            "Iteration: 3858; Percent complete: 96.5%; Average loss: 0.1476\n",
            "Iteration: 3859; Percent complete: 96.5%; Average loss: 0.1445\n",
            "Iteration: 3860; Percent complete: 96.5%; Average loss: 0.1653\n",
            "Iteration: 3861; Percent complete: 96.5%; Average loss: 0.1531\n",
            "Iteration: 3862; Percent complete: 96.5%; Average loss: 0.1262\n",
            "Iteration: 3863; Percent complete: 96.6%; Average loss: 0.1502\n",
            "Iteration: 3864; Percent complete: 96.6%; Average loss: 0.1483\n",
            "Iteration: 3865; Percent complete: 96.6%; Average loss: 0.1130\n",
            "Iteration: 3866; Percent complete: 96.7%; Average loss: 0.1637\n",
            "Iteration: 3867; Percent complete: 96.7%; Average loss: 0.1462\n",
            "Iteration: 3868; Percent complete: 96.7%; Average loss: 0.1476\n",
            "Iteration: 3869; Percent complete: 96.7%; Average loss: 0.1432\n",
            "Iteration: 3870; Percent complete: 96.8%; Average loss: 0.1335\n",
            "Iteration: 3871; Percent complete: 96.8%; Average loss: 0.1502\n",
            "Iteration: 3872; Percent complete: 96.8%; Average loss: 0.1156\n",
            "Iteration: 3873; Percent complete: 96.8%; Average loss: 0.1321\n",
            "Iteration: 3874; Percent complete: 96.9%; Average loss: 0.1467\n",
            "Iteration: 3875; Percent complete: 96.9%; Average loss: 0.1443\n",
            "Iteration: 3876; Percent complete: 96.9%; Average loss: 0.1415\n",
            "Iteration: 3877; Percent complete: 96.9%; Average loss: 0.1329\n",
            "Iteration: 3878; Percent complete: 97.0%; Average loss: 0.1454\n",
            "Iteration: 3879; Percent complete: 97.0%; Average loss: 0.1539\n",
            "Iteration: 3880; Percent complete: 97.0%; Average loss: 0.1717\n",
            "Iteration: 3881; Percent complete: 97.0%; Average loss: 0.1775\n",
            "Iteration: 3882; Percent complete: 97.0%; Average loss: 0.1486\n",
            "Iteration: 3883; Percent complete: 97.1%; Average loss: 0.1371\n",
            "Iteration: 3884; Percent complete: 97.1%; Average loss: 0.1353\n",
            "Iteration: 3885; Percent complete: 97.1%; Average loss: 0.1646\n",
            "Iteration: 3886; Percent complete: 97.2%; Average loss: 0.1310\n",
            "Iteration: 3887; Percent complete: 97.2%; Average loss: 0.1255\n",
            "Iteration: 3888; Percent complete: 97.2%; Average loss: 0.1541\n",
            "Iteration: 3889; Percent complete: 97.2%; Average loss: 0.1380\n",
            "Iteration: 3890; Percent complete: 97.2%; Average loss: 0.1569\n",
            "Iteration: 3891; Percent complete: 97.3%; Average loss: 0.1523\n",
            "Iteration: 3892; Percent complete: 97.3%; Average loss: 0.1258\n",
            "Iteration: 3893; Percent complete: 97.3%; Average loss: 0.1371\n",
            "Iteration: 3894; Percent complete: 97.4%; Average loss: 0.1508\n",
            "Iteration: 3895; Percent complete: 97.4%; Average loss: 0.1426\n",
            "Iteration: 3896; Percent complete: 97.4%; Average loss: 0.1485\n",
            "Iteration: 3897; Percent complete: 97.4%; Average loss: 0.1285\n",
            "Iteration: 3898; Percent complete: 97.5%; Average loss: 0.1269\n",
            "Iteration: 3899; Percent complete: 97.5%; Average loss: 0.1180\n",
            "Iteration: 3900; Percent complete: 97.5%; Average loss: 0.1355\n",
            "Iteration: 3901; Percent complete: 97.5%; Average loss: 0.1352\n",
            "Iteration: 3902; Percent complete: 97.5%; Average loss: 0.1242\n",
            "Iteration: 3903; Percent complete: 97.6%; Average loss: 0.1526\n",
            "Iteration: 3904; Percent complete: 97.6%; Average loss: 0.1374\n",
            "Iteration: 3905; Percent complete: 97.6%; Average loss: 0.1400\n",
            "Iteration: 3906; Percent complete: 97.7%; Average loss: 0.1763\n",
            "Iteration: 3907; Percent complete: 97.7%; Average loss: 0.1334\n",
            "Iteration: 3908; Percent complete: 97.7%; Average loss: 0.1321\n",
            "Iteration: 3909; Percent complete: 97.7%; Average loss: 0.1526\n",
            "Iteration: 3910; Percent complete: 97.8%; Average loss: 0.1586\n",
            "Iteration: 3911; Percent complete: 97.8%; Average loss: 0.1170\n",
            "Iteration: 3912; Percent complete: 97.8%; Average loss: 0.1359\n",
            "Iteration: 3913; Percent complete: 97.8%; Average loss: 0.1472\n",
            "Iteration: 3914; Percent complete: 97.9%; Average loss: 0.1249\n",
            "Iteration: 3915; Percent complete: 97.9%; Average loss: 0.1342\n",
            "Iteration: 3916; Percent complete: 97.9%; Average loss: 0.1506\n",
            "Iteration: 3917; Percent complete: 97.9%; Average loss: 0.1298\n",
            "Iteration: 3918; Percent complete: 98.0%; Average loss: 0.1369\n",
            "Iteration: 3919; Percent complete: 98.0%; Average loss: 0.1559\n",
            "Iteration: 3920; Percent complete: 98.0%; Average loss: 0.1284\n",
            "Iteration: 3921; Percent complete: 98.0%; Average loss: 0.1430\n",
            "Iteration: 3922; Percent complete: 98.0%; Average loss: 0.1475\n",
            "Iteration: 3923; Percent complete: 98.1%; Average loss: 0.1406\n",
            "Iteration: 3924; Percent complete: 98.1%; Average loss: 0.1669\n",
            "Iteration: 3925; Percent complete: 98.1%; Average loss: 0.1587\n",
            "Iteration: 3926; Percent complete: 98.2%; Average loss: 0.1274\n",
            "Iteration: 3927; Percent complete: 98.2%; Average loss: 0.1185\n",
            "Iteration: 3928; Percent complete: 98.2%; Average loss: 0.1333\n",
            "Iteration: 3929; Percent complete: 98.2%; Average loss: 0.1635\n",
            "Iteration: 3930; Percent complete: 98.2%; Average loss: 0.1359\n",
            "Iteration: 3931; Percent complete: 98.3%; Average loss: 0.1465\n",
            "Iteration: 3932; Percent complete: 98.3%; Average loss: 0.1105\n",
            "Iteration: 3933; Percent complete: 98.3%; Average loss: 0.1168\n",
            "Iteration: 3934; Percent complete: 98.4%; Average loss: 0.1339\n",
            "Iteration: 3935; Percent complete: 98.4%; Average loss: 0.1813\n",
            "Iteration: 3936; Percent complete: 98.4%; Average loss: 0.1366\n",
            "Iteration: 3937; Percent complete: 98.4%; Average loss: 0.1375\n",
            "Iteration: 3938; Percent complete: 98.5%; Average loss: 0.1474\n",
            "Iteration: 3939; Percent complete: 98.5%; Average loss: 0.1222\n",
            "Iteration: 3940; Percent complete: 98.5%; Average loss: 0.1342\n",
            "Iteration: 3941; Percent complete: 98.5%; Average loss: 0.1368\n",
            "Iteration: 3942; Percent complete: 98.6%; Average loss: 0.1288\n",
            "Iteration: 3943; Percent complete: 98.6%; Average loss: 0.1233\n",
            "Iteration: 3944; Percent complete: 98.6%; Average loss: 0.1544\n",
            "Iteration: 3945; Percent complete: 98.6%; Average loss: 0.1594\n",
            "Iteration: 3946; Percent complete: 98.7%; Average loss: 0.1164\n",
            "Iteration: 3947; Percent complete: 98.7%; Average loss: 0.1317\n",
            "Iteration: 3948; Percent complete: 98.7%; Average loss: 0.1240\n",
            "Iteration: 3949; Percent complete: 98.7%; Average loss: 0.1123\n",
            "Iteration: 3950; Percent complete: 98.8%; Average loss: 0.1316\n",
            "Iteration: 3951; Percent complete: 98.8%; Average loss: 0.1107\n",
            "Iteration: 3952; Percent complete: 98.8%; Average loss: 0.1357\n",
            "Iteration: 3953; Percent complete: 98.8%; Average loss: 0.1390\n",
            "Iteration: 3954; Percent complete: 98.9%; Average loss: 0.1278\n",
            "Iteration: 3955; Percent complete: 98.9%; Average loss: 0.1389\n",
            "Iteration: 3956; Percent complete: 98.9%; Average loss: 0.1040\n",
            "Iteration: 3957; Percent complete: 98.9%; Average loss: 0.1288\n",
            "Iteration: 3958; Percent complete: 99.0%; Average loss: 0.1362\n",
            "Iteration: 3959; Percent complete: 99.0%; Average loss: 0.1433\n",
            "Iteration: 3960; Percent complete: 99.0%; Average loss: 0.1205\n",
            "Iteration: 3961; Percent complete: 99.0%; Average loss: 0.1391\n",
            "Iteration: 3962; Percent complete: 99.1%; Average loss: 0.1111\n",
            "Iteration: 3963; Percent complete: 99.1%; Average loss: 0.1335\n",
            "Iteration: 3964; Percent complete: 99.1%; Average loss: 0.1402\n",
            "Iteration: 3965; Percent complete: 99.1%; Average loss: 0.1380\n",
            "Iteration: 3966; Percent complete: 99.2%; Average loss: 0.1245\n",
            "Iteration: 3967; Percent complete: 99.2%; Average loss: 0.1279\n",
            "Iteration: 3968; Percent complete: 99.2%; Average loss: 0.1342\n",
            "Iteration: 3969; Percent complete: 99.2%; Average loss: 0.1577\n",
            "Iteration: 3970; Percent complete: 99.2%; Average loss: 0.1198\n",
            "Iteration: 3971; Percent complete: 99.3%; Average loss: 0.1128\n",
            "Iteration: 3972; Percent complete: 99.3%; Average loss: 0.1220\n",
            "Iteration: 3973; Percent complete: 99.3%; Average loss: 0.1351\n",
            "Iteration: 3974; Percent complete: 99.4%; Average loss: 0.1495\n",
            "Iteration: 3975; Percent complete: 99.4%; Average loss: 0.1239\n",
            "Iteration: 3976; Percent complete: 99.4%; Average loss: 0.1211\n",
            "Iteration: 3977; Percent complete: 99.4%; Average loss: 0.1370\n",
            "Iteration: 3978; Percent complete: 99.5%; Average loss: 0.1434\n",
            "Iteration: 3979; Percent complete: 99.5%; Average loss: 0.1608\n",
            "Iteration: 3980; Percent complete: 99.5%; Average loss: 0.1456\n",
            "Iteration: 3981; Percent complete: 99.5%; Average loss: 0.1405\n",
            "Iteration: 3982; Percent complete: 99.6%; Average loss: 0.1261\n",
            "Iteration: 3983; Percent complete: 99.6%; Average loss: 0.1135\n",
            "Iteration: 3984; Percent complete: 99.6%; Average loss: 0.1430\n",
            "Iteration: 3985; Percent complete: 99.6%; Average loss: 0.1289\n",
            "Iteration: 3986; Percent complete: 99.7%; Average loss: 0.1494\n",
            "Iteration: 3987; Percent complete: 99.7%; Average loss: 0.1442\n",
            "Iteration: 3988; Percent complete: 99.7%; Average loss: 0.1286\n",
            "Iteration: 3989; Percent complete: 99.7%; Average loss: 0.1251\n",
            "Iteration: 3990; Percent complete: 99.8%; Average loss: 0.1251\n",
            "Iteration: 3991; Percent complete: 99.8%; Average loss: 0.1412\n",
            "Iteration: 3992; Percent complete: 99.8%; Average loss: 0.1127\n",
            "Iteration: 3993; Percent complete: 99.8%; Average loss: 0.1181\n",
            "Iteration: 3994; Percent complete: 99.9%; Average loss: 0.1249\n",
            "Iteration: 3995; Percent complete: 99.9%; Average loss: 0.1270\n",
            "Iteration: 3996; Percent complete: 99.9%; Average loss: 0.1292\n",
            "Iteration: 3997; Percent complete: 99.9%; Average loss: 0.1341\n",
            "Iteration: 3998; Percent complete: 100.0%; Average loss: 0.1210\n",
            "Iteration: 3999; Percent complete: 100.0%; Average loss: 0.1203\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 0.1300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bF1TpbAsu6h"
      },
      "source": [
        "## Start chatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xe1maBq7LaK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d590dc-e2af-432e-d23d-22573033332c"
      },
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "searcher = GreedySearchDecoder(encoder, decoder)\n",
        "evaluateInput(encoder, decoder, searcher, voc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "$ the fans in my macbook are making a lot of noise what should i do\n",
            "Jarvis: Sorry, I cannot understand your question. Try again.\n",
            "$ macbook not working properly\n",
            "Jarvis: great to hear were you able to log this from our end can you send us a dm with your country to review further it it is the system is currently installed send that info via dm it you all the system it and well go from there\n",
            "$ my uber ride got cancelled\n",
            "Jarvis: sorry to hear this please send us a dm with your email address so we can assist it it to it it is you have a chance to contact us there it it as well it\n",
            "$ i love to fuck\n",
            "Jarvis: we love you right back jen and let us know the results in dm your name and zip code you all installed send a dm you there you all were we able to go from there you all were we\n",
            "$ my xbox is just freezing most of the times\n",
            "Jarvis: hello i apologize for the inconvenience can you please dm us with your account information we are here to help rk you a few it you have a chance to dm us if you have any questions mm it it it it\n",
            "$ hello i apologize\n",
            "Jarvis: wed like to look into this with you for you please check your dms for further instructions it it sb it you have a chance to look into this for you it it it is available you have a chance to look into this\n",
            "$ book my airline ticket\n",
            "Jarvis: thats a good rest of your new folder in your system is there any improvement after it the delivery is saying at this time jw it as the system is currently nq it the delivery is saying it to be available it\n",
            "$ q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhJxAcuX7f62"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}